{"cells":[{"cell_type":"markdown","metadata":{"id":"PHJaS1l-uS-B"},"source":["# **Milestone 2**"]},{"cell_type":"markdown","metadata":{"id":"Cdqhtr8yuS-L"},"source":["## **Model Building - Approach**\n","1. Data preparation\n","2. Partition the data into train and test set\n","3. Fit on the train data\n","4. Tune the model and prune the tree, if required\n","5. Test the model on test set"]},{"cell_type":"markdown","metadata":{"id":"7QgAXSWfuS-M"},"source":["## **Data Preparation**"]},{"cell_type":"markdown","metadata":{"id":"jSUhpu0fuS-M"},"source":["### **Separating the target variable from other variables**"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5960 entries, 0 to 5959\n","Data columns (total 13 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   BAD      5960 non-null   int64  \n"," 1   LOAN     5960 non-null   int64  \n"," 2   MORTDUE  5442 non-null   float64\n"," 3   VALUE    5848 non-null   float64\n"," 4   REASON   5708 non-null   object \n"," 5   JOB      5681 non-null   object \n"," 6   YOJ      5445 non-null   float64\n"," 7   DEROG    5252 non-null   float64\n"," 8   DELINQ   5380 non-null   float64\n"," 9   CLAGE    5652 non-null   float64\n"," 10  NINQ     5450 non-null   float64\n"," 11  CLNO     5738 non-null   float64\n"," 12  DEBTINC  4693 non-null   float64\n","dtypes: float64(9), int64(2), object(2)\n","memory usage: 605.4+ KB\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5960 entries, 0 to 5959\n","Data columns (total 13 columns):\n"," #   Column   Non-Null Count  Dtype   \n","---  ------   --------------  -----   \n"," 0   BAD      5960 non-null   category\n"," 1   LOAN     5960 non-null   int64   \n"," 2   MORTDUE  5442 non-null   float64 \n"," 3   VALUE    5848 non-null   float64 \n"," 4   REASON   5708 non-null   category\n"," 5   JOB      5681 non-null   category\n"," 6   YOJ      5445 non-null   float64 \n"," 7   DEROG    5252 non-null   float64 \n"," 8   DELINQ   5380 non-null   float64 \n"," 9   CLAGE    5652 non-null   float64 \n"," 10  NINQ     5450 non-null   float64 \n"," 11  CLNO     5738 non-null   float64 \n"," 12  DEBTINC  4693 non-null   float64 \n","dtypes: category(3), float64(9), int64(1)\n","memory usage: 483.7 KB\n","Unique values in BAD are :\n","0    4771\n","1    1189\n","Name: BAD, dtype: int64\n","****************************************\n","Unique values in REASON are :\n","DebtCon    3928\n","HomeImp    1780\n","Name: REASON, dtype: int64\n","****************************************\n","Unique values in JOB are :\n","Other      2388\n","ProfExe    1276\n","Office      948\n","Mgr         767\n","Self        193\n","Sales       109\n","Name: JOB, dtype: int64\n","****************************************\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_theme()\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,precision_score,recall_score,f1_score\n","\n","from sklearn import tree\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","import scipy.stats as stats\n","\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","### **Read the dataset**\n","hm=pd.read_csv(\"hmeq.csv\")\n","# Copying data to another variable to avoid any changes to original data\n","data=hm.copy()\n","### **Print the first and last 5 rows of the dataset**\n","# Display first five rows\n","data.head()\n","# Display last 5 rows\n","data.tail()\n","### **Understand the shape of the dataset**\n","# Check the shape of the data\n","data.shape\n","### **Check the data types of the columns**\n","# Check info of the data\n","data.info()\n","### **Check for missing values**\n","# Analyse missing values - Hint: use isnull() function\n","data.isnull().sum()\n","# Check the percentage of missing values in the each column.\n","# Hint: divide the result from the previous code by the number of rows in the dataset\n","# Remove ___________ and complete the code\n","\n","missing_percent = data.isnull().sum() * 100 / len(data)\n","missing_percent\n","### **Convert the data types**\n","cols = data.select_dtypes(['object']).columns.tolist()\n","\n","#adding target variable to this list as this is an classification problem and the target variable is categorical\n","\n","cols.append('BAD')\n","# Changing the data type of object type column to category. hint use astype() function\n","# remove ___________ and complete the code\n","\n","for i in cols:\n","    data[i] = data[i].astype(\"category\")\n","\n","data.dtypes\n","# Checking the info again and the datatype of different variable\n","# remove ___________ and complete the code\n","\n","data.info()\n","### **Analyze Summary Statistics of the dataset**\n","# Analyze the summary statistics for numerical variables\n","# Remove ___________ and complete the code\n","\n","data.describe()\n","# Check summary for categorical data - Hint: inside describe function you can use the argument include=['category']\n","# Remove ___________ and complete the code\n","\n","data.describe(include=['category']).T\n","# Checking the count of unique values in each categorical column \n","# Remove ___________ and complete the code\n","\n","cols_cat= data.select_dtypes(['category'])\n","\n","for i in cols_cat.columns:\n","    print('Unique values in',i, 'are :')\n","    print(cols_cat[i].value_counts())\n","    print('*'*40)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BAD</th>\n","      <th>LOAN</th>\n","      <th>MORTDUE</th>\n","      <th>VALUE</th>\n","      <th>REASON</th>\n","      <th>JOB</th>\n","      <th>YOJ</th>\n","      <th>DEROG</th>\n","      <th>DELINQ</th>\n","      <th>CLAGE</th>\n","      <th>NINQ</th>\n","      <th>CLNO</th>\n","      <th>DEBTINC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1100</td>\n","      <td>25860.0</td>\n","      <td>39025.0</td>\n","      <td>HomeImp</td>\n","      <td>Other</td>\n","      <td>10.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>94.366667</td>\n","      <td>1.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1300</td>\n","      <td>70053.0</td>\n","      <td>68400.0</td>\n","      <td>HomeImp</td>\n","      <td>Other</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>121.833333</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1500</td>\n","      <td>13500.0</td>\n","      <td>16700.0</td>\n","      <td>HomeImp</td>\n","      <td>Other</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>149.466667</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1500</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1700</td>\n","      <td>97800.0</td>\n","      <td>112000.0</td>\n","      <td>HomeImp</td>\n","      <td>Office</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>93.333333</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  BAD  LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n","0   1  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   \n","1   1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0   \n","2   1  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0   \n","3   1  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN   \n","4   0  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   \n","\n","        CLAGE  NINQ  CLNO  DEBTINC  \n","0   94.366667   1.0   9.0      NaN  \n","1  121.833333   0.0  14.0      NaN  \n","2  149.466667   1.0  10.0      NaN  \n","3         NaN   NaN   NaN      NaN  \n","4   93.333333   0.0  14.0      NaN  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data.head()\n","df =data.copy()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BAD</th>\n","      <th>LOAN</th>\n","      <th>MORTDUE</th>\n","      <th>VALUE</th>\n","      <th>REASON</th>\n","      <th>JOB</th>\n","      <th>YOJ</th>\n","      <th>DEROG</th>\n","      <th>DELINQ</th>\n","      <th>CLAGE</th>\n","      <th>NINQ</th>\n","      <th>CLNO</th>\n","      <th>DEBTINC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1100</td>\n","      <td>25860.0</td>\n","      <td>39025.0</td>\n","      <td>HomeImp</td>\n","      <td>Other</td>\n","      <td>10.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>94.366667</td>\n","      <td>1.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1300</td>\n","      <td>70053.0</td>\n","      <td>68400.0</td>\n","      <td>HomeImp</td>\n","      <td>Other</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>121.833333</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1500</td>\n","      <td>13500.0</td>\n","      <td>16700.0</td>\n","      <td>HomeImp</td>\n","      <td>Other</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>149.466667</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1500</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1700</td>\n","      <td>97800.0</td>\n","      <td>112000.0</td>\n","      <td>HomeImp</td>\n","      <td>Office</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>93.333333</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   BAD  LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n","0    1  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   \n","1    1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0   \n","2    1  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0   \n","3    1  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN   \n","4    0  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   \n","\n","        CLAGE  NINQ  CLNO  DEBTINC  \n","0   94.366667   1.0   9.0      NaN  \n","1  121.833333   0.0  14.0      NaN  \n","2  149.466667   1.0  10.0      NaN  \n","3         NaN   NaN   NaN      NaN  \n","4   93.333333   0.0  14.0      NaN  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# replacing nan values of Numerical features\n","df['LOAN'].fillna((df['LOAN'].median()), inplace=True)\n","df['MORTDUE'].fillna((df['MORTDUE'].median()), inplace=True)\n","df['VALUE'].fillna((df['VALUE'].median()), inplace=True)\n","df['YOJ'].fillna((df['YOJ'].median()), inplace=True)\n","df['DEROG'].fillna((df['DEROG'].median()), inplace=True)\n","df['DELINQ'].fillna((df['DELINQ'].median()), inplace=True)\n","df['CLAGE'].fillna((df['CLAGE'].median()), inplace=True)\n","df['NINQ'].fillna((df['NINQ'].median()), inplace=True)\n","df['CLNO'].fillna((df['CLNO'].median()), inplace=True)\n","df['DEBTINC'].fillna((df['DEBTINC'].median()), inplace=True)\n","# replacing nan values of Categorical features\n","df['BAD'].fillna((df['BAD'].median()), inplace=True)\n","df['REASON'].fillna((df['REASON'].median()), inplace=True)\n","df['JOB'].fillna((df['JOB'].median()), inplace=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"2_IZEwKruS-N"},"outputs":[],"source":["# Drop the dependent variable from the dataframe and create the X(independent variable) matrix\n","# Remove _________ and complete the code\n","X = df.drop(['BAD'], axis=1)\n","\n","# Create dummy variables for the categorical variables - Hint: use the get_dummies() function\n","# Remove _________ and complete the code\n","#X = ______________________\n","\n","# Create y(dependent varibale)\n","# Remove _________ and complete the code\n","\n","y = df['BAD']"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["X['REASON'] = pd.factorize(X['REASON'])[0]\n","X['JOB'] = pd.factorize(X['JOB'])[0]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LOAN</th>\n","      <th>MORTDUE</th>\n","      <th>VALUE</th>\n","      <th>REASON</th>\n","      <th>JOB</th>\n","      <th>YOJ</th>\n","      <th>DEROG</th>\n","      <th>DELINQ</th>\n","      <th>CLAGE</th>\n","      <th>NINQ</th>\n","      <th>CLNO</th>\n","      <th>DEBTINC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1100</td>\n","      <td>25860.0</td>\n","      <td>39025.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>94.366667</td>\n","      <td>1.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1300</td>\n","      <td>70053.0</td>\n","      <td>68400.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>121.833333</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1500</td>\n","      <td>13500.0</td>\n","      <td>16700.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>149.466667</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1500</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1700</td>\n","      <td>97800.0</td>\n","      <td>112000.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>93.333333</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5955</th>\n","      <td>88900</td>\n","      <td>57264.0</td>\n","      <td>90185.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>221.808718</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>36.112347</td>\n","    </tr>\n","    <tr>\n","      <th>5956</th>\n","      <td>89000</td>\n","      <td>54576.0</td>\n","      <td>92937.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>208.692070</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>35.859971</td>\n","    </tr>\n","    <tr>\n","      <th>5957</th>\n","      <td>89200</td>\n","      <td>54045.0</td>\n","      <td>92924.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>212.279697</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>35.556590</td>\n","    </tr>\n","    <tr>\n","      <th>5958</th>\n","      <td>89800</td>\n","      <td>50370.0</td>\n","      <td>91861.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>213.892709</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>34.340882</td>\n","    </tr>\n","    <tr>\n","      <th>5959</th>\n","      <td>89900</td>\n","      <td>48811.0</td>\n","      <td>88934.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>219.601002</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>34.571519</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5960 rows × 12 columns</p>\n","</div>"],"text/plain":["       LOAN  MORTDUE     VALUE  REASON  JOB   YOJ  DEROG  DELINQ       CLAGE  \\\n","0      1100  25860.0   39025.0       0    0  10.5    0.0     0.0   94.366667   \n","1      1300  70053.0   68400.0       0    0   7.0    0.0     2.0  121.833333   \n","2      1500  13500.0   16700.0       0    0   4.0    0.0     0.0  149.466667   \n","3      1500      NaN       NaN      -1   -1   NaN    NaN     NaN         NaN   \n","4      1700  97800.0  112000.0       0    1   3.0    0.0     0.0   93.333333   \n","...     ...      ...       ...     ...  ...   ...    ...     ...         ...   \n","5955  88900  57264.0   90185.0       1    0  16.0    0.0     0.0  221.808718   \n","5956  89000  54576.0   92937.0       1    0  16.0    0.0     0.0  208.692070   \n","5957  89200  54045.0   92924.0       1    0  15.0    0.0     0.0  212.279697   \n","5958  89800  50370.0   91861.0       1    0  14.0    0.0     0.0  213.892709   \n","5959  89900  48811.0   88934.0       1    0  15.0    0.0     0.0  219.601002   \n","\n","      NINQ  CLNO    DEBTINC  \n","0      1.0   9.0        NaN  \n","1      0.0  14.0        NaN  \n","2      1.0  10.0        NaN  \n","3      NaN   NaN        NaN  \n","4      0.0  14.0        NaN  \n","...    ...   ...        ...  \n","5955   0.0  16.0  36.112347  \n","5956   0.0  15.0  35.859971  \n","5957   0.0  15.0  35.556590  \n","5958   0.0  16.0  34.340882  \n","5959   0.0  16.0  34.571519  \n","\n","[5960 rows x 12 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["(   LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ       CLAGE  \\\n"," 0  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   94.366667   \n"," 1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0  121.833333   \n"," 2  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0  149.466667   \n"," 3  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN         NaN   \n"," 4  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   93.333333   \n"," \n","    NINQ  CLNO  DEBTINC  \n"," 0   1.0   9.0      NaN  \n"," 1   0.0  14.0      NaN  \n"," 2   1.0  10.0      NaN  \n"," 3   NaN   NaN      NaN  \n"," 4   0.0  14.0      NaN  ,\n"," 0    1\n"," 1    1\n"," 2    1\n"," 3    1\n"," 4    0\n"," Name: BAD, dtype: int64)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["X.head(),y.head()"]},{"cell_type":"markdown","metadata":{"id":"La_3-i5quS-P"},"source":["### **Splitting the data into 70% train and 30% test set**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgF5mdtCuS-P"},"outputs":[],"source":["# Split the data into training and test set\n","# Remove _________ and complete the code\n","\n","\n","_____________________________"]},{"cell_type":"markdown","metadata":{"id":"181uwUApuS-R"},"source":["### **Think about it** \n","- You can try different splits like 70:30 or 80:20 as per your choice. Does this change in split affect the performance?\n","- If the data is imbalanced, can you make the split more balanced and if yes, how?"]},{"cell_type":"markdown","metadata":{"id":"EVxWdZc_uS-S"},"source":["## **Model Evaluation Criterion**\n","\n","#### After understanding the problem statement, think about which evaluation metrics to consider and why. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNVO2cX_uS-V"},"outputs":[],"source":["#creating metric function \n","def metrics_score(actual, predicted):\n","    print(classification_report(actual, predicted))\n","    cm = confusion_matrix(actual, predicted)\n","    plt.figure(figsize=(8,5))\n","    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels=['Not Eligible', 'Eligible'], yticklabels=['Not Eligible', 'Eligible'])\n","    plt.ylabel('Actual')\n","    plt.xlabel('Predicted')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eTdaiYeMuS-a"},"source":["### **Build a Logistic Regression Model** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkEsDyg-uS-b"},"outputs":[],"source":["# Defining the Logistic regression model\n","# Remove _________ and complete the code\n","____________\n","\n","# Fitting the model on the training data \n","# Remove _________ and complete the code\n","\n","________________"]},{"cell_type":"markdown","metadata":{"id":"RZj-by40uS-c"},"source":["#### Checking the performance on the train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga0ZoViNuS-d"},"outputs":[],"source":["#Predict for train set\n","# Remove _________ and complete the code\n","________________\n","\n","#checking the performance on the train dataset\n","# Remove _________ and complete the code\n","_________________________"]},{"cell_type":"markdown","metadata":{"id":"4ouIrxTDuS-f"},"source":["#### Checking the performance on the test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtQ3PUoAuS-f"},"outputs":[],"source":["#Predict for test set\n","# Remove _________ and complete the code\n","\n","_______________________\n","\n","#checking the performance on the test dataset\n","# Remove _________ and complete the code\n","\n","_____________________________"]},{"cell_type":"markdown","metadata":{"id":"P0Uix_PRuS-g"},"source":["**Observations: __________**"]},{"cell_type":"markdown","metadata":{"id":"e1WM0T3vuS-g"},"source":["#### Let's check the coefficients, and check which variables are important and how they affect the process of loan approval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uelo699muS-h"},"outputs":[],"source":["# Printing the coefficients of logistic regression\n","# Remove _________ and complete the code\n","\n","\n","_____________________"]},{"cell_type":"markdown","metadata":{"id":"eQAjCv4MuS-i"},"source":["**Insights ________**"]},{"cell_type":"markdown","metadata":{"id":"k7X4-6d-uS-i"},"source":["### **Think about it:**\n","- The above Logistic regression model was build on the threshold of 0.5, can we use different threshold?\n","- How to get an optimal threshold and which curve will help you achieve?\n","- How does, accuracy, precision and recall change on the threshold?"]},{"cell_type":"markdown","metadata":{"id":"Qn8IjxI7uS-j"},"source":["### **Build a Decision Tree Model**"]},{"cell_type":"markdown","metadata":{"id":"ZOYH3hhauS-l"},"source":["### **Think about it:**\n","- In Logistic regression we treated the outliers and built the model, should we do the same for tree based models or not? If not, why?"]},{"cell_type":"markdown","metadata":{"id":"LcsyeOmMuS-n"},"source":["#### Data Preparation for the tree based model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syncXvl-uS-n"},"outputs":[],"source":["# Add binary flags\n","# List of columns that has missing values in it\n","missing_col = [col for col in data.columns if data[col].isnull().any()]\n","\n","for colmn in missing_col:\n","    add_binary_flag(data,colmn)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUaxm207uS-o"},"outputs":[],"source":["#  Treat Missing values in numerical columns with median and mode in categorical variables\n","# Select numeric columns.\n","num_data = data.select_dtypes('number')\n","\n","# Select string and object columns.\n","cat_data = data.select_dtypes('category').columns.tolist()#df.select_dtypes('object')\n","\n","# Fill numeric columns with median.\n","# Remove _________ and complete the code\n","data[num_data.columns] = num_data._________________\n","\n","# Fill object columns with model.\n","# Remove _________ and complete the code\n","for column in cat_data:\n","    mode = data[column].mode()[0]\n","    data[column] = data[column].____________"]},{"cell_type":"markdown","metadata":{"id":"aO6ZhcAGuS-o"},"source":["#### Separating the target variable y and independent variable x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t63yXVu_uS-p"},"outputs":[],"source":["# Drop dependent variable from dataframe and create the X(independent variable) matrix\n","# Remove _________ and complete the code\n","\n","X = ____________________\n","\n","# Create dummy variables for the categorical variables - Hint: use the get_dummies() function\n","# Remove _________ and complete the code\n","X = ______________________\n","\n","# Create y(dependent varibale)\n","# Remove _________ and complete the code\n","\n","y = ___________________________-"]},{"cell_type":"markdown","metadata":{"id":"Z_npczaCuS-p"},"source":["#### Split the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AEW52XOuS-p"},"outputs":[],"source":["# Split the data into training and test set\n","# Remove _________ and complete the code\n","\n","\n","______________ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_n6jIx9yuS-q"},"outputs":[],"source":["#Defining Decision tree model with class weights class_weight={0: 0.2, 1: 0.8}\n","# Remove ___________ and complete the code\n","\n","_______________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BongVVR0uS-q"},"outputs":[],"source":["#fitting Decision tree model\n","# Remove ___________ and complete the code\n","_______________"]},{"cell_type":"markdown","metadata":{"id":"n85UqWwJuS-q"},"source":["#### Checking the performance on the train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z2noEOCLuS-r"},"outputs":[],"source":["# Checking performance on the training data\n","# Remove ___________ and complete the code\n","\n","_______________"]},{"cell_type":"markdown","metadata":{"id":"hD_3cgYvuS-r"},"source":["#### Checking the performance on the test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajlKdERCuS-r"},"outputs":[],"source":["# Checking performance on the testing data\n","# Remove _________ and complete the code\n","\n","_______________"]},{"cell_type":"markdown","metadata":{"id":"kUDAFw4cuS-r"},"source":["**Insights _____________**"]},{"cell_type":"markdown","metadata":{"id":"7GtaZ2_juS-s"},"source":["### **Think about it:**\n","- Can we improve this model? \n","- How to get optimal parameters in order to get the best possible results?"]},{"cell_type":"markdown","metadata":{"id":"kjPqLicruS-s"},"source":["### **Decision Tree - Hyperparameter Tuning**\n","\n","* Hyperparameter tuning is tricky in the sense that **there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model**, so we usually resort to experimentation. We'll use Grid search to perform hyperparameter tuning.\n","* **Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.** \n","* **It is an exhaustive search** that is performed on the specific parameter values of a model.\n","* The parameters of the estimator/model used to apply these methods are **optimized by cross-validated grid-search** over a parameter grid.\n","\n","**Criterion {“gini”, “entropy”}**\n","\n","The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.\n","\n","**max_depth** \n","\n","The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n","\n","**min_samples_leaf**\n","\n","The minimum number of samples is required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n","\n","You can learn about more Hyperpapameters on this link and try to tune them. \n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"]},{"cell_type":"markdown","metadata":{"id":"LWj_L0VnuS-s"},"source":["#### Using GridSearchCV for Hyperparameter tuning on the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_v-aQT3SuS-s"},"outputs":[],"source":["# Choose the type of classifier. \n","# Remove _________ and complete the code\n","________________\n","\n","\n","# Grid of parameters to choose from\n","# Remove _________ and complete the code\n","________________\n","\n","\n","# Type of scoring used to compare parameter combinations\n","# Remove _________ and complete the code\n","_________________\n","\n","\n","# Run the grid search\n","# Remove _________ and complete the code\n","_________________\n","\n","\n","# Fit the GridSearch on train dataset\n","# Remove _________ and complete the code\n","__________________\n","\n","\n","# Set the clf to the best combination of parameters\n","# Remove _________ and complete the code\n","_________________\n","\n","\n","# Fit the best algorithm to the data. \n","# Remove _________ and complete the code\n","_________________"]},{"cell_type":"markdown","metadata":{"id":"5Nd9-d44uS-t"},"source":["#### Checking the performance on the train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJuFkZwluS-t"},"outputs":[],"source":["# Checking performance on the training data based on the tuned model\n","# Remove _________ and complete the code\n","\n","______________"]},{"cell_type":"markdown","metadata":{"id":"0e6nxW5zuS-t"},"source":["#### Checking the performance on the test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXhwj5UtuS-t"},"outputs":[],"source":["# Checking performance on the testing data based on the tuned model\n","# Remove _________ and complete the code\n","\n","_________________\n"]},{"cell_type":"markdown","metadata":{"id":"sskSDE2RuS-u"},"source":["**Insights ___________**"]},{"cell_type":"markdown","metadata":{"id":"YgPleHWHuS-u"},"source":["#### Plotting the Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9alMIpUuS-u"},"outputs":[],"source":["# Plot the decision  tree and analyze it to build the decision rule\n","# Remove _________ and complete the code\n","\n","\n","____________"]},{"cell_type":"markdown","metadata":{"id":"DXlpWpwquS-u"},"source":["#### Deduce the business rules apparent from the Decision Tree and write them down: _____"]},{"cell_type":"markdown","metadata":{"id":"4IG8BCgluS-u"},"source":["### **Building a Random Forest Classifier**\n","\n","**Random Forest is a bagging algorithm where the base models are Decision Trees.** Samples are taken from the training data and on each sample a decision tree makes a prediction. \n","\n","**The results from all the decision trees are combined together and the final prediction is made using voting or averaging.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CS_aJmluS-u"},"outputs":[],"source":["# Defining Random forest CLassifier\n","# Remove _________ and complete the code\n","\n","___________________"]},{"cell_type":"markdown","metadata":{"id":"9MGpWZ8buS-v"},"source":["#### Checking the performance on the train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8CrEYjsuS-v"},"outputs":[],"source":["#Checking performance on the training data\n","# Remove _________ and complete the code\n","_______________"]},{"cell_type":"markdown","metadata":{"id":"DaH64bDMuS-v"},"source":["#### Checking the performance on the test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"At9Nu5KkuS-v"},"outputs":[],"source":["# Checking performance on the test data\n","# Remove _________ and complete the code\n","\n","_______________"]},{"cell_type":"markdown","metadata":{"id":"UqQfEbEKuS-v"},"source":["**Observations: __________**"]},{"cell_type":"markdown","metadata":{"id":"HCBcKpE3uS-w"},"source":["### **Build a Random Forest model with Class Weights**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRsYlxyXuS-w"},"outputs":[],"source":["# Defining Random Forest model with class weights class_weight={0: 0.2, 1: 0.8}\n","\n","# Remove _________ and complete the code\n","\n","_____________________________\n","\n","# Fitting Random Forest model\n","# Remove _________ and complete the code\n","\n","_______________"]},{"cell_type":"markdown","metadata":{"id":"JJP3x99guS-w"},"source":["#### Checking the performance on the train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xg6LNpXPuS-w","scrolled":false},"outputs":[],"source":["# Checking performance on the train data\n","# Remove _________ and complete the code\n","\n","________________"]},{"cell_type":"markdown","metadata":{"id":"sKMujUrwuS-w"},"source":["#### Checking the performance on the test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehxp227duS-x"},"outputs":[],"source":["# Checking performance on the test data\n","# Remove _________ and complete the code\n","\n","________________"]},{"cell_type":"markdown","metadata":{"id":"HU_b2tY3uS-x"},"source":["### **Think about it:**\n","- Can we try different weights?\n","- If yes, should we increase or decrease class weights for different classes? "]},{"cell_type":"markdown","metadata":{"id":"nFRFdf0KuS-x"},"source":["### **Tuning the Random Forest**"]},{"cell_type":"markdown","metadata":{"id":"-pHpGmcquS-x"},"source":["* Hyperparameter tuning is tricky in the sense that **there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model**, so we usually resort to experimentation. We'll use Grid search to perform hyperparameter tuning.\n","* **Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.** \n","* **It is an exhaustive search** that is performed on the specific parameter values of a model.\n","* The parameters of the estimator/model used to apply these methods are **optimized by cross-validated grid-search** over a parameter grid.\n","\n","\n","**n_estimators**: The number of trees in the forest.\n","\n","**min_samples_split**: The minimum number of samples required to split an internal node:\n","\n","**min_samples_leaf**: The minimum number of samples required to be at a leaf node. \n","\n","**max_features{“auto”, “sqrt”, “log2”, 'None'}**: The number of features to consider when looking for the best split.\n","\n","- If “auto”, then max_features=sqrt(n_features).\n","\n","- If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n","\n","- If “log2”, then max_features=log2(n_features).\n","\n","- If None, then max_features=n_features.\n","\n","You can learn more about Random Forest Hyperparameters from the link given below and try to tune them\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"]},{"cell_type":"markdown","metadata":{"id":"2Yju5_bLuS-y"},"source":["#### **Warning:** This may take a long time depending on the parameters you tune. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4eF3pM_0uS-y"},"outputs":[],"source":["# Choose the type of classifier. \n","# Remove _________ and complete the code\n","________________\n","\n","\n","# Grid of parameters to choose from\n","# Remove _________ and complete the code\n","________________\n","\n","\n","# Type of scoring used to compare parameter combinations\n","# Remove _________ and complete the code\n","_________________\n","\n","\n","# Run the grid search\n","# Remove _________ and complete the code\n","_________________\n","\n","\n","#fit the GridSearch on train dataset\n","# Remove _________ and complete the code\n","__________________\n","\n","\n","# Set the clf to the best combination of parameters\n","# Remove _________ and complete the code\n","_________________\n","\n","\n","# Fit the best algorithm to the data. \n","# Remove _________ and complete the code\n","_________________"]},{"cell_type":"markdown","metadata":{"id":"Mawgr8A6uS-z"},"source":["#### Checking the performance on the train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gm8MPNCOuS-z"},"outputs":[],"source":["# Checking performance on the training data\n","# Remove _________ and complete the code\n","______________"]},{"cell_type":"markdown","metadata":{"id":"oepvVX5CuS-3"},"source":["#### Checking the performance on the test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PoLfAzauS-3"},"outputs":[],"source":["# Checking performace on test dataset\n","# Remove _________ and complete the code\n","\n","_________________"]},{"cell_type":"markdown","metadata":{"id":"2bhHvKnAuS-4"},"source":["**Insights: _____**"]},{"cell_type":"markdown","metadata":{"id":"Pq9GKJxnuS-4"},"source":["#### Plot the Feature importance of the tuned Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PeJMlclxuS-4"},"outputs":[],"source":["# importance of features in the tree building ( The importance of a feature is computed as the \n","#(normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n","# Checking performace on test dataset\n","# Remove _________ and complete the code\n","\n","_________________"]},{"cell_type":"markdown","metadata":{"id":"Z02xcdkcuS-5"},"source":["### **Think about it:**\n","- We have only built 3 models so far, Logistic Regression, Decision Tree and Random Forest \n","- We can build other Machine Learning classification models like kNN, LDA, QDA or even Support Vector Machines (SVM).\n","- Can we also perform feature engineering and create model features and build a more robust and accurate model for this problem statement? "]},{"cell_type":"markdown","metadata":{"id":"fkR0P8HXuS-5"},"source":["### **Comparing Model Performances**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pe6Pl8FVuS-6"},"outputs":[],"source":["def get_recall_score(model,flag=True,X_train=X_train,X_test=X_test):\n","    '''\n","    model : classifier to predict values of X\n","\n","    '''\n","    a = [] # defining an empty list to store train and test results\n","    pred_train = model.predict(X_train)\n","    pred_test = model.predict(X_test)\n","    train_recall = metrics.recall_score(y_train,pred_train)\n","    test_recall = metrics.recall_score(y_test,pred_test)\n","    a.append(train_recall) # adding train recall to list \n","    a.append(test_recall) # adding test recall to list\n","    \n","    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n","    if flag == True: \n","        print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n","        print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n","    \n","    return a # returning the list with train and test scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHrSzelxuS-6"},"outputs":[],"source":["##  Function to calculate precision score\n","def get_precision_score(model,flag=True,X_train=X_train,X_test=X_test):\n","    '''\n","    model : classifier to predict values of X\n","\n","    '''\n","    b = []  # defining an empty list to store train and test results\n","    pred_train = model.predict(X_train)\n","    pred_test = model.predict(X_test)\n","    train_precision = metrics.precision_score(y_train,pred_train)\n","    test_precision = metrics.precision_score(y_test,pred_test)\n","    b.append(train_precision) # adding train precision to list\n","    b.append(test_precision) # adding test precision to list\n","    \n","    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n","    if flag == True: \n","        print(\"Precision on training set : \",metrics.precision_score(y_train,pred_train))\n","        print(\"Precision on test set : \",metrics.precision_score(y_test,pred_test))\n","\n","    return b # returning the list with train and test scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8UbeXu-guS-7"},"outputs":[],"source":["##  Function to calculate accuracy score\n","def get_accuracy_score(model,flag=True,X_train=X_train,X_test=X_test):\n","    '''\n","    model : classifier to predict values of X\n","\n","    '''\n","    c = [] # defining an empty list to store train and test results\n","    train_acc = model.score(X_train,y_train)\n","    test_acc = model.score(X_test,y_test)\n","    c.append(train_acc) # adding train accuracy to list\n","    c.append(test_acc) # adding test accuracy to list\n","    \n","    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n","    if flag == True:\n","        print(\"Accuracy on training set : \",model.score(X_train,y_train))\n","        print(\"Accuracy on test set : \",model.score(X_test,y_test))\n","    \n","    return c # returning the list with train and test scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZ9-xSnjuS-8"},"outputs":[],"source":["# Make the list of all the model names \n","\n","models = [___________________________]\n","# Remove _________ and complete the code\n","\n","# defining empty lists to add train and test results\n","acc_train = []\n","acc_test = []\n","recall_train = []\n","recall_test = []\n","precision_train = []\n","precision_test = []\n","\n","# looping through all the models to get the accuracy,recall and precision scores\n","for model in models:\n","     # accuracy score\n","    j = get_accuracy_score(model,False)\n","    acc_train.append(j[0])\n","    acc_test.append(j[1])\n","\n","    # recall score\n","    k = get_recall_score(model,False)\n","    recall_train.append(k[0])\n","    recall_test.append(k[1])\n","\n","    # precision score\n","    l = get_precision_score(model,False)\n","    precision_train.append(l[0])\n","    precision_test.append(l[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHsbc4DMuS-8"},"outputs":[],"source":["# Mention the Model names in the list. for example 'Model': ['Decision Tree', 'Tuned Decision Tree'..... write tht names of all model built]\n","# Remove _________ and complete the code\n","\n","comparison_frame = pd.DataFrame({'Model':[______________________], \n","                                          'Train_Accuracy': acc_train,\n","                                          'Test_Accuracy': acc_test,\n","                                          'Train_Recall': recall_train,\n","                                          'Test_Recall': recall_test,\n","                                          'Train_Precision': precision_train,\n","                                          'Test_Precision': precision_test}) \n","comparison_frame"]},{"cell_type":"markdown","metadata":{"id":"YxFPX-pduS-9"},"source":["**Insights: ________**"]},{"cell_type":"markdown","metadata":{"id":"kPywjJo6uS-9"},"source":["**1. Refined insights -** What are the most meaningful insights from the data relevant to the problem?"]},{"cell_type":"markdown","metadata":{"id":"eZdLjL5vuS-9"},"source":["**2. Comparison of various techniques and their relative performance -** How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?"]},{"cell_type":"markdown","metadata":{"id":"lJRsBfsruS--"},"source":["**3. Proposal for the final solution design -** What model do you propose to be adopted? Why is this the best solution to adopt?"]}],"metadata":{"colab":{"collapsed_sections":["jSUhpu0fuS-M","La_3-i5quS-P","eTdaiYeMuS-a","RZj-by40uS-c","4ouIrxTDuS-f","e1WM0T3vuS-g","k7X4-6d-uS-i","LcsyeOmMuS-n","aO6ZhcAGuS-o","Z_npczaCuS-p","n85UqWwJuS-q","hD_3cgYvuS-r","7GtaZ2_juS-s","kjPqLicruS-s","LWj_L0VnuS-s","5Nd9-d44uS-t","0e6nxW5zuS-t","YgPleHWHuS-u","DXlpWpwquS-u","4IG8BCgluS-u","9MGpWZ8buS-v","DaH64bDMuS-v","HCBcKpE3uS-w","JJP3x99guS-w","sKMujUrwuS-w","HU_b2tY3uS-x","nFRFdf0KuS-x","2Yju5_bLuS-y","Mawgr8A6uS-z","oepvVX5CuS-3","Z02xcdkcuS-5"],"name":"Reference_Notebook_Milestone_2_Classification.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}
