{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all essential libraries\n",
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "## Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>site off</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>88</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      MB033 MB034 MB035 MB036\n",
       "0 2021-01-01  site off     4    71    40\n",
       "1 2021-01-02        88    66    52    12\n",
       "2 2021-01-03        52    40    54    72\n",
       "3 2021-01-04        49    34    32    28\n",
       "4 2021-01-05        82    32    85    49"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Book01.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>75</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  MB033 MB034 MB035 MB036\n",
       "498 2022-05-14    98    50    19    60\n",
       "499 2022-05-15     3     0    66    48\n",
       "500 2022-05-16    75    54    37    10\n",
       "501 2022-05-17    43    43    20    37\n",
       "502 2022-05-18     7    56    74    42"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     0\n",
       "MB033    0\n",
       "MB034    0\n",
       "MB035    0\n",
       "MB036    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in train data\n",
    "df.isnull().sum()\n",
    " #No missing valuues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for better understanding of the data, We can eloborate as month and weekday wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1      66\n",
       "2      40\n",
       "3      34\n",
       "4      32\n",
       "       ..\n",
       "498    50\n",
       "499     0\n",
       "500    54\n",
       "501    43\n",
       "502    56\n",
       "Name: MB034, Length: 503, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MB034']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MB033'] = df['MB033'].replace(['site off'],0)\n",
    "df['MB034'] = df['MB034'].replace(['site off'],0)\n",
    "df['MB035'] = df['MB035'].replace(['site off'],0)\n",
    "df['MB036'] = df['MB036'].replace(['site off'],0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,  66,  40,  34,  32,  77,  15,  36,  64,  92,   5,   6,  71,\n",
       "        87,   8,  32,  59,  55,  47,  82,  48,  95,  74,  66,  49,  40,\n",
       "        20,  62,  18,  84,   0,  91,   7,  65,  65,  22,  74,  30,  66,\n",
       "        45,  41,  20,  27,  19,  73,  32,  90,  48,  17,  59,  30,  28,\n",
       "        32,  61,  38,  73,  48,  38,   0,  26,   5,  22,  34,  39,  91,\n",
       "        51,  32,  94,  34,  71,   4,  69,  93,  61,  58,  68,  96,  83,\n",
       "        92,  43,  31,   1,  59,  90,  46,  99,  31,  53,  25,   0,  65,\n",
       "        25,   9,  30,  38,   4,  46,  12,  24,  61,  27,  29,  48,  90,\n",
       "        51,  78,  87,  90,  24,  57,  24,   2,  44,  69,  22,  21,  18,\n",
       "        44,  62,   0,  69,  59,  86,  59,  25,  68,  18,  68,  76,  14,\n",
       "        99,  79,  12,  20,  65,  30,  76,  51,  33,  76,  94,  89,  61,\n",
       "        53,  87,  90,  39,  14,  79,  16,   0,  66,  42,  55,  33,  82,\n",
       "        57,  40,  55,  99,  25,   6,  98,  41,  93,  34,   6,  84,  34,\n",
       "        75,  31,  75,  99,  57,  36,  97,  82,  17,  31,  81,   0,  74,\n",
       "        60,  35,  89,  77,  21,  95,  45,  34,  73,  52,  93,  85,  12,\n",
       "        53,  76,  43,  59,   1,  61,  49,  23,  29,  64,   6,  31,  49,\n",
       "         1,   6,  89,   0,  19,  82,  91,  84,  87,  69,  29,  66,  68,\n",
       "        81,  15,  46,  52,  83,  91,  12,  80,  40,  32,  63,  78,  50,\n",
       "        53,   8,  49,  14,  12,  92,  39,  20,   0,  56,  31,  38,   2,\n",
       "        22,  34,  18,  45,  58,  86,  25,   8,  75,  54,   3,  99,  59,\n",
       "        33,  92,  36,  72,  93,  99,  82,  75,  19,  52,  75,  96,   0,\n",
       "        33,   8,  17,  99,  87,  21,  93,  60,  27,  22,  71,  15,  33,\n",
       "        97,  48,  25,  47,   5,  91,   8,   0,  67,  78,  30,  98,  97,\n",
       "        42,  89,  28,  79,   0,  86,  49,  26,  28, 100,  90,  92,   7,\n",
       "        73,  14,  62,  40,  71,   0,  70,  42,  61,   8,  98,  47,  46,\n",
       "        24,  94,  32,  11,  84,  30,  67,  83,   0,   6,  49,  29,   6,\n",
       "         7,  17,  46,  47,  45,  43,   9,  78,  29,   2,  25,  64,  72,\n",
       "        29,  90,  13,  45,  81,  31,  73,  84,  21,  83,  73,   7,  28,\n",
       "         0,  85,  47,  70,  66,   5,  29,   3,  17,  85,   9,  72,  10,\n",
       "        67,  21,  42,  10,  87,  76,  84,  20,  78,  83,  36,   2,  60,\n",
       "        46,  68,  15,  24,  65,   0,  36,   9,   9,  67,  91,  91,  43,\n",
       "        62,  67,  97,  96,  87,  18,  10,  18,  78,  55,  90,  28,  92,\n",
       "        67,  16,  14,  97,  51,  97,  55,   0,  60,   9,  58,  81,   4,\n",
       "        16,  57,  30,  91,   5,  98,  64,  14,  72,  57,  85,  27,  80,\n",
       "        16,   1,   1,   8,  61,  54,  26,  23,  52,  73,  81,  47,   0,\n",
       "        22,  62,   1,  63,  30,  40,  40,  48,  42,  43,  28,  57,  53,\n",
       "        22,  93,  17,  55,  20,  63,  91,  63,  28,  49,   2,  94,  65,\n",
       "        84,  63,  42,   0,  29,  12,  99,  33,  53,  72,  68,   9,  69,\n",
       "        19,  42,   3,  82,  50,   0,  54,  43,  56])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = df['MB034'].values\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def splitSequence(seq, n_steps):\n",
    "    \n",
    "    #Declare X and y as empty list\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        #get the last index\n",
    "        lastIndex = i + n_steps\n",
    "        \n",
    "        #if lastIndex is greater than length of sequence then break\n",
    "        if lastIndex > len(seq) - 1:\n",
    "            break\n",
    "            \n",
    "        #Create input and output sequence\n",
    "        seq_X, seq_y = seq[i:lastIndex], seq[lastIndex]\n",
    "        \n",
    "        #append seq_X, seq_y in X and y list\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        pass\n",
    "    #Convert X and y into numpy array\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y \n",
    "    \n",
    "    pass\n",
    "\n",
    "n_steps = 10\n",
    "X, y = splitSequence(arr1, n_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((493, 10), (493,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 66 40 34 32 77 15 36 64 92] 5\n",
      "[66 40 34 32 77 15 36 64 92  5] 6\n",
      "[40 34 32 77 15 36 64 92  5  6] 71\n",
      "[34 32 77 15 36 64 92  5  6 71] 87\n",
      "[32 77 15 36 64 92  5  6 71 87] 8\n",
      "[77 15 36 64 92  5  6 71 87  8] 32\n",
      "[15 36 64 92  5  6 71 87  8 32] 59\n",
      "[36 64 92  5  6 71 87  8 32 59] 55\n",
      "[64 92  5  6 71 87  8 32 59 55] 47\n",
      "[92  5  6 71 87  8 32 59 55 47] 82\n",
      "[ 5  6 71 87  8 32 59 55 47 82] 48\n",
      "[ 6 71 87  8 32 59 55 47 82 48] 95\n",
      "[71 87  8 32 59 55 47 82 48 95] 74\n",
      "[87  8 32 59 55 47 82 48 95 74] 66\n",
      "[ 8 32 59 55 47 82 48 95 74 66] 49\n",
      "[32 59 55 47 82 48 95 74 66 49] 40\n",
      "[59 55 47 82 48 95 74 66 49 40] 20\n",
      "[55 47 82 48 95 74 66 49 40 20] 62\n",
      "[47 82 48 95 74 66 49 40 20 62] 18\n",
      "[82 48 95 74 66 49 40 20 62 18] 84\n",
      "[48 95 74 66 49 40 20 62 18 84] 0\n",
      "[95 74 66 49 40 20 62 18 84  0] 91\n",
      "[74 66 49 40 20 62 18 84  0 91] 7\n",
      "[66 49 40 20 62 18 84  0 91  7] 65\n",
      "[49 40 20 62 18 84  0 91  7 65] 65\n",
      "[40 20 62 18 84  0 91  7 65 65] 22\n",
      "[20 62 18 84  0 91  7 65 65 22] 74\n",
      "[62 18 84  0 91  7 65 65 22 74] 30\n",
      "[18 84  0 91  7 65 65 22 74 30] 66\n",
      "[84  0 91  7 65 65 22 74 30 66] 45\n",
      "[ 0 91  7 65 65 22 74 30 66 45] 41\n",
      "[91  7 65 65 22 74 30 66 45 41] 20\n",
      "[ 7 65 65 22 74 30 66 45 41 20] 27\n",
      "[65 65 22 74 30 66 45 41 20 27] 19\n",
      "[65 22 74 30 66 45 41 20 27 19] 73\n",
      "[22 74 30 66 45 41 20 27 19 73] 32\n",
      "[74 30 66 45 41 20 27 19 73 32] 90\n",
      "[30 66 45 41 20 27 19 73 32 90] 48\n",
      "[66 45 41 20 27 19 73 32 90 48] 17\n",
      "[45 41 20 27 19 73 32 90 48 17] 59\n",
      "[41 20 27 19 73 32 90 48 17 59] 30\n",
      "[20 27 19 73 32 90 48 17 59 30] 28\n",
      "[27 19 73 32 90 48 17 59 30 28] 32\n",
      "[19 73 32 90 48 17 59 30 28 32] 61\n",
      "[73 32 90 48 17 59 30 28 32 61] 38\n",
      "[32 90 48 17 59 30 28 32 61 38] 73\n",
      "[90 48 17 59 30 28 32 61 38 73] 48\n",
      "[48 17 59 30 28 32 61 38 73 48] 38\n",
      "[17 59 30 28 32 61 38 73 48 38] 0\n",
      "[59 30 28 32 61 38 73 48 38  0] 26\n",
      "[30 28 32 61 38 73 48 38  0 26] 5\n",
      "[28 32 61 38 73 48 38  0 26  5] 22\n",
      "[32 61 38 73 48 38  0 26  5 22] 34\n",
      "[61 38 73 48 38  0 26  5 22 34] 39\n",
      "[38 73 48 38  0 26  5 22 34 39] 91\n",
      "[73 48 38  0 26  5 22 34 39 91] 51\n",
      "[48 38  0 26  5 22 34 39 91 51] 32\n",
      "[38  0 26  5 22 34 39 91 51 32] 94\n",
      "[ 0 26  5 22 34 39 91 51 32 94] 34\n",
      "[26  5 22 34 39 91 51 32 94 34] 71\n",
      "[ 5 22 34 39 91 51 32 94 34 71] 4\n",
      "[22 34 39 91 51 32 94 34 71  4] 69\n",
      "[34 39 91 51 32 94 34 71  4 69] 93\n",
      "[39 91 51 32 94 34 71  4 69 93] 61\n",
      "[91 51 32 94 34 71  4 69 93 61] 58\n",
      "[51 32 94 34 71  4 69 93 61 58] 68\n",
      "[32 94 34 71  4 69 93 61 58 68] 96\n",
      "[94 34 71  4 69 93 61 58 68 96] 83\n",
      "[34 71  4 69 93 61 58 68 96 83] 92\n",
      "[71  4 69 93 61 58 68 96 83 92] 43\n",
      "[ 4 69 93 61 58 68 96 83 92 43] 31\n",
      "[69 93 61 58 68 96 83 92 43 31] 1\n",
      "[93 61 58 68 96 83 92 43 31  1] 59\n",
      "[61 58 68 96 83 92 43 31  1 59] 90\n",
      "[58 68 96 83 92 43 31  1 59 90] 46\n",
      "[68 96 83 92 43 31  1 59 90 46] 99\n",
      "[96 83 92 43 31  1 59 90 46 99] 31\n",
      "[83 92 43 31  1 59 90 46 99 31] 53\n",
      "[92 43 31  1 59 90 46 99 31 53] 25\n",
      "[43 31  1 59 90 46 99 31 53 25] 0\n",
      "[31  1 59 90 46 99 31 53 25  0] 65\n",
      "[ 1 59 90 46 99 31 53 25  0 65] 25\n",
      "[59 90 46 99 31 53 25  0 65 25] 9\n",
      "[90 46 99 31 53 25  0 65 25  9] 30\n",
      "[46 99 31 53 25  0 65 25  9 30] 38\n",
      "[99 31 53 25  0 65 25  9 30 38] 4\n",
      "[31 53 25  0 65 25  9 30 38  4] 46\n",
      "[53 25  0 65 25  9 30 38  4 46] 12\n",
      "[25  0 65 25  9 30 38  4 46 12] 24\n",
      "[ 0 65 25  9 30 38  4 46 12 24] 61\n",
      "[65 25  9 30 38  4 46 12 24 61] 27\n",
      "[25  9 30 38  4 46 12 24 61 27] 29\n",
      "[ 9 30 38  4 46 12 24 61 27 29] 48\n",
      "[30 38  4 46 12 24 61 27 29 48] 90\n",
      "[38  4 46 12 24 61 27 29 48 90] 51\n",
      "[ 4 46 12 24 61 27 29 48 90 51] 78\n",
      "[46 12 24 61 27 29 48 90 51 78] 87\n",
      "[12 24 61 27 29 48 90 51 78 87] 90\n",
      "[24 61 27 29 48 90 51 78 87 90] 24\n",
      "[61 27 29 48 90 51 78 87 90 24] 57\n",
      "[27 29 48 90 51 78 87 90 24 57] 24\n",
      "[29 48 90 51 78 87 90 24 57 24] 2\n",
      "[48 90 51 78 87 90 24 57 24  2] 44\n",
      "[90 51 78 87 90 24 57 24  2 44] 69\n",
      "[51 78 87 90 24 57 24  2 44 69] 22\n",
      "[78 87 90 24 57 24  2 44 69 22] 21\n",
      "[87 90 24 57 24  2 44 69 22 21] 18\n",
      "[90 24 57 24  2 44 69 22 21 18] 44\n",
      "[24 57 24  2 44 69 22 21 18 44] 62\n",
      "[57 24  2 44 69 22 21 18 44 62] 0\n",
      "[24  2 44 69 22 21 18 44 62  0] 69\n",
      "[ 2 44 69 22 21 18 44 62  0 69] 59\n",
      "[44 69 22 21 18 44 62  0 69 59] 86\n",
      "[69 22 21 18 44 62  0 69 59 86] 59\n",
      "[22 21 18 44 62  0 69 59 86 59] 25\n",
      "[21 18 44 62  0 69 59 86 59 25] 68\n",
      "[18 44 62  0 69 59 86 59 25 68] 18\n",
      "[44 62  0 69 59 86 59 25 68 18] 68\n",
      "[62  0 69 59 86 59 25 68 18 68] 76\n",
      "[ 0 69 59 86 59 25 68 18 68 76] 14\n",
      "[69 59 86 59 25 68 18 68 76 14] 99\n",
      "[59 86 59 25 68 18 68 76 14 99] 79\n",
      "[86 59 25 68 18 68 76 14 99 79] 12\n",
      "[59 25 68 18 68 76 14 99 79 12] 20\n",
      "[25 68 18 68 76 14 99 79 12 20] 65\n",
      "[68 18 68 76 14 99 79 12 20 65] 30\n",
      "[18 68 76 14 99 79 12 20 65 30] 76\n",
      "[68 76 14 99 79 12 20 65 30 76] 51\n",
      "[76 14 99 79 12 20 65 30 76 51] 33\n",
      "[14 99 79 12 20 65 30 76 51 33] 76\n",
      "[99 79 12 20 65 30 76 51 33 76] 94\n",
      "[79 12 20 65 30 76 51 33 76 94] 89\n",
      "[12 20 65 30 76 51 33 76 94 89] 61\n",
      "[20 65 30 76 51 33 76 94 89 61] 53\n",
      "[65 30 76 51 33 76 94 89 61 53] 87\n",
      "[30 76 51 33 76 94 89 61 53 87] 90\n",
      "[76 51 33 76 94 89 61 53 87 90] 39\n",
      "[51 33 76 94 89 61 53 87 90 39] 14\n",
      "[33 76 94 89 61 53 87 90 39 14] 79\n",
      "[76 94 89 61 53 87 90 39 14 79] 16\n",
      "[94 89 61 53 87 90 39 14 79 16] 0\n",
      "[89 61 53 87 90 39 14 79 16  0] 66\n",
      "[61 53 87 90 39 14 79 16  0 66] 42\n",
      "[53 87 90 39 14 79 16  0 66 42] 55\n",
      "[87 90 39 14 79 16  0 66 42 55] 33\n",
      "[90 39 14 79 16  0 66 42 55 33] 82\n",
      "[39 14 79 16  0 66 42 55 33 82] 57\n",
      "[14 79 16  0 66 42 55 33 82 57] 40\n",
      "[79 16  0 66 42 55 33 82 57 40] 55\n",
      "[16  0 66 42 55 33 82 57 40 55] 99\n",
      "[ 0 66 42 55 33 82 57 40 55 99] 25\n",
      "[66 42 55 33 82 57 40 55 99 25] 6\n",
      "[42 55 33 82 57 40 55 99 25  6] 98\n",
      "[55 33 82 57 40 55 99 25  6 98] 41\n",
      "[33 82 57 40 55 99 25  6 98 41] 93\n",
      "[82 57 40 55 99 25  6 98 41 93] 34\n",
      "[57 40 55 99 25  6 98 41 93 34] 6\n",
      "[40 55 99 25  6 98 41 93 34  6] 84\n",
      "[55 99 25  6 98 41 93 34  6 84] 34\n",
      "[99 25  6 98 41 93 34  6 84 34] 75\n",
      "[25  6 98 41 93 34  6 84 34 75] 31\n",
      "[ 6 98 41 93 34  6 84 34 75 31] 75\n",
      "[98 41 93 34  6 84 34 75 31 75] 99\n",
      "[41 93 34  6 84 34 75 31 75 99] 57\n",
      "[93 34  6 84 34 75 31 75 99 57] 36\n",
      "[34  6 84 34 75 31 75 99 57 36] 97\n",
      "[ 6 84 34 75 31 75 99 57 36 97] 82\n",
      "[84 34 75 31 75 99 57 36 97 82] 17\n",
      "[34 75 31 75 99 57 36 97 82 17] 31\n",
      "[75 31 75 99 57 36 97 82 17 31] 81\n",
      "[31 75 99 57 36 97 82 17 31 81] 0\n",
      "[75 99 57 36 97 82 17 31 81  0] 74\n",
      "[99 57 36 97 82 17 31 81  0 74] 60\n",
      "[57 36 97 82 17 31 81  0 74 60] 35\n",
      "[36 97 82 17 31 81  0 74 60 35] 89\n",
      "[97 82 17 31 81  0 74 60 35 89] 77\n",
      "[82 17 31 81  0 74 60 35 89 77] 21\n",
      "[17 31 81  0 74 60 35 89 77 21] 95\n",
      "[31 81  0 74 60 35 89 77 21 95] 45\n",
      "[81  0 74 60 35 89 77 21 95 45] 34\n",
      "[ 0 74 60 35 89 77 21 95 45 34] 73\n",
      "[74 60 35 89 77 21 95 45 34 73] 52\n",
      "[60 35 89 77 21 95 45 34 73 52] 93\n",
      "[35 89 77 21 95 45 34 73 52 93] 85\n",
      "[89 77 21 95 45 34 73 52 93 85] 12\n",
      "[77 21 95 45 34 73 52 93 85 12] 53\n",
      "[21 95 45 34 73 52 93 85 12 53] 76\n",
      "[95 45 34 73 52 93 85 12 53 76] 43\n",
      "[45 34 73 52 93 85 12 53 76 43] 59\n",
      "[34 73 52 93 85 12 53 76 43 59] 1\n",
      "[73 52 93 85 12 53 76 43 59  1] 61\n",
      "[52 93 85 12 53 76 43 59  1 61] 49\n",
      "[93 85 12 53 76 43 59  1 61 49] 23\n",
      "[85 12 53 76 43 59  1 61 49 23] 29\n",
      "[12 53 76 43 59  1 61 49 23 29] 64\n",
      "[53 76 43 59  1 61 49 23 29 64] 6\n",
      "[76 43 59  1 61 49 23 29 64  6] 31\n",
      "[43 59  1 61 49 23 29 64  6 31] 49\n",
      "[59  1 61 49 23 29 64  6 31 49] 1\n",
      "[ 1 61 49 23 29 64  6 31 49  1] 6\n",
      "[61 49 23 29 64  6 31 49  1  6] 89\n",
      "[49 23 29 64  6 31 49  1  6 89] 0\n",
      "[23 29 64  6 31 49  1  6 89  0] 19\n",
      "[29 64  6 31 49  1  6 89  0 19] 82\n",
      "[64  6 31 49  1  6 89  0 19 82] 91\n",
      "[ 6 31 49  1  6 89  0 19 82 91] 84\n",
      "[31 49  1  6 89  0 19 82 91 84] 87\n",
      "[49  1  6 89  0 19 82 91 84 87] 69\n",
      "[ 1  6 89  0 19 82 91 84 87 69] 29\n",
      "[ 6 89  0 19 82 91 84 87 69 29] 66\n",
      "[89  0 19 82 91 84 87 69 29 66] 68\n",
      "[ 0 19 82 91 84 87 69 29 66 68] 81\n",
      "[19 82 91 84 87 69 29 66 68 81] 15\n",
      "[82 91 84 87 69 29 66 68 81 15] 46\n",
      "[91 84 87 69 29 66 68 81 15 46] 52\n",
      "[84 87 69 29 66 68 81 15 46 52] 83\n",
      "[87 69 29 66 68 81 15 46 52 83] 91\n",
      "[69 29 66 68 81 15 46 52 83 91] 12\n",
      "[29 66 68 81 15 46 52 83 91 12] 80\n",
      "[66 68 81 15 46 52 83 91 12 80] 40\n",
      "[68 81 15 46 52 83 91 12 80 40] 32\n",
      "[81 15 46 52 83 91 12 80 40 32] 63\n",
      "[15 46 52 83 91 12 80 40 32 63] 78\n",
      "[46 52 83 91 12 80 40 32 63 78] 50\n",
      "[52 83 91 12 80 40 32 63 78 50] 53\n",
      "[83 91 12 80 40 32 63 78 50 53] 8\n",
      "[91 12 80 40 32 63 78 50 53  8] 49\n",
      "[12 80 40 32 63 78 50 53  8 49] 14\n",
      "[80 40 32 63 78 50 53  8 49 14] 12\n",
      "[40 32 63 78 50 53  8 49 14 12] 92\n",
      "[32 63 78 50 53  8 49 14 12 92] 39\n",
      "[63 78 50 53  8 49 14 12 92 39] 20\n",
      "[78 50 53  8 49 14 12 92 39 20] 0\n",
      "[50 53  8 49 14 12 92 39 20  0] 56\n",
      "[53  8 49 14 12 92 39 20  0 56] 31\n",
      "[ 8 49 14 12 92 39 20  0 56 31] 38\n",
      "[49 14 12 92 39 20  0 56 31 38] 2\n",
      "[14 12 92 39 20  0 56 31 38  2] 22\n",
      "[12 92 39 20  0 56 31 38  2 22] 34\n",
      "[92 39 20  0 56 31 38  2 22 34] 18\n",
      "[39 20  0 56 31 38  2 22 34 18] 45\n",
      "[20  0 56 31 38  2 22 34 18 45] 58\n",
      "[ 0 56 31 38  2 22 34 18 45 58] 86\n",
      "[56 31 38  2 22 34 18 45 58 86] 25\n",
      "[31 38  2 22 34 18 45 58 86 25] 8\n",
      "[38  2 22 34 18 45 58 86 25  8] 75\n",
      "[ 2 22 34 18 45 58 86 25  8 75] 54\n",
      "[22 34 18 45 58 86 25  8 75 54] 3\n",
      "[34 18 45 58 86 25  8 75 54  3] 99\n",
      "[18 45 58 86 25  8 75 54  3 99] 59\n",
      "[45 58 86 25  8 75 54  3 99 59] 33\n",
      "[58 86 25  8 75 54  3 99 59 33] 92\n",
      "[86 25  8 75 54  3 99 59 33 92] 36\n",
      "[25  8 75 54  3 99 59 33 92 36] 72\n",
      "[ 8 75 54  3 99 59 33 92 36 72] 93\n",
      "[75 54  3 99 59 33 92 36 72 93] 99\n",
      "[54  3 99 59 33 92 36 72 93 99] 82\n",
      "[ 3 99 59 33 92 36 72 93 99 82] 75\n",
      "[99 59 33 92 36 72 93 99 82 75] 19\n",
      "[59 33 92 36 72 93 99 82 75 19] 52\n",
      "[33 92 36 72 93 99 82 75 19 52] 75\n",
      "[92 36 72 93 99 82 75 19 52 75] 96\n",
      "[36 72 93 99 82 75 19 52 75 96] 0\n",
      "[72 93 99 82 75 19 52 75 96  0] 33\n",
      "[93 99 82 75 19 52 75 96  0 33] 8\n",
      "[99 82 75 19 52 75 96  0 33  8] 17\n",
      "[82 75 19 52 75 96  0 33  8 17] 99\n",
      "[75 19 52 75 96  0 33  8 17 99] 87\n",
      "[19 52 75 96  0 33  8 17 99 87] 21\n",
      "[52 75 96  0 33  8 17 99 87 21] 93\n",
      "[75 96  0 33  8 17 99 87 21 93] 60\n",
      "[96  0 33  8 17 99 87 21 93 60] 27\n",
      "[ 0 33  8 17 99 87 21 93 60 27] 22\n",
      "[33  8 17 99 87 21 93 60 27 22] 71\n",
      "[ 8 17 99 87 21 93 60 27 22 71] 15\n",
      "[17 99 87 21 93 60 27 22 71 15] 33\n",
      "[99 87 21 93 60 27 22 71 15 33] 97\n",
      "[87 21 93 60 27 22 71 15 33 97] 48\n",
      "[21 93 60 27 22 71 15 33 97 48] 25\n",
      "[93 60 27 22 71 15 33 97 48 25] 47\n",
      "[60 27 22 71 15 33 97 48 25 47] 5\n",
      "[27 22 71 15 33 97 48 25 47  5] 91\n",
      "[22 71 15 33 97 48 25 47  5 91] 8\n",
      "[71 15 33 97 48 25 47  5 91  8] 0\n",
      "[15 33 97 48 25 47  5 91  8  0] 67\n",
      "[33 97 48 25 47  5 91  8  0 67] 78\n",
      "[97 48 25 47  5 91  8  0 67 78] 30\n",
      "[48 25 47  5 91  8  0 67 78 30] 98\n",
      "[25 47  5 91  8  0 67 78 30 98] 97\n",
      "[47  5 91  8  0 67 78 30 98 97] 42\n",
      "[ 5 91  8  0 67 78 30 98 97 42] 89\n",
      "[91  8  0 67 78 30 98 97 42 89] 28\n",
      "[ 8  0 67 78 30 98 97 42 89 28] 79\n",
      "[ 0 67 78 30 98 97 42 89 28 79] 0\n",
      "[67 78 30 98 97 42 89 28 79  0] 86\n",
      "[78 30 98 97 42 89 28 79  0 86] 49\n",
      "[30 98 97 42 89 28 79  0 86 49] 26\n",
      "[98 97 42 89 28 79  0 86 49 26] 28\n",
      "[97 42 89 28 79  0 86 49 26 28] 100\n",
      "[ 42  89  28  79   0  86  49  26  28 100] 90\n",
      "[ 89  28  79   0  86  49  26  28 100  90] 92\n",
      "[ 28  79   0  86  49  26  28 100  90  92] 7\n",
      "[ 79   0  86  49  26  28 100  90  92   7] 73\n",
      "[  0  86  49  26  28 100  90  92   7  73] 14\n",
      "[ 86  49  26  28 100  90  92   7  73  14] 62\n",
      "[ 49  26  28 100  90  92   7  73  14  62] 40\n",
      "[ 26  28 100  90  92   7  73  14  62  40] 71\n",
      "[ 28 100  90  92   7  73  14  62  40  71] 0\n",
      "[100  90  92   7  73  14  62  40  71   0] 70\n",
      "[90 92  7 73 14 62 40 71  0 70] 42\n",
      "[92  7 73 14 62 40 71  0 70 42] 61\n",
      "[ 7 73 14 62 40 71  0 70 42 61] 8\n",
      "[73 14 62 40 71  0 70 42 61  8] 98\n",
      "[14 62 40 71  0 70 42 61  8 98] 47\n",
      "[62 40 71  0 70 42 61  8 98 47] 46\n",
      "[40 71  0 70 42 61  8 98 47 46] 24\n",
      "[71  0 70 42 61  8 98 47 46 24] 94\n",
      "[ 0 70 42 61  8 98 47 46 24 94] 32\n",
      "[70 42 61  8 98 47 46 24 94 32] 11\n",
      "[42 61  8 98 47 46 24 94 32 11] 84\n",
      "[61  8 98 47 46 24 94 32 11 84] 30\n",
      "[ 8 98 47 46 24 94 32 11 84 30] 67\n",
      "[98 47 46 24 94 32 11 84 30 67] 83\n",
      "[47 46 24 94 32 11 84 30 67 83] 0\n",
      "[46 24 94 32 11 84 30 67 83  0] 6\n",
      "[24 94 32 11 84 30 67 83  0  6] 49\n",
      "[94 32 11 84 30 67 83  0  6 49] 29\n",
      "[32 11 84 30 67 83  0  6 49 29] 6\n",
      "[11 84 30 67 83  0  6 49 29  6] 7\n",
      "[84 30 67 83  0  6 49 29  6  7] 17\n",
      "[30 67 83  0  6 49 29  6  7 17] 46\n",
      "[67 83  0  6 49 29  6  7 17 46] 47\n",
      "[83  0  6 49 29  6  7 17 46 47] 45\n",
      "[ 0  6 49 29  6  7 17 46 47 45] 43\n",
      "[ 6 49 29  6  7 17 46 47 45 43] 9\n",
      "[49 29  6  7 17 46 47 45 43  9] 78\n",
      "[29  6  7 17 46 47 45 43  9 78] 29\n",
      "[ 6  7 17 46 47 45 43  9 78 29] 2\n",
      "[ 7 17 46 47 45 43  9 78 29  2] 25\n",
      "[17 46 47 45 43  9 78 29  2 25] 64\n",
      "[46 47 45 43  9 78 29  2 25 64] 72\n",
      "[47 45 43  9 78 29  2 25 64 72] 29\n",
      "[45 43  9 78 29  2 25 64 72 29] 90\n",
      "[43  9 78 29  2 25 64 72 29 90] 13\n",
      "[ 9 78 29  2 25 64 72 29 90 13] 45\n",
      "[78 29  2 25 64 72 29 90 13 45] 81\n",
      "[29  2 25 64 72 29 90 13 45 81] 31\n",
      "[ 2 25 64 72 29 90 13 45 81 31] 73\n",
      "[25 64 72 29 90 13 45 81 31 73] 84\n",
      "[64 72 29 90 13 45 81 31 73 84] 21\n",
      "[72 29 90 13 45 81 31 73 84 21] 83\n",
      "[29 90 13 45 81 31 73 84 21 83] 73\n",
      "[90 13 45 81 31 73 84 21 83 73] 7\n",
      "[13 45 81 31 73 84 21 83 73  7] 28\n",
      "[45 81 31 73 84 21 83 73  7 28] 0\n",
      "[81 31 73 84 21 83 73  7 28  0] 85\n",
      "[31 73 84 21 83 73  7 28  0 85] 47\n",
      "[73 84 21 83 73  7 28  0 85 47] 70\n",
      "[84 21 83 73  7 28  0 85 47 70] 66\n",
      "[21 83 73  7 28  0 85 47 70 66] 5\n",
      "[83 73  7 28  0 85 47 70 66  5] 29\n",
      "[73  7 28  0 85 47 70 66  5 29] 3\n",
      "[ 7 28  0 85 47 70 66  5 29  3] 17\n",
      "[28  0 85 47 70 66  5 29  3 17] 85\n",
      "[ 0 85 47 70 66  5 29  3 17 85] 9\n",
      "[85 47 70 66  5 29  3 17 85  9] 72\n",
      "[47 70 66  5 29  3 17 85  9 72] 10\n",
      "[70 66  5 29  3 17 85  9 72 10] 67\n",
      "[66  5 29  3 17 85  9 72 10 67] 21\n",
      "[ 5 29  3 17 85  9 72 10 67 21] 42\n",
      "[29  3 17 85  9 72 10 67 21 42] 10\n",
      "[ 3 17 85  9 72 10 67 21 42 10] 87\n",
      "[17 85  9 72 10 67 21 42 10 87] 76\n",
      "[85  9 72 10 67 21 42 10 87 76] 84\n",
      "[ 9 72 10 67 21 42 10 87 76 84] 20\n",
      "[72 10 67 21 42 10 87 76 84 20] 78\n",
      "[10 67 21 42 10 87 76 84 20 78] 83\n",
      "[67 21 42 10 87 76 84 20 78 83] 36\n",
      "[21 42 10 87 76 84 20 78 83 36] 2\n",
      "[42 10 87 76 84 20 78 83 36  2] 60\n",
      "[10 87 76 84 20 78 83 36  2 60] 46\n",
      "[87 76 84 20 78 83 36  2 60 46] 68\n",
      "[76 84 20 78 83 36  2 60 46 68] 15\n",
      "[84 20 78 83 36  2 60 46 68 15] 24\n",
      "[20 78 83 36  2 60 46 68 15 24] 65\n",
      "[78 83 36  2 60 46 68 15 24 65] 0\n",
      "[83 36  2 60 46 68 15 24 65  0] 36\n",
      "[36  2 60 46 68 15 24 65  0 36] 9\n",
      "[ 2 60 46 68 15 24 65  0 36  9] 9\n",
      "[60 46 68 15 24 65  0 36  9  9] 67\n",
      "[46 68 15 24 65  0 36  9  9 67] 91\n",
      "[68 15 24 65  0 36  9  9 67 91] 91\n",
      "[15 24 65  0 36  9  9 67 91 91] 43\n",
      "[24 65  0 36  9  9 67 91 91 43] 62\n",
      "[65  0 36  9  9 67 91 91 43 62] 67\n",
      "[ 0 36  9  9 67 91 91 43 62 67] 97\n",
      "[36  9  9 67 91 91 43 62 67 97] 96\n",
      "[ 9  9 67 91 91 43 62 67 97 96] 87\n",
      "[ 9 67 91 91 43 62 67 97 96 87] 18\n",
      "[67 91 91 43 62 67 97 96 87 18] 10\n",
      "[91 91 43 62 67 97 96 87 18 10] 18\n",
      "[91 43 62 67 97 96 87 18 10 18] 78\n",
      "[43 62 67 97 96 87 18 10 18 78] 55\n",
      "[62 67 97 96 87 18 10 18 78 55] 90\n",
      "[67 97 96 87 18 10 18 78 55 90] 28\n",
      "[97 96 87 18 10 18 78 55 90 28] 92\n",
      "[96 87 18 10 18 78 55 90 28 92] 67\n",
      "[87 18 10 18 78 55 90 28 92 67] 16\n",
      "[18 10 18 78 55 90 28 92 67 16] 14\n",
      "[10 18 78 55 90 28 92 67 16 14] 97\n",
      "[18 78 55 90 28 92 67 16 14 97] 51\n",
      "[78 55 90 28 92 67 16 14 97 51] 97\n",
      "[55 90 28 92 67 16 14 97 51 97] 55\n",
      "[90 28 92 67 16 14 97 51 97 55] 0\n",
      "[28 92 67 16 14 97 51 97 55  0] 60\n",
      "[92 67 16 14 97 51 97 55  0 60] 9\n",
      "[67 16 14 97 51 97 55  0 60  9] 58\n",
      "[16 14 97 51 97 55  0 60  9 58] 81\n",
      "[14 97 51 97 55  0 60  9 58 81] 4\n",
      "[97 51 97 55  0 60  9 58 81  4] 16\n",
      "[51 97 55  0 60  9 58 81  4 16] 57\n",
      "[97 55  0 60  9 58 81  4 16 57] 30\n",
      "[55  0 60  9 58 81  4 16 57 30] 91\n",
      "[ 0 60  9 58 81  4 16 57 30 91] 5\n",
      "[60  9 58 81  4 16 57 30 91  5] 98\n",
      "[ 9 58 81  4 16 57 30 91  5 98] 64\n",
      "[58 81  4 16 57 30 91  5 98 64] 14\n",
      "[81  4 16 57 30 91  5 98 64 14] 72\n",
      "[ 4 16 57 30 91  5 98 64 14 72] 57\n",
      "[16 57 30 91  5 98 64 14 72 57] 85\n",
      "[57 30 91  5 98 64 14 72 57 85] 27\n",
      "[30 91  5 98 64 14 72 57 85 27] 80\n",
      "[91  5 98 64 14 72 57 85 27 80] 16\n",
      "[ 5 98 64 14 72 57 85 27 80 16] 1\n",
      "[98 64 14 72 57 85 27 80 16  1] 1\n",
      "[64 14 72 57 85 27 80 16  1  1] 8\n",
      "[14 72 57 85 27 80 16  1  1  8] 61\n",
      "[72 57 85 27 80 16  1  1  8 61] 54\n",
      "[57 85 27 80 16  1  1  8 61 54] 26\n",
      "[85 27 80 16  1  1  8 61 54 26] 23\n",
      "[27 80 16  1  1  8 61 54 26 23] 52\n",
      "[80 16  1  1  8 61 54 26 23 52] 73\n",
      "[16  1  1  8 61 54 26 23 52 73] 81\n",
      "[ 1  1  8 61 54 26 23 52 73 81] 47\n",
      "[ 1  8 61 54 26 23 52 73 81 47] 0\n",
      "[ 8 61 54 26 23 52 73 81 47  0] 22\n",
      "[61 54 26 23 52 73 81 47  0 22] 62\n",
      "[54 26 23 52 73 81 47  0 22 62] 1\n",
      "[26 23 52 73 81 47  0 22 62  1] 63\n",
      "[23 52 73 81 47  0 22 62  1 63] 30\n",
      "[52 73 81 47  0 22 62  1 63 30] 40\n",
      "[73 81 47  0 22 62  1 63 30 40] 40\n",
      "[81 47  0 22 62  1 63 30 40 40] 48\n",
      "[47  0 22 62  1 63 30 40 40 48] 42\n",
      "[ 0 22 62  1 63 30 40 40 48 42] 43\n",
      "[22 62  1 63 30 40 40 48 42 43] 28\n",
      "[62  1 63 30 40 40 48 42 43 28] 57\n",
      "[ 1 63 30 40 40 48 42 43 28 57] 53\n",
      "[63 30 40 40 48 42 43 28 57 53] 22\n",
      "[30 40 40 48 42 43 28 57 53 22] 93\n",
      "[40 40 48 42 43 28 57 53 22 93] 17\n",
      "[40 48 42 43 28 57 53 22 93 17] 55\n",
      "[48 42 43 28 57 53 22 93 17 55] 20\n",
      "[42 43 28 57 53 22 93 17 55 20] 63\n",
      "[43 28 57 53 22 93 17 55 20 63] 91\n",
      "[28 57 53 22 93 17 55 20 63 91] 63\n",
      "[57 53 22 93 17 55 20 63 91 63] 28\n",
      "[53 22 93 17 55 20 63 91 63 28] 49\n",
      "[22 93 17 55 20 63 91 63 28 49] 2\n",
      "[93 17 55 20 63 91 63 28 49  2] 94\n",
      "[17 55 20 63 91 63 28 49  2 94] 65\n",
      "[55 20 63 91 63 28 49  2 94 65] 84\n",
      "[20 63 91 63 28 49  2 94 65 84] 63\n",
      "[63 91 63 28 49  2 94 65 84 63] 42\n",
      "[91 63 28 49  2 94 65 84 63 42] 0\n",
      "[63 28 49  2 94 65 84 63 42  0] 29\n",
      "[28 49  2 94 65 84 63 42  0 29] 12\n",
      "[49  2 94 65 84 63 42  0 29 12] 99\n",
      "[ 2 94 65 84 63 42  0 29 12 99] 33\n",
      "[94 65 84 63 42  0 29 12 99 33] 53\n",
      "[65 84 63 42  0 29 12 99 33 53] 72\n",
      "[84 63 42  0 29 12 99 33 53 72] 68\n",
      "[63 42  0 29 12 99 33 53 72 68] 9\n",
      "[42  0 29 12 99 33 53 72 68  9] 69\n",
      "[ 0 29 12 99 33 53 72 68  9 69] 19\n",
      "[29 12 99 33 53 72 68  9 69 19] 42\n",
      "[12 99 33 53 72 68  9 69 19 42] 3\n",
      "[99 33 53 72 68  9 69 19 42  3] 82\n",
      "[33 53 72 68  9 69 19 42  3 82] 50\n",
      "[53 72 68  9 69 19 42  3 82 50] 0\n",
      "[72 68  9 69 19 42  3 82 50  0] 54\n",
      "[68  9 69 19 42  3 82 50  0 54] 43\n",
      "[ 9 69 19 42  3 82 50  0 54 43] 56\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 4]\n",
      "  [66]\n",
      "  [40]\n",
      "  [34]\n",
      "  [32]\n",
      "  [77]\n",
      "  [15]\n",
      "  [36]\n",
      "  [64]\n",
      "  [92]]\n",
      "\n",
      " [[66]\n",
      "  [40]\n",
      "  [34]\n",
      "  [32]\n",
      "  [77]\n",
      "  [15]\n",
      "  [36]\n",
      "  [64]\n",
      "  [92]\n",
      "  [ 5]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "model2.add(layers.LSTM(100, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model2.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.rnn.lstm.LSTM at 0x7fbb3c6b75d0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fbb3c6b7690>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 10ms/step - loss: 18663.0137 - accuracy: 0.0203\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1980.5190 - accuracy: 0.0122\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1151.3112 - accuracy: 0.0122\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1033.9058 - accuracy: 0.0122\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 964.3533 - accuracy: 0.0122\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1022.2039 - accuracy: 0.0122\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 964.3099 - accuracy: 0.0122\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 947.5341 - accuracy: 0.0122\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 946.2963 - accuracy: 0.0122\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 918.3176 - accuracy: 0.0122\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 907.3334 - accuracy: 0.0122\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 909.8330 - accuracy: 0.0122\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 912.8627 - accuracy: 0.0122\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 896.7718 - accuracy: 0.0122\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 891.2134 - accuracy: 0.0122\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 928.5854 - accuracy: 0.0122\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 948.0595 - accuracy: 0.0122\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 933.6420 - accuracy: 0.0122\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 908.9453 - accuracy: 0.0122\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 877.6354 - accuracy: 0.0122\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 889.1288 - accuracy: 0.0122\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 896.5363 - accuracy: 0.0122\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 914.0293 - accuracy: 0.0122\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 879.7466 - accuracy: 0.0122\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 878.8306 - accuracy: 0.0122\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 886.2522 - accuracy: 0.0122\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 893.5585 - accuracy: 0.0122\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 893.6276 - accuracy: 0.0122\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 901.3196 - accuracy: 0.0122\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 889.2450 - accuracy: 0.0122\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 881.7844 - accuracy: 0.0122\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 868.0169 - accuracy: 0.0122\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 862.4507 - accuracy: 0.0122\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 858.9855 - accuracy: 0.0122\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 933.0895 - accuracy: 0.0122\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 978.1351 - accuracy: 0.0122\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 938.9524 - accuracy: 0.0122\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 900.9678 - accuracy: 0.0122\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 895.0607 - accuracy: 0.0122\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 923.9917 - accuracy: 0.0122\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 880.1750 - accuracy: 0.0122\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 897.1216 - accuracy: 0.0122\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 882.2705 - accuracy: 0.0122\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 883.0454 - accuracy: 0.0122\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 865.2257 - accuracy: 0.0122\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 876.4229 - accuracy: 0.0122\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 866.5759 - accuracy: 0.0122\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 902.5356 - accuracy: 0.0122\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 895.0446 - accuracy: 0.0122\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 867.5640 - accuracy: 0.0122\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 879.3789 - accuracy: 0.0122\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 866.1650 - accuracy: 0.0122\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 878.3677 - accuracy: 0.0122\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 864.4146 - accuracy: 0.0122\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 880.1024 - accuracy: 0.0122\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 879.6505 - accuracy: 0.0122\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 890.5047 - accuracy: 0.0122\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 899.5220 - accuracy: 0.0122\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 874.1462 - accuracy: 0.0122\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 861.6398 - accuracy: 0.0122\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 861.1025 - accuracy: 0.0122\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 886.3748 - accuracy: 0.0122\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 889.2076 - accuracy: 0.0122\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 868.6310 - accuracy: 0.0122\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 873.8328 - accuracy: 0.0122\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 879.8263 - accuracy: 0.0122\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 893.0568 - accuracy: 0.0122\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 867.7354 - accuracy: 0.0122\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 886.6454 - accuracy: 0.0122\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 894.9944 - accuracy: 0.0122\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 889.0986 - accuracy: 0.0122\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 869.3052 - accuracy: 0.0122\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 875.5211 - accuracy: 0.0122\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 862.1057 - accuracy: 0.0122\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 864.2829 - accuracy: 0.0122\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 865.5065 - accuracy: 0.0122\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 843.1661 - accuracy: 0.0122\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 862.8763 - accuracy: 0.0122\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 856.5312 - accuracy: 0.0122\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 883.2166 - accuracy: 0.0122\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 862.8987 - accuracy: 0.0122\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 857.5326 - accuracy: 0.0122\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 852.3832 - accuracy: 0.0122\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 866.1714 - accuracy: 0.0122\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 841.2047 - accuracy: 0.0122\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 860.6066 - accuracy: 0.0122\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 853.5312 - accuracy: 0.0122\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 865.2753 - accuracy: 0.0122\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 847.1738 - accuracy: 0.0122\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 845.8740 - accuracy: 0.0122\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 865.1991 - accuracy: 0.0122\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 847.3163 - accuracy: 0.0122\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 849.5262 - accuracy: 0.0122\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 841.8538 - accuracy: 0.0122\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 846.3243 - accuracy: 0.0122\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 838.8231 - accuracy: 0.0122\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 856.7654 - accuracy: 0.0122\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 873.5645 - accuracy: 0.0122\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 848.2621 - accuracy: 0.0122\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 841.7795 - accuracy: 0.0122\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 837.2313 - accuracy: 0.0122\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 825.2791 - accuracy: 0.0122\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 836.1000 - accuracy: 0.0122\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 882.8104 - accuracy: 0.0122\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 864.4400 - accuracy: 0.0122\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 838.1038 - accuracy: 0.0122\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 845.9991 - accuracy: 0.0122\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 833.6990 - accuracy: 0.0122\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 851.3122 - accuracy: 0.0122\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 878.0262 - accuracy: 0.0122\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 872.0035 - accuracy: 0.0122\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 830.4771 - accuracy: 0.0122\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 837.3394 - accuracy: 0.0122\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 850.3251 - accuracy: 0.0122\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 805.6360 - accuracy: 0.0122\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 874.0709 - accuracy: 0.0122\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 883.7862 - accuracy: 0.0122\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 854.0757 - accuracy: 0.0122\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 935.9215 - accuracy: 0.0122\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 832.4067 - accuracy: 0.0122\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 831.9263 - accuracy: 0.0122\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 831.3271 - accuracy: 0.0122\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 854.2344 - accuracy: 0.0122\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 847.5007 - accuracy: 0.0122\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 850.9941 - accuracy: 0.0122\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 846.2057 - accuracy: 0.0122\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 863.1779 - accuracy: 0.0122\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 853.4669 - accuracy: 0.0122\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 815.0726 - accuracy: 0.0122\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 836.9216 - accuracy: 0.0122\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 821.9137 - accuracy: 0.0122\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 815.3370 - accuracy: 0.0122\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 804.1384 - accuracy: 0.0122\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 842.6292 - accuracy: 0.0122\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 819.6580 - accuracy: 0.0122\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 809.4244 - accuracy: 0.0122\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 874.4928 - accuracy: 0.0122\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 829.1660 - accuracy: 0.0122\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 826.1515 - accuracy: 0.0122\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 798.2963 - accuracy: 0.0122\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 858.1090 - accuracy: 0.0122\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 904.0646 - accuracy: 0.0122\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 877.0155 - accuracy: 0.0122\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 866.6249 - accuracy: 0.0122\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 846.5811 - accuracy: 0.0122\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 824.2734 - accuracy: 0.0122\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 852.4444 - accuracy: 0.0122\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 847.2889 - accuracy: 0.0122\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 869.3566 - accuracy: 0.0122\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 813.7243 - accuracy: 0.0122\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 891.1298 - accuracy: 0.0122\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 897.4377 - accuracy: 0.0122\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 879.5327 - accuracy: 0.0122\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 874.0607 - accuracy: 0.0122\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 908.3718 - accuracy: 0.0122\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 865.6982 - accuracy: 0.0122\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 879.8798 - accuracy: 0.0122\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 869.9805 - accuracy: 0.0122\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 875.7409 - accuracy: 0.0122\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 855.5671 - accuracy: 0.0122\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 866.5295 - accuracy: 0.0122\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 858.7874 - accuracy: 0.0122\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 838.5707 - accuracy: 0.0122\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 835.4471 - accuracy: 0.0122\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 850.5350 - accuracy: 0.0122\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 837.3900 - accuracy: 0.0122\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 828.9523 - accuracy: 0.0122\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 846.1934 - accuracy: 0.0122\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 831.0215 - accuracy: 0.0122\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 850.5574 - accuracy: 0.0122\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 846.2253 - accuracy: 0.0122\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 842.1530 - accuracy: 0.0122\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 858.6335 - accuracy: 0.0122\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 844.8277 - accuracy: 0.0122\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 824.3751 - accuracy: 0.0122\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 827.6531 - accuracy: 0.0122\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 826.5020 - accuracy: 0.0122\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 838.3702 - accuracy: 0.0122\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 819.0034 - accuracy: 0.0122\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 835.6571 - accuracy: 0.0122\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 815.9144 - accuracy: 0.0122\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 811.9443 - accuracy: 0.0122\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 833.8850 - accuracy: 0.0122\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 838.3164 - accuracy: 0.0122\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 810.4376 - accuracy: 0.0122\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 806.5050 - accuracy: 0.0122\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 802.9376 - accuracy: 0.0122\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 821.9450 - accuracy: 0.0122\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 805.6047 - accuracy: 0.0122\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 807.4857 - accuracy: 0.0122\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 813.2283 - accuracy: 0.0122\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 831.7825 - accuracy: 0.0122\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 849.0785 - accuracy: 0.0122\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 827.0844 - accuracy: 0.0122\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 823.6375 - accuracy: 0.0122\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 800.1776 - accuracy: 0.0122\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 812.5053 - accuracy: 0.0122\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 801.3896 - accuracy: 0.0122\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 807.4736 - accuracy: 0.0122\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 810.7306 - accuracy: 0.0122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb3c6e5290>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[69],\n",
       "        [19],\n",
       "        [42],\n",
       "        [ 3],\n",
       "        [82],\n",
       "        [50],\n",
       "        [ 0],\n",
       "        [54],\n",
       "        [43],\n",
       "        [56]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = arr1[-10:]\n",
    "test_data = test_data.reshape((1, n_steps, n_features))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 302ms/step\n",
      "[[43.698875]]\n"
     ]
    }
   ],
   "source": [
    "predictNextNumber = model2.predict(test_data, verbose=1)\n",
    "print(predictNextNumber)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f293f16398db128e85df277de8eb5f9ab0a1b28857fa0f1c8543245825f1b931"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
