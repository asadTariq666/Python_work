{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all essential libraries\n",
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "## Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>site off</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>88</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      MB033 MB034 MB035 MB036\n",
       "0 2021-01-01  site off     4    71    40\n",
       "1 2021-01-02        88    66    52    12\n",
       "2 2021-01-03        52    40    54    72\n",
       "3 2021-01-04        49    34    32    28\n",
       "4 2021-01-05        82    32    85    49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Book01.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>70</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  MB033 MB034 MB035 MB036\n",
       "495 2022-05-11    70    42     6     2\n",
       "496 2022-05-12    92     3    99    64\n",
       "497 2022-05-13    84    82    24    30\n",
       "498 2022-05-14    98    50    19    60\n",
       "499 2022-05-15     3     0    66    48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     0\n",
       "MB033    0\n",
       "MB034    0\n",
       "MB035    0\n",
       "MB036    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in train data\n",
    "df.isnull().sum()\n",
    " #No missing valuues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for better understanding of the data, We can eloborate as month and weekday wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      71\n",
       "1      52\n",
       "2      54\n",
       "3      32\n",
       "4      85\n",
       "       ..\n",
       "495     6\n",
       "496    99\n",
       "497    24\n",
       "498    19\n",
       "499    66\n",
       "Name: MB035, Length: 500, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MB035']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MB033'] = df['MB033'].replace(['site off'],0)\n",
    "df['MB034'] = df['MB034'].replace(['site off'],0)\n",
    "df['MB035'] = df['MB035'].replace(['site off'],0)\n",
    "df['MB036'] = df['MB036'].replace(['site off'],0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 71,  52,  54,  32,  85,  17,  71,  36,  16,  68,  12,   4,  68,\n",
       "        76,  38,  25,  38,  96,  97,  78,  73,  58,  11,  99,  38,  79,\n",
       "        17,  41,  13,  99,   0,  47,  99,  46,  70,  64,  64,  61,  21,\n",
       "         1,  78,   1, 100,  49,  42,  64,  73,   4,  95,  80,   7,  76,\n",
       "        72,  91,  63,  80,  80,  64,   0,  34,  16,   8,  28,  19,  55,\n",
       "        84,  82,  79,  44,  73,  99,  79,  65,  27,  62,  40,  48,  27,\n",
       "        83,  24,  13,  45,  53,   0,  69,  22,  60,  85,  65,   0,  77,\n",
       "        53,   2,  30,  93,  22,   4,  16,  70,  70,  80,  40,  76,  38,\n",
       "        89,  36,  92,  13,  29,  72,  87,  26,  75,   4,  89,  83,  53,\n",
       "        92,  25,   0,  29,  93,  96,  23,  26,  62,  58,  54,  19,  47,\n",
       "        64,  98,   3,  90,  53,  53,  10,  51,  14,   1,  50,  71,  60,\n",
       "        89,  82,   9,  43,  12,  39,  73,   0,  48,  18,  47,  98,  73,\n",
       "        43,  87,  11,  11,  98,  82,  46,  92,  17,  48,  64,  95,  61,\n",
       "        82,  36,  60,  31,  63,  59,  73,  32,  72,  24,  60,   0,  38,\n",
       "         8,  86,   5,  93,  94,  94,  59,  13,  85,  48,  13,  83,  54,\n",
       "        54,  24,  16,  29,  41,  83,  66,  17,  22,  88,  20,   1,  48,\n",
       "        99,  32,  86,   0,  56,   9,  68,  59,  95,  93,  32,  91,  47,\n",
       "        78,  80,  57,  50,   2,  34,  19,  23,  85,  18,  34,   8,  73,\n",
       "        59,  74,  53,  61,  29,  98,  59,  78,   0,   5,  14,   1,  53,\n",
       "        11,  41,  36,  20,  86,  31,   5,  65,  36,  91,  11,  84,  60,\n",
       "        84,  99,  45,  23,  96,  49,  39,  97,  54,  26,  56,  20,   0,\n",
       "        25,  44,  76,  95,  73,   0,  26,  57,  73,  33,  99,  52,  96,\n",
       "        88,  23,  63,  79,  47,   6,  16,   4,  84,  70,  90,  89,  36,\n",
       "        43,  49,  45,  78,   0,  43,   0,  29,  41,  97,  57,  58,  20,\n",
       "        88,  51,  62,  70,  16,   3,  66,  81,  80,  97,  62,  94,  42,\n",
       "        30,  50,  99,  93,  35,  24,  42,  65,   0,  69,  75,  71,   9,\n",
       "        45,  82,  33,  97,   6,   2,  77,  88,  74,  21,  69,  68,  61,\n",
       "        74,  51,  68,  34,  13,  46,  31,  86,  33,  83,  77,  85,  88,\n",
       "         0,  96,  30,  89,  56,   4,  80,   8,  47,  68,  31,  10,   4,\n",
       "        28,  57,  21,  77,  12,  44,  80,  70,  78,  10,  94,  10,   7,\n",
       "        58,  12,  85,  41,  51,   0,  44,  37,  49,  32,  97,  11,  25,\n",
       "        21,  90,  29,  84,  92,  91,  52,  28,  95,  72,  11,  96,  60,\n",
       "        35,  21,  17,  58,  37,   1,  89,   0,  49,   9,  81,  69,  38,\n",
       "         5,  57,  90,  77,  13,  34,  59,  95,  12,  45,  25,  84,  30,\n",
       "        87,  70,  60,  65,  77,  62,  66,  13,  73,  66,  43,  74,   0,\n",
       "        52,   0,  51,  19,  12,  80,  51,  36,  58,   6, 100,  45,  33,\n",
       "        20,  72,  71,  43,  67,  48,  53,  86,  20,   7,  93,  85,  48,\n",
       "        90,  28,  37,   0,  88,  34,  19, 100,  73,  89,  59,  52,  20,\n",
       "        74,   6,  99,  24,  19,  66])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = df['MB035'].values\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def splitSequence(seq, n_steps):\n",
    "    \n",
    "    #Declare X and y as empty list\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        #get the last index\n",
    "        lastIndex = i + n_steps\n",
    "        \n",
    "        #if lastIndex is greater than length of sequence then break\n",
    "        if lastIndex > len(seq) - 1:\n",
    "            break\n",
    "            \n",
    "        #Create input and output sequence\n",
    "        seq_X, seq_y = seq[i:lastIndex], seq[lastIndex]\n",
    "        \n",
    "        #append seq_X, seq_y in X and y list\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        pass\n",
    "    #Convert X and y into numpy array\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y \n",
    "    \n",
    "    pass\n",
    "\n",
    "n_steps = 15\n",
    "X, y = splitSequence(arr1, n_steps = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((485, 15), (485,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71 52 54 32 85 17 71 36 16 68 12  4 68 76 38] 25\n",
      "[52 54 32 85 17 71 36 16 68 12  4 68 76 38 25] 38\n",
      "[54 32 85 17 71 36 16 68 12  4 68 76 38 25 38] 96\n",
      "[32 85 17 71 36 16 68 12  4 68 76 38 25 38 96] 97\n",
      "[85 17 71 36 16 68 12  4 68 76 38 25 38 96 97] 78\n",
      "[17 71 36 16 68 12  4 68 76 38 25 38 96 97 78] 73\n",
      "[71 36 16 68 12  4 68 76 38 25 38 96 97 78 73] 58\n",
      "[36 16 68 12  4 68 76 38 25 38 96 97 78 73 58] 11\n",
      "[16 68 12  4 68 76 38 25 38 96 97 78 73 58 11] 99\n",
      "[68 12  4 68 76 38 25 38 96 97 78 73 58 11 99] 38\n",
      "[12  4 68 76 38 25 38 96 97 78 73 58 11 99 38] 79\n",
      "[ 4 68 76 38 25 38 96 97 78 73 58 11 99 38 79] 17\n",
      "[68 76 38 25 38 96 97 78 73 58 11 99 38 79 17] 41\n",
      "[76 38 25 38 96 97 78 73 58 11 99 38 79 17 41] 13\n",
      "[38 25 38 96 97 78 73 58 11 99 38 79 17 41 13] 99\n",
      "[25 38 96 97 78 73 58 11 99 38 79 17 41 13 99] 0\n",
      "[38 96 97 78 73 58 11 99 38 79 17 41 13 99  0] 47\n",
      "[96 97 78 73 58 11 99 38 79 17 41 13 99  0 47] 99\n",
      "[97 78 73 58 11 99 38 79 17 41 13 99  0 47 99] 46\n",
      "[78 73 58 11 99 38 79 17 41 13 99  0 47 99 46] 70\n",
      "[73 58 11 99 38 79 17 41 13 99  0 47 99 46 70] 64\n",
      "[58 11 99 38 79 17 41 13 99  0 47 99 46 70 64] 64\n",
      "[11 99 38 79 17 41 13 99  0 47 99 46 70 64 64] 61\n",
      "[99 38 79 17 41 13 99  0 47 99 46 70 64 64 61] 21\n",
      "[38 79 17 41 13 99  0 47 99 46 70 64 64 61 21] 1\n",
      "[79 17 41 13 99  0 47 99 46 70 64 64 61 21  1] 78\n",
      "[17 41 13 99  0 47 99 46 70 64 64 61 21  1 78] 1\n",
      "[41 13 99  0 47 99 46 70 64 64 61 21  1 78  1] 100\n",
      "[ 13  99   0  47  99  46  70  64  64  61  21   1  78   1 100] 49\n",
      "[ 99   0  47  99  46  70  64  64  61  21   1  78   1 100  49] 42\n",
      "[  0  47  99  46  70  64  64  61  21   1  78   1 100  49  42] 64\n",
      "[ 47  99  46  70  64  64  61  21   1  78   1 100  49  42  64] 73\n",
      "[ 99  46  70  64  64  61  21   1  78   1 100  49  42  64  73] 4\n",
      "[ 46  70  64  64  61  21   1  78   1 100  49  42  64  73   4] 95\n",
      "[ 70  64  64  61  21   1  78   1 100  49  42  64  73   4  95] 80\n",
      "[ 64  64  61  21   1  78   1 100  49  42  64  73   4  95  80] 7\n",
      "[ 64  61  21   1  78   1 100  49  42  64  73   4  95  80   7] 76\n",
      "[ 61  21   1  78   1 100  49  42  64  73   4  95  80   7  76] 72\n",
      "[ 21   1  78   1 100  49  42  64  73   4  95  80   7  76  72] 91\n",
      "[  1  78   1 100  49  42  64  73   4  95  80   7  76  72  91] 63\n",
      "[ 78   1 100  49  42  64  73   4  95  80   7  76  72  91  63] 80\n",
      "[  1 100  49  42  64  73   4  95  80   7  76  72  91  63  80] 80\n",
      "[100  49  42  64  73   4  95  80   7  76  72  91  63  80  80] 64\n",
      "[49 42 64 73  4 95 80  7 76 72 91 63 80 80 64] 0\n",
      "[42 64 73  4 95 80  7 76 72 91 63 80 80 64  0] 34\n",
      "[64 73  4 95 80  7 76 72 91 63 80 80 64  0 34] 16\n",
      "[73  4 95 80  7 76 72 91 63 80 80 64  0 34 16] 8\n",
      "[ 4 95 80  7 76 72 91 63 80 80 64  0 34 16  8] 28\n",
      "[95 80  7 76 72 91 63 80 80 64  0 34 16  8 28] 19\n",
      "[80  7 76 72 91 63 80 80 64  0 34 16  8 28 19] 55\n",
      "[ 7 76 72 91 63 80 80 64  0 34 16  8 28 19 55] 84\n",
      "[76 72 91 63 80 80 64  0 34 16  8 28 19 55 84] 82\n",
      "[72 91 63 80 80 64  0 34 16  8 28 19 55 84 82] 79\n",
      "[91 63 80 80 64  0 34 16  8 28 19 55 84 82 79] 44\n",
      "[63 80 80 64  0 34 16  8 28 19 55 84 82 79 44] 73\n",
      "[80 80 64  0 34 16  8 28 19 55 84 82 79 44 73] 99\n",
      "[80 64  0 34 16  8 28 19 55 84 82 79 44 73 99] 79\n",
      "[64  0 34 16  8 28 19 55 84 82 79 44 73 99 79] 65\n",
      "[ 0 34 16  8 28 19 55 84 82 79 44 73 99 79 65] 27\n",
      "[34 16  8 28 19 55 84 82 79 44 73 99 79 65 27] 62\n",
      "[16  8 28 19 55 84 82 79 44 73 99 79 65 27 62] 40\n",
      "[ 8 28 19 55 84 82 79 44 73 99 79 65 27 62 40] 48\n",
      "[28 19 55 84 82 79 44 73 99 79 65 27 62 40 48] 27\n",
      "[19 55 84 82 79 44 73 99 79 65 27 62 40 48 27] 83\n",
      "[55 84 82 79 44 73 99 79 65 27 62 40 48 27 83] 24\n",
      "[84 82 79 44 73 99 79 65 27 62 40 48 27 83 24] 13\n",
      "[82 79 44 73 99 79 65 27 62 40 48 27 83 24 13] 45\n",
      "[79 44 73 99 79 65 27 62 40 48 27 83 24 13 45] 53\n",
      "[44 73 99 79 65 27 62 40 48 27 83 24 13 45 53] 0\n",
      "[73 99 79 65 27 62 40 48 27 83 24 13 45 53  0] 69\n",
      "[99 79 65 27 62 40 48 27 83 24 13 45 53  0 69] 22\n",
      "[79 65 27 62 40 48 27 83 24 13 45 53  0 69 22] 60\n",
      "[65 27 62 40 48 27 83 24 13 45 53  0 69 22 60] 85\n",
      "[27 62 40 48 27 83 24 13 45 53  0 69 22 60 85] 65\n",
      "[62 40 48 27 83 24 13 45 53  0 69 22 60 85 65] 0\n",
      "[40 48 27 83 24 13 45 53  0 69 22 60 85 65  0] 77\n",
      "[48 27 83 24 13 45 53  0 69 22 60 85 65  0 77] 53\n",
      "[27 83 24 13 45 53  0 69 22 60 85 65  0 77 53] 2\n",
      "[83 24 13 45 53  0 69 22 60 85 65  0 77 53  2] 30\n",
      "[24 13 45 53  0 69 22 60 85 65  0 77 53  2 30] 93\n",
      "[13 45 53  0 69 22 60 85 65  0 77 53  2 30 93] 22\n",
      "[45 53  0 69 22 60 85 65  0 77 53  2 30 93 22] 4\n",
      "[53  0 69 22 60 85 65  0 77 53  2 30 93 22  4] 16\n",
      "[ 0 69 22 60 85 65  0 77 53  2 30 93 22  4 16] 70\n",
      "[69 22 60 85 65  0 77 53  2 30 93 22  4 16 70] 70\n",
      "[22 60 85 65  0 77 53  2 30 93 22  4 16 70 70] 80\n",
      "[60 85 65  0 77 53  2 30 93 22  4 16 70 70 80] 40\n",
      "[85 65  0 77 53  2 30 93 22  4 16 70 70 80 40] 76\n",
      "[65  0 77 53  2 30 93 22  4 16 70 70 80 40 76] 38\n",
      "[ 0 77 53  2 30 93 22  4 16 70 70 80 40 76 38] 89\n",
      "[77 53  2 30 93 22  4 16 70 70 80 40 76 38 89] 36\n",
      "[53  2 30 93 22  4 16 70 70 80 40 76 38 89 36] 92\n",
      "[ 2 30 93 22  4 16 70 70 80 40 76 38 89 36 92] 13\n",
      "[30 93 22  4 16 70 70 80 40 76 38 89 36 92 13] 29\n",
      "[93 22  4 16 70 70 80 40 76 38 89 36 92 13 29] 72\n",
      "[22  4 16 70 70 80 40 76 38 89 36 92 13 29 72] 87\n",
      "[ 4 16 70 70 80 40 76 38 89 36 92 13 29 72 87] 26\n",
      "[16 70 70 80 40 76 38 89 36 92 13 29 72 87 26] 75\n",
      "[70 70 80 40 76 38 89 36 92 13 29 72 87 26 75] 4\n",
      "[70 80 40 76 38 89 36 92 13 29 72 87 26 75  4] 89\n",
      "[80 40 76 38 89 36 92 13 29 72 87 26 75  4 89] 83\n",
      "[40 76 38 89 36 92 13 29 72 87 26 75  4 89 83] 53\n",
      "[76 38 89 36 92 13 29 72 87 26 75  4 89 83 53] 92\n",
      "[38 89 36 92 13 29 72 87 26 75  4 89 83 53 92] 25\n",
      "[89 36 92 13 29 72 87 26 75  4 89 83 53 92 25] 0\n",
      "[36 92 13 29 72 87 26 75  4 89 83 53 92 25  0] 29\n",
      "[92 13 29 72 87 26 75  4 89 83 53 92 25  0 29] 93\n",
      "[13 29 72 87 26 75  4 89 83 53 92 25  0 29 93] 96\n",
      "[29 72 87 26 75  4 89 83 53 92 25  0 29 93 96] 23\n",
      "[72 87 26 75  4 89 83 53 92 25  0 29 93 96 23] 26\n",
      "[87 26 75  4 89 83 53 92 25  0 29 93 96 23 26] 62\n",
      "[26 75  4 89 83 53 92 25  0 29 93 96 23 26 62] 58\n",
      "[75  4 89 83 53 92 25  0 29 93 96 23 26 62 58] 54\n",
      "[ 4 89 83 53 92 25  0 29 93 96 23 26 62 58 54] 19\n",
      "[89 83 53 92 25  0 29 93 96 23 26 62 58 54 19] 47\n",
      "[83 53 92 25  0 29 93 96 23 26 62 58 54 19 47] 64\n",
      "[53 92 25  0 29 93 96 23 26 62 58 54 19 47 64] 98\n",
      "[92 25  0 29 93 96 23 26 62 58 54 19 47 64 98] 3\n",
      "[25  0 29 93 96 23 26 62 58 54 19 47 64 98  3] 90\n",
      "[ 0 29 93 96 23 26 62 58 54 19 47 64 98  3 90] 53\n",
      "[29 93 96 23 26 62 58 54 19 47 64 98  3 90 53] 53\n",
      "[93 96 23 26 62 58 54 19 47 64 98  3 90 53 53] 10\n",
      "[96 23 26 62 58 54 19 47 64 98  3 90 53 53 10] 51\n",
      "[23 26 62 58 54 19 47 64 98  3 90 53 53 10 51] 14\n",
      "[26 62 58 54 19 47 64 98  3 90 53 53 10 51 14] 1\n",
      "[62 58 54 19 47 64 98  3 90 53 53 10 51 14  1] 50\n",
      "[58 54 19 47 64 98  3 90 53 53 10 51 14  1 50] 71\n",
      "[54 19 47 64 98  3 90 53 53 10 51 14  1 50 71] 60\n",
      "[19 47 64 98  3 90 53 53 10 51 14  1 50 71 60] 89\n",
      "[47 64 98  3 90 53 53 10 51 14  1 50 71 60 89] 82\n",
      "[64 98  3 90 53 53 10 51 14  1 50 71 60 89 82] 9\n",
      "[98  3 90 53 53 10 51 14  1 50 71 60 89 82  9] 43\n",
      "[ 3 90 53 53 10 51 14  1 50 71 60 89 82  9 43] 12\n",
      "[90 53 53 10 51 14  1 50 71 60 89 82  9 43 12] 39\n",
      "[53 53 10 51 14  1 50 71 60 89 82  9 43 12 39] 73\n",
      "[53 10 51 14  1 50 71 60 89 82  9 43 12 39 73] 0\n",
      "[10 51 14  1 50 71 60 89 82  9 43 12 39 73  0] 48\n",
      "[51 14  1 50 71 60 89 82  9 43 12 39 73  0 48] 18\n",
      "[14  1 50 71 60 89 82  9 43 12 39 73  0 48 18] 47\n",
      "[ 1 50 71 60 89 82  9 43 12 39 73  0 48 18 47] 98\n",
      "[50 71 60 89 82  9 43 12 39 73  0 48 18 47 98] 73\n",
      "[71 60 89 82  9 43 12 39 73  0 48 18 47 98 73] 43\n",
      "[60 89 82  9 43 12 39 73  0 48 18 47 98 73 43] 87\n",
      "[89 82  9 43 12 39 73  0 48 18 47 98 73 43 87] 11\n",
      "[82  9 43 12 39 73  0 48 18 47 98 73 43 87 11] 11\n",
      "[ 9 43 12 39 73  0 48 18 47 98 73 43 87 11 11] 98\n",
      "[43 12 39 73  0 48 18 47 98 73 43 87 11 11 98] 82\n",
      "[12 39 73  0 48 18 47 98 73 43 87 11 11 98 82] 46\n",
      "[39 73  0 48 18 47 98 73 43 87 11 11 98 82 46] 92\n",
      "[73  0 48 18 47 98 73 43 87 11 11 98 82 46 92] 17\n",
      "[ 0 48 18 47 98 73 43 87 11 11 98 82 46 92 17] 48\n",
      "[48 18 47 98 73 43 87 11 11 98 82 46 92 17 48] 64\n",
      "[18 47 98 73 43 87 11 11 98 82 46 92 17 48 64] 95\n",
      "[47 98 73 43 87 11 11 98 82 46 92 17 48 64 95] 61\n",
      "[98 73 43 87 11 11 98 82 46 92 17 48 64 95 61] 82\n",
      "[73 43 87 11 11 98 82 46 92 17 48 64 95 61 82] 36\n",
      "[43 87 11 11 98 82 46 92 17 48 64 95 61 82 36] 60\n",
      "[87 11 11 98 82 46 92 17 48 64 95 61 82 36 60] 31\n",
      "[11 11 98 82 46 92 17 48 64 95 61 82 36 60 31] 63\n",
      "[11 98 82 46 92 17 48 64 95 61 82 36 60 31 63] 59\n",
      "[98 82 46 92 17 48 64 95 61 82 36 60 31 63 59] 73\n",
      "[82 46 92 17 48 64 95 61 82 36 60 31 63 59 73] 32\n",
      "[46 92 17 48 64 95 61 82 36 60 31 63 59 73 32] 72\n",
      "[92 17 48 64 95 61 82 36 60 31 63 59 73 32 72] 24\n",
      "[17 48 64 95 61 82 36 60 31 63 59 73 32 72 24] 60\n",
      "[48 64 95 61 82 36 60 31 63 59 73 32 72 24 60] 0\n",
      "[64 95 61 82 36 60 31 63 59 73 32 72 24 60  0] 38\n",
      "[95 61 82 36 60 31 63 59 73 32 72 24 60  0 38] 8\n",
      "[61 82 36 60 31 63 59 73 32 72 24 60  0 38  8] 86\n",
      "[82 36 60 31 63 59 73 32 72 24 60  0 38  8 86] 5\n",
      "[36 60 31 63 59 73 32 72 24 60  0 38  8 86  5] 93\n",
      "[60 31 63 59 73 32 72 24 60  0 38  8 86  5 93] 94\n",
      "[31 63 59 73 32 72 24 60  0 38  8 86  5 93 94] 94\n",
      "[63 59 73 32 72 24 60  0 38  8 86  5 93 94 94] 59\n",
      "[59 73 32 72 24 60  0 38  8 86  5 93 94 94 59] 13\n",
      "[73 32 72 24 60  0 38  8 86  5 93 94 94 59 13] 85\n",
      "[32 72 24 60  0 38  8 86  5 93 94 94 59 13 85] 48\n",
      "[72 24 60  0 38  8 86  5 93 94 94 59 13 85 48] 13\n",
      "[24 60  0 38  8 86  5 93 94 94 59 13 85 48 13] 83\n",
      "[60  0 38  8 86  5 93 94 94 59 13 85 48 13 83] 54\n",
      "[ 0 38  8 86  5 93 94 94 59 13 85 48 13 83 54] 54\n",
      "[38  8 86  5 93 94 94 59 13 85 48 13 83 54 54] 24\n",
      "[ 8 86  5 93 94 94 59 13 85 48 13 83 54 54 24] 16\n",
      "[86  5 93 94 94 59 13 85 48 13 83 54 54 24 16] 29\n",
      "[ 5 93 94 94 59 13 85 48 13 83 54 54 24 16 29] 41\n",
      "[93 94 94 59 13 85 48 13 83 54 54 24 16 29 41] 83\n",
      "[94 94 59 13 85 48 13 83 54 54 24 16 29 41 83] 66\n",
      "[94 59 13 85 48 13 83 54 54 24 16 29 41 83 66] 17\n",
      "[59 13 85 48 13 83 54 54 24 16 29 41 83 66 17] 22\n",
      "[13 85 48 13 83 54 54 24 16 29 41 83 66 17 22] 88\n",
      "[85 48 13 83 54 54 24 16 29 41 83 66 17 22 88] 20\n",
      "[48 13 83 54 54 24 16 29 41 83 66 17 22 88 20] 1\n",
      "[13 83 54 54 24 16 29 41 83 66 17 22 88 20  1] 48\n",
      "[83 54 54 24 16 29 41 83 66 17 22 88 20  1 48] 99\n",
      "[54 54 24 16 29 41 83 66 17 22 88 20  1 48 99] 32\n",
      "[54 24 16 29 41 83 66 17 22 88 20  1 48 99 32] 86\n",
      "[24 16 29 41 83 66 17 22 88 20  1 48 99 32 86] 0\n",
      "[16 29 41 83 66 17 22 88 20  1 48 99 32 86  0] 56\n",
      "[29 41 83 66 17 22 88 20  1 48 99 32 86  0 56] 9\n",
      "[41 83 66 17 22 88 20  1 48 99 32 86  0 56  9] 68\n",
      "[83 66 17 22 88 20  1 48 99 32 86  0 56  9 68] 59\n",
      "[66 17 22 88 20  1 48 99 32 86  0 56  9 68 59] 95\n",
      "[17 22 88 20  1 48 99 32 86  0 56  9 68 59 95] 93\n",
      "[22 88 20  1 48 99 32 86  0 56  9 68 59 95 93] 32\n",
      "[88 20  1 48 99 32 86  0 56  9 68 59 95 93 32] 91\n",
      "[20  1 48 99 32 86  0 56  9 68 59 95 93 32 91] 47\n",
      "[ 1 48 99 32 86  0 56  9 68 59 95 93 32 91 47] 78\n",
      "[48 99 32 86  0 56  9 68 59 95 93 32 91 47 78] 80\n",
      "[99 32 86  0 56  9 68 59 95 93 32 91 47 78 80] 57\n",
      "[32 86  0 56  9 68 59 95 93 32 91 47 78 80 57] 50\n",
      "[86  0 56  9 68 59 95 93 32 91 47 78 80 57 50] 2\n",
      "[ 0 56  9 68 59 95 93 32 91 47 78 80 57 50  2] 34\n",
      "[56  9 68 59 95 93 32 91 47 78 80 57 50  2 34] 19\n",
      "[ 9 68 59 95 93 32 91 47 78 80 57 50  2 34 19] 23\n",
      "[68 59 95 93 32 91 47 78 80 57 50  2 34 19 23] 85\n",
      "[59 95 93 32 91 47 78 80 57 50  2 34 19 23 85] 18\n",
      "[95 93 32 91 47 78 80 57 50  2 34 19 23 85 18] 34\n",
      "[93 32 91 47 78 80 57 50  2 34 19 23 85 18 34] 8\n",
      "[32 91 47 78 80 57 50  2 34 19 23 85 18 34  8] 73\n",
      "[91 47 78 80 57 50  2 34 19 23 85 18 34  8 73] 59\n",
      "[47 78 80 57 50  2 34 19 23 85 18 34  8 73 59] 74\n",
      "[78 80 57 50  2 34 19 23 85 18 34  8 73 59 74] 53\n",
      "[80 57 50  2 34 19 23 85 18 34  8 73 59 74 53] 61\n",
      "[57 50  2 34 19 23 85 18 34  8 73 59 74 53 61] 29\n",
      "[50  2 34 19 23 85 18 34  8 73 59 74 53 61 29] 98\n",
      "[ 2 34 19 23 85 18 34  8 73 59 74 53 61 29 98] 59\n",
      "[34 19 23 85 18 34  8 73 59 74 53 61 29 98 59] 78\n",
      "[19 23 85 18 34  8 73 59 74 53 61 29 98 59 78] 0\n",
      "[23 85 18 34  8 73 59 74 53 61 29 98 59 78  0] 5\n",
      "[85 18 34  8 73 59 74 53 61 29 98 59 78  0  5] 14\n",
      "[18 34  8 73 59 74 53 61 29 98 59 78  0  5 14] 1\n",
      "[34  8 73 59 74 53 61 29 98 59 78  0  5 14  1] 53\n",
      "[ 8 73 59 74 53 61 29 98 59 78  0  5 14  1 53] 11\n",
      "[73 59 74 53 61 29 98 59 78  0  5 14  1 53 11] 41\n",
      "[59 74 53 61 29 98 59 78  0  5 14  1 53 11 41] 36\n",
      "[74 53 61 29 98 59 78  0  5 14  1 53 11 41 36] 20\n",
      "[53 61 29 98 59 78  0  5 14  1 53 11 41 36 20] 86\n",
      "[61 29 98 59 78  0  5 14  1 53 11 41 36 20 86] 31\n",
      "[29 98 59 78  0  5 14  1 53 11 41 36 20 86 31] 5\n",
      "[98 59 78  0  5 14  1 53 11 41 36 20 86 31  5] 65\n",
      "[59 78  0  5 14  1 53 11 41 36 20 86 31  5 65] 36\n",
      "[78  0  5 14  1 53 11 41 36 20 86 31  5 65 36] 91\n",
      "[ 0  5 14  1 53 11 41 36 20 86 31  5 65 36 91] 11\n",
      "[ 5 14  1 53 11 41 36 20 86 31  5 65 36 91 11] 84\n",
      "[14  1 53 11 41 36 20 86 31  5 65 36 91 11 84] 60\n",
      "[ 1 53 11 41 36 20 86 31  5 65 36 91 11 84 60] 84\n",
      "[53 11 41 36 20 86 31  5 65 36 91 11 84 60 84] 99\n",
      "[11 41 36 20 86 31  5 65 36 91 11 84 60 84 99] 45\n",
      "[41 36 20 86 31  5 65 36 91 11 84 60 84 99 45] 23\n",
      "[36 20 86 31  5 65 36 91 11 84 60 84 99 45 23] 96\n",
      "[20 86 31  5 65 36 91 11 84 60 84 99 45 23 96] 49\n",
      "[86 31  5 65 36 91 11 84 60 84 99 45 23 96 49] 39\n",
      "[31  5 65 36 91 11 84 60 84 99 45 23 96 49 39] 97\n",
      "[ 5 65 36 91 11 84 60 84 99 45 23 96 49 39 97] 54\n",
      "[65 36 91 11 84 60 84 99 45 23 96 49 39 97 54] 26\n",
      "[36 91 11 84 60 84 99 45 23 96 49 39 97 54 26] 56\n",
      "[91 11 84 60 84 99 45 23 96 49 39 97 54 26 56] 20\n",
      "[11 84 60 84 99 45 23 96 49 39 97 54 26 56 20] 0\n",
      "[84 60 84 99 45 23 96 49 39 97 54 26 56 20  0] 25\n",
      "[60 84 99 45 23 96 49 39 97 54 26 56 20  0 25] 44\n",
      "[84 99 45 23 96 49 39 97 54 26 56 20  0 25 44] 76\n",
      "[99 45 23 96 49 39 97 54 26 56 20  0 25 44 76] 95\n",
      "[45 23 96 49 39 97 54 26 56 20  0 25 44 76 95] 73\n",
      "[23 96 49 39 97 54 26 56 20  0 25 44 76 95 73] 0\n",
      "[96 49 39 97 54 26 56 20  0 25 44 76 95 73  0] 26\n",
      "[49 39 97 54 26 56 20  0 25 44 76 95 73  0 26] 57\n",
      "[39 97 54 26 56 20  0 25 44 76 95 73  0 26 57] 73\n",
      "[97 54 26 56 20  0 25 44 76 95 73  0 26 57 73] 33\n",
      "[54 26 56 20  0 25 44 76 95 73  0 26 57 73 33] 99\n",
      "[26 56 20  0 25 44 76 95 73  0 26 57 73 33 99] 52\n",
      "[56 20  0 25 44 76 95 73  0 26 57 73 33 99 52] 96\n",
      "[20  0 25 44 76 95 73  0 26 57 73 33 99 52 96] 88\n",
      "[ 0 25 44 76 95 73  0 26 57 73 33 99 52 96 88] 23\n",
      "[25 44 76 95 73  0 26 57 73 33 99 52 96 88 23] 63\n",
      "[44 76 95 73  0 26 57 73 33 99 52 96 88 23 63] 79\n",
      "[76 95 73  0 26 57 73 33 99 52 96 88 23 63 79] 47\n",
      "[95 73  0 26 57 73 33 99 52 96 88 23 63 79 47] 6\n",
      "[73  0 26 57 73 33 99 52 96 88 23 63 79 47  6] 16\n",
      "[ 0 26 57 73 33 99 52 96 88 23 63 79 47  6 16] 4\n",
      "[26 57 73 33 99 52 96 88 23 63 79 47  6 16  4] 84\n",
      "[57 73 33 99 52 96 88 23 63 79 47  6 16  4 84] 70\n",
      "[73 33 99 52 96 88 23 63 79 47  6 16  4 84 70] 90\n",
      "[33 99 52 96 88 23 63 79 47  6 16  4 84 70 90] 89\n",
      "[99 52 96 88 23 63 79 47  6 16  4 84 70 90 89] 36\n",
      "[52 96 88 23 63 79 47  6 16  4 84 70 90 89 36] 43\n",
      "[96 88 23 63 79 47  6 16  4 84 70 90 89 36 43] 49\n",
      "[88 23 63 79 47  6 16  4 84 70 90 89 36 43 49] 45\n",
      "[23 63 79 47  6 16  4 84 70 90 89 36 43 49 45] 78\n",
      "[63 79 47  6 16  4 84 70 90 89 36 43 49 45 78] 0\n",
      "[79 47  6 16  4 84 70 90 89 36 43 49 45 78  0] 43\n",
      "[47  6 16  4 84 70 90 89 36 43 49 45 78  0 43] 0\n",
      "[ 6 16  4 84 70 90 89 36 43 49 45 78  0 43  0] 29\n",
      "[16  4 84 70 90 89 36 43 49 45 78  0 43  0 29] 41\n",
      "[ 4 84 70 90 89 36 43 49 45 78  0 43  0 29 41] 97\n",
      "[84 70 90 89 36 43 49 45 78  0 43  0 29 41 97] 57\n",
      "[70 90 89 36 43 49 45 78  0 43  0 29 41 97 57] 58\n",
      "[90 89 36 43 49 45 78  0 43  0 29 41 97 57 58] 20\n",
      "[89 36 43 49 45 78  0 43  0 29 41 97 57 58 20] 88\n",
      "[36 43 49 45 78  0 43  0 29 41 97 57 58 20 88] 51\n",
      "[43 49 45 78  0 43  0 29 41 97 57 58 20 88 51] 62\n",
      "[49 45 78  0 43  0 29 41 97 57 58 20 88 51 62] 70\n",
      "[45 78  0 43  0 29 41 97 57 58 20 88 51 62 70] 16\n",
      "[78  0 43  0 29 41 97 57 58 20 88 51 62 70 16] 3\n",
      "[ 0 43  0 29 41 97 57 58 20 88 51 62 70 16  3] 66\n",
      "[43  0 29 41 97 57 58 20 88 51 62 70 16  3 66] 81\n",
      "[ 0 29 41 97 57 58 20 88 51 62 70 16  3 66 81] 80\n",
      "[29 41 97 57 58 20 88 51 62 70 16  3 66 81 80] 97\n",
      "[41 97 57 58 20 88 51 62 70 16  3 66 81 80 97] 62\n",
      "[97 57 58 20 88 51 62 70 16  3 66 81 80 97 62] 94\n",
      "[57 58 20 88 51 62 70 16  3 66 81 80 97 62 94] 42\n",
      "[58 20 88 51 62 70 16  3 66 81 80 97 62 94 42] 30\n",
      "[20 88 51 62 70 16  3 66 81 80 97 62 94 42 30] 50\n",
      "[88 51 62 70 16  3 66 81 80 97 62 94 42 30 50] 99\n",
      "[51 62 70 16  3 66 81 80 97 62 94 42 30 50 99] 93\n",
      "[62 70 16  3 66 81 80 97 62 94 42 30 50 99 93] 35\n",
      "[70 16  3 66 81 80 97 62 94 42 30 50 99 93 35] 24\n",
      "[16  3 66 81 80 97 62 94 42 30 50 99 93 35 24] 42\n",
      "[ 3 66 81 80 97 62 94 42 30 50 99 93 35 24 42] 65\n",
      "[66 81 80 97 62 94 42 30 50 99 93 35 24 42 65] 0\n",
      "[81 80 97 62 94 42 30 50 99 93 35 24 42 65  0] 69\n",
      "[80 97 62 94 42 30 50 99 93 35 24 42 65  0 69] 75\n",
      "[97 62 94 42 30 50 99 93 35 24 42 65  0 69 75] 71\n",
      "[62 94 42 30 50 99 93 35 24 42 65  0 69 75 71] 9\n",
      "[94 42 30 50 99 93 35 24 42 65  0 69 75 71  9] 45\n",
      "[42 30 50 99 93 35 24 42 65  0 69 75 71  9 45] 82\n",
      "[30 50 99 93 35 24 42 65  0 69 75 71  9 45 82] 33\n",
      "[50 99 93 35 24 42 65  0 69 75 71  9 45 82 33] 97\n",
      "[99 93 35 24 42 65  0 69 75 71  9 45 82 33 97] 6\n",
      "[93 35 24 42 65  0 69 75 71  9 45 82 33 97  6] 2\n",
      "[35 24 42 65  0 69 75 71  9 45 82 33 97  6  2] 77\n",
      "[24 42 65  0 69 75 71  9 45 82 33 97  6  2 77] 88\n",
      "[42 65  0 69 75 71  9 45 82 33 97  6  2 77 88] 74\n",
      "[65  0 69 75 71  9 45 82 33 97  6  2 77 88 74] 21\n",
      "[ 0 69 75 71  9 45 82 33 97  6  2 77 88 74 21] 69\n",
      "[69 75 71  9 45 82 33 97  6  2 77 88 74 21 69] 68\n",
      "[75 71  9 45 82 33 97  6  2 77 88 74 21 69 68] 61\n",
      "[71  9 45 82 33 97  6  2 77 88 74 21 69 68 61] 74\n",
      "[ 9 45 82 33 97  6  2 77 88 74 21 69 68 61 74] 51\n",
      "[45 82 33 97  6  2 77 88 74 21 69 68 61 74 51] 68\n",
      "[82 33 97  6  2 77 88 74 21 69 68 61 74 51 68] 34\n",
      "[33 97  6  2 77 88 74 21 69 68 61 74 51 68 34] 13\n",
      "[97  6  2 77 88 74 21 69 68 61 74 51 68 34 13] 46\n",
      "[ 6  2 77 88 74 21 69 68 61 74 51 68 34 13 46] 31\n",
      "[ 2 77 88 74 21 69 68 61 74 51 68 34 13 46 31] 86\n",
      "[77 88 74 21 69 68 61 74 51 68 34 13 46 31 86] 33\n",
      "[88 74 21 69 68 61 74 51 68 34 13 46 31 86 33] 83\n",
      "[74 21 69 68 61 74 51 68 34 13 46 31 86 33 83] 77\n",
      "[21 69 68 61 74 51 68 34 13 46 31 86 33 83 77] 85\n",
      "[69 68 61 74 51 68 34 13 46 31 86 33 83 77 85] 88\n",
      "[68 61 74 51 68 34 13 46 31 86 33 83 77 85 88] 0\n",
      "[61 74 51 68 34 13 46 31 86 33 83 77 85 88  0] 96\n",
      "[74 51 68 34 13 46 31 86 33 83 77 85 88  0 96] 30\n",
      "[51 68 34 13 46 31 86 33 83 77 85 88  0 96 30] 89\n",
      "[68 34 13 46 31 86 33 83 77 85 88  0 96 30 89] 56\n",
      "[34 13 46 31 86 33 83 77 85 88  0 96 30 89 56] 4\n",
      "[13 46 31 86 33 83 77 85 88  0 96 30 89 56  4] 80\n",
      "[46 31 86 33 83 77 85 88  0 96 30 89 56  4 80] 8\n",
      "[31 86 33 83 77 85 88  0 96 30 89 56  4 80  8] 47\n",
      "[86 33 83 77 85 88  0 96 30 89 56  4 80  8 47] 68\n",
      "[33 83 77 85 88  0 96 30 89 56  4 80  8 47 68] 31\n",
      "[83 77 85 88  0 96 30 89 56  4 80  8 47 68 31] 10\n",
      "[77 85 88  0 96 30 89 56  4 80  8 47 68 31 10] 4\n",
      "[85 88  0 96 30 89 56  4 80  8 47 68 31 10  4] 28\n",
      "[88  0 96 30 89 56  4 80  8 47 68 31 10  4 28] 57\n",
      "[ 0 96 30 89 56  4 80  8 47 68 31 10  4 28 57] 21\n",
      "[96 30 89 56  4 80  8 47 68 31 10  4 28 57 21] 77\n",
      "[30 89 56  4 80  8 47 68 31 10  4 28 57 21 77] 12\n",
      "[89 56  4 80  8 47 68 31 10  4 28 57 21 77 12] 44\n",
      "[56  4 80  8 47 68 31 10  4 28 57 21 77 12 44] 80\n",
      "[ 4 80  8 47 68 31 10  4 28 57 21 77 12 44 80] 70\n",
      "[80  8 47 68 31 10  4 28 57 21 77 12 44 80 70] 78\n",
      "[ 8 47 68 31 10  4 28 57 21 77 12 44 80 70 78] 10\n",
      "[47 68 31 10  4 28 57 21 77 12 44 80 70 78 10] 94\n",
      "[68 31 10  4 28 57 21 77 12 44 80 70 78 10 94] 10\n",
      "[31 10  4 28 57 21 77 12 44 80 70 78 10 94 10] 7\n",
      "[10  4 28 57 21 77 12 44 80 70 78 10 94 10  7] 58\n",
      "[ 4 28 57 21 77 12 44 80 70 78 10 94 10  7 58] 12\n",
      "[28 57 21 77 12 44 80 70 78 10 94 10  7 58 12] 85\n",
      "[57 21 77 12 44 80 70 78 10 94 10  7 58 12 85] 41\n",
      "[21 77 12 44 80 70 78 10 94 10  7 58 12 85 41] 51\n",
      "[77 12 44 80 70 78 10 94 10  7 58 12 85 41 51] 0\n",
      "[12 44 80 70 78 10 94 10  7 58 12 85 41 51  0] 44\n",
      "[44 80 70 78 10 94 10  7 58 12 85 41 51  0 44] 37\n",
      "[80 70 78 10 94 10  7 58 12 85 41 51  0 44 37] 49\n",
      "[70 78 10 94 10  7 58 12 85 41 51  0 44 37 49] 32\n",
      "[78 10 94 10  7 58 12 85 41 51  0 44 37 49 32] 97\n",
      "[10 94 10  7 58 12 85 41 51  0 44 37 49 32 97] 11\n",
      "[94 10  7 58 12 85 41 51  0 44 37 49 32 97 11] 25\n",
      "[10  7 58 12 85 41 51  0 44 37 49 32 97 11 25] 21\n",
      "[ 7 58 12 85 41 51  0 44 37 49 32 97 11 25 21] 90\n",
      "[58 12 85 41 51  0 44 37 49 32 97 11 25 21 90] 29\n",
      "[12 85 41 51  0 44 37 49 32 97 11 25 21 90 29] 84\n",
      "[85 41 51  0 44 37 49 32 97 11 25 21 90 29 84] 92\n",
      "[41 51  0 44 37 49 32 97 11 25 21 90 29 84 92] 91\n",
      "[51  0 44 37 49 32 97 11 25 21 90 29 84 92 91] 52\n",
      "[ 0 44 37 49 32 97 11 25 21 90 29 84 92 91 52] 28\n",
      "[44 37 49 32 97 11 25 21 90 29 84 92 91 52 28] 95\n",
      "[37 49 32 97 11 25 21 90 29 84 92 91 52 28 95] 72\n",
      "[49 32 97 11 25 21 90 29 84 92 91 52 28 95 72] 11\n",
      "[32 97 11 25 21 90 29 84 92 91 52 28 95 72 11] 96\n",
      "[97 11 25 21 90 29 84 92 91 52 28 95 72 11 96] 60\n",
      "[11 25 21 90 29 84 92 91 52 28 95 72 11 96 60] 35\n",
      "[25 21 90 29 84 92 91 52 28 95 72 11 96 60 35] 21\n",
      "[21 90 29 84 92 91 52 28 95 72 11 96 60 35 21] 17\n",
      "[90 29 84 92 91 52 28 95 72 11 96 60 35 21 17] 58\n",
      "[29 84 92 91 52 28 95 72 11 96 60 35 21 17 58] 37\n",
      "[84 92 91 52 28 95 72 11 96 60 35 21 17 58 37] 1\n",
      "[92 91 52 28 95 72 11 96 60 35 21 17 58 37  1] 89\n",
      "[91 52 28 95 72 11 96 60 35 21 17 58 37  1 89] 0\n",
      "[52 28 95 72 11 96 60 35 21 17 58 37  1 89  0] 49\n",
      "[28 95 72 11 96 60 35 21 17 58 37  1 89  0 49] 9\n",
      "[95 72 11 96 60 35 21 17 58 37  1 89  0 49  9] 81\n",
      "[72 11 96 60 35 21 17 58 37  1 89  0 49  9 81] 69\n",
      "[11 96 60 35 21 17 58 37  1 89  0 49  9 81 69] 38\n",
      "[96 60 35 21 17 58 37  1 89  0 49  9 81 69 38] 5\n",
      "[60 35 21 17 58 37  1 89  0 49  9 81 69 38  5] 57\n",
      "[35 21 17 58 37  1 89  0 49  9 81 69 38  5 57] 90\n",
      "[21 17 58 37  1 89  0 49  9 81 69 38  5 57 90] 77\n",
      "[17 58 37  1 89  0 49  9 81 69 38  5 57 90 77] 13\n",
      "[58 37  1 89  0 49  9 81 69 38  5 57 90 77 13] 34\n",
      "[37  1 89  0 49  9 81 69 38  5 57 90 77 13 34] 59\n",
      "[ 1 89  0 49  9 81 69 38  5 57 90 77 13 34 59] 95\n",
      "[89  0 49  9 81 69 38  5 57 90 77 13 34 59 95] 12\n",
      "[ 0 49  9 81 69 38  5 57 90 77 13 34 59 95 12] 45\n",
      "[49  9 81 69 38  5 57 90 77 13 34 59 95 12 45] 25\n",
      "[ 9 81 69 38  5 57 90 77 13 34 59 95 12 45 25] 84\n",
      "[81 69 38  5 57 90 77 13 34 59 95 12 45 25 84] 30\n",
      "[69 38  5 57 90 77 13 34 59 95 12 45 25 84 30] 87\n",
      "[38  5 57 90 77 13 34 59 95 12 45 25 84 30 87] 70\n",
      "[ 5 57 90 77 13 34 59 95 12 45 25 84 30 87 70] 60\n",
      "[57 90 77 13 34 59 95 12 45 25 84 30 87 70 60] 65\n",
      "[90 77 13 34 59 95 12 45 25 84 30 87 70 60 65] 77\n",
      "[77 13 34 59 95 12 45 25 84 30 87 70 60 65 77] 62\n",
      "[13 34 59 95 12 45 25 84 30 87 70 60 65 77 62] 66\n",
      "[34 59 95 12 45 25 84 30 87 70 60 65 77 62 66] 13\n",
      "[59 95 12 45 25 84 30 87 70 60 65 77 62 66 13] 73\n",
      "[95 12 45 25 84 30 87 70 60 65 77 62 66 13 73] 66\n",
      "[12 45 25 84 30 87 70 60 65 77 62 66 13 73 66] 43\n",
      "[45 25 84 30 87 70 60 65 77 62 66 13 73 66 43] 74\n",
      "[25 84 30 87 70 60 65 77 62 66 13 73 66 43 74] 0\n",
      "[84 30 87 70 60 65 77 62 66 13 73 66 43 74  0] 52\n",
      "[30 87 70 60 65 77 62 66 13 73 66 43 74  0 52] 0\n",
      "[87 70 60 65 77 62 66 13 73 66 43 74  0 52  0] 51\n",
      "[70 60 65 77 62 66 13 73 66 43 74  0 52  0 51] 19\n",
      "[60 65 77 62 66 13 73 66 43 74  0 52  0 51 19] 12\n",
      "[65 77 62 66 13 73 66 43 74  0 52  0 51 19 12] 80\n",
      "[77 62 66 13 73 66 43 74  0 52  0 51 19 12 80] 51\n",
      "[62 66 13 73 66 43 74  0 52  0 51 19 12 80 51] 36\n",
      "[66 13 73 66 43 74  0 52  0 51 19 12 80 51 36] 58\n",
      "[13 73 66 43 74  0 52  0 51 19 12 80 51 36 58] 6\n",
      "[73 66 43 74  0 52  0 51 19 12 80 51 36 58  6] 100\n",
      "[ 66  43  74   0  52   0  51  19  12  80  51  36  58   6 100] 45\n",
      "[ 43  74   0  52   0  51  19  12  80  51  36  58   6 100  45] 33\n",
      "[ 74   0  52   0  51  19  12  80  51  36  58   6 100  45  33] 20\n",
      "[  0  52   0  51  19  12  80  51  36  58   6 100  45  33  20] 72\n",
      "[ 52   0  51  19  12  80  51  36  58   6 100  45  33  20  72] 71\n",
      "[  0  51  19  12  80  51  36  58   6 100  45  33  20  72  71] 43\n",
      "[ 51  19  12  80  51  36  58   6 100  45  33  20  72  71  43] 67\n",
      "[ 19  12  80  51  36  58   6 100  45  33  20  72  71  43  67] 48\n",
      "[ 12  80  51  36  58   6 100  45  33  20  72  71  43  67  48] 53\n",
      "[ 80  51  36  58   6 100  45  33  20  72  71  43  67  48  53] 86\n",
      "[ 51  36  58   6 100  45  33  20  72  71  43  67  48  53  86] 20\n",
      "[ 36  58   6 100  45  33  20  72  71  43  67  48  53  86  20] 7\n",
      "[ 58   6 100  45  33  20  72  71  43  67  48  53  86  20   7] 93\n",
      "[  6 100  45  33  20  72  71  43  67  48  53  86  20   7  93] 85\n",
      "[100  45  33  20  72  71  43  67  48  53  86  20   7  93  85] 48\n",
      "[45 33 20 72 71 43 67 48 53 86 20  7 93 85 48] 90\n",
      "[33 20 72 71 43 67 48 53 86 20  7 93 85 48 90] 28\n",
      "[20 72 71 43 67 48 53 86 20  7 93 85 48 90 28] 37\n",
      "[72 71 43 67 48 53 86 20  7 93 85 48 90 28 37] 0\n",
      "[71 43 67 48 53 86 20  7 93 85 48 90 28 37  0] 88\n",
      "[43 67 48 53 86 20  7 93 85 48 90 28 37  0 88] 34\n",
      "[67 48 53 86 20  7 93 85 48 90 28 37  0 88 34] 19\n",
      "[48 53 86 20  7 93 85 48 90 28 37  0 88 34 19] 100\n",
      "[ 53  86  20   7  93  85  48  90  28  37   0  88  34  19 100] 73\n",
      "[ 86  20   7  93  85  48  90  28  37   0  88  34  19 100  73] 89\n",
      "[ 20   7  93  85  48  90  28  37   0  88  34  19 100  73  89] 59\n",
      "[  7  93  85  48  90  28  37   0  88  34  19 100  73  89  59] 52\n",
      "[ 93  85  48  90  28  37   0  88  34  19 100  73  89  59  52] 20\n",
      "[ 85  48  90  28  37   0  88  34  19 100  73  89  59  52  20] 74\n",
      "[ 48  90  28  37   0  88  34  19 100  73  89  59  52  20  74] 6\n",
      "[ 90  28  37   0  88  34  19 100  73  89  59  52  20  74   6] 99\n",
      "[ 28  37   0  88  34  19 100  73  89  59  52  20  74   6  99] 24\n",
      "[ 37   0  88  34  19 100  73  89  59  52  20  74   6  99  24] 19\n",
      "[  0  88  34  19 100  73  89  59  52  20  74   6  99  24  19] 66\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[71]\n",
      "  [52]\n",
      "  [54]\n",
      "  [32]\n",
      "  [85]\n",
      "  [17]\n",
      "  [71]\n",
      "  [36]\n",
      "  [16]\n",
      "  [68]\n",
      "  [12]\n",
      "  [ 4]\n",
      "  [68]\n",
      "  [76]\n",
      "  [38]]\n",
      "\n",
      " [[52]\n",
      "  [54]\n",
      "  [32]\n",
      "  [85]\n",
      "  [17]\n",
      "  [71]\n",
      "  [36]\n",
      "  [16]\n",
      "  [68]\n",
      "  [12]\n",
      "  [ 4]\n",
      "  [68]\n",
      "  [76]\n",
      "  [38]\n",
      "  [25]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.Sequential()\n",
    "model3.add(layers.LSTM(100, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model3.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.rnn.lstm.LSTM at 0x7fe623933590>,\n",
       " <keras.layers.core.dense.Dense at 0x7fe623933390>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 11ms/step - loss: 1651.1329 - accuracy: 0.0124\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1244.8685 - accuracy: 0.0124\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1022.9379 - accuracy: 0.0124\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1007.8016 - accuracy: 0.0124\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1004.9525 - accuracy: 0.0124\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 989.6764 - accuracy: 0.0124\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 988.6370 - accuracy: 0.0124\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 973.9019 - accuracy: 0.0124\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 977.2203 - accuracy: 0.0124\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 990.6849 - accuracy: 0.0124\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 985.7214 - accuracy: 0.0124\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1054.2108 - accuracy: 0.0124\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 986.4512 - accuracy: 0.0124\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 975.5805 - accuracy: 0.0124\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 999.9191 - accuracy: 0.0124\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1026.4647 - accuracy: 0.0124\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 978.7886 - accuracy: 0.0124\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 947.7657 - accuracy: 0.0124\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 953.5976 - accuracy: 0.0124\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1003.1002 - accuracy: 0.0124\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 982.5342 - accuracy: 0.0124\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 951.1652 - accuracy: 0.0124\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 950.9177 - accuracy: 0.0124\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 942.9191 - accuracy: 0.0124\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 932.1221 - accuracy: 0.0124\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 934.3123 - accuracy: 0.0124\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 950.2610 - accuracy: 0.0124\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 922.5165 - accuracy: 0.0124\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 947.5699 - accuracy: 0.0124\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 948.2809 - accuracy: 0.0124\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 916.3583 - accuracy: 0.0124\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 915.5116 - accuracy: 0.0124\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 913.9105 - accuracy: 0.0124\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 906.0734 - accuracy: 0.0124\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 912.8723 - accuracy: 0.0124\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 947.0012 - accuracy: 0.0124\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 952.9402 - accuracy: 0.0124\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 947.2130 - accuracy: 0.0124\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 902.1579 - accuracy: 0.0124\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 923.0084 - accuracy: 0.0124\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 915.7900 - accuracy: 0.0124\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 910.3714 - accuracy: 0.0124\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 935.0770 - accuracy: 0.0124\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 898.9493 - accuracy: 0.0124\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 938.6169 - accuracy: 0.0124\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 903.6794 - accuracy: 0.0124\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 875.3768 - accuracy: 0.0124\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 909.2676 - accuracy: 0.0124\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 891.4106 - accuracy: 0.0124\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 888.0499 - accuracy: 0.0124\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 892.8966 - accuracy: 0.0124\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 912.1982 - accuracy: 0.0124\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 910.5112 - accuracy: 0.0124\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 890.6976 - accuracy: 0.0124\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 934.0762 - accuracy: 0.0124\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 903.3863 - accuracy: 0.0124\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 890.6172 - accuracy: 0.0124\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 887.1306 - accuracy: 0.0124\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 884.7889 - accuracy: 0.0124\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 876.2220 - accuracy: 0.0124\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 888.3907 - accuracy: 0.0124\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 913.9238 - accuracy: 0.0124\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 884.6551 - accuracy: 0.0124\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 922.8661 - accuracy: 0.0124\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 884.8049 - accuracy: 0.0124\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 893.3263 - accuracy: 0.0124\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 873.8215 - accuracy: 0.0124\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 882.5751 - accuracy: 0.0124\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 886.9651 - accuracy: 0.0124\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 870.6941 - accuracy: 0.0124\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 888.1143 - accuracy: 0.0124\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 897.9071 - accuracy: 0.0124\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 918.5473 - accuracy: 0.0124\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 907.5157 - accuracy: 0.0124\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 907.9146 - accuracy: 0.0124\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 879.5513 - accuracy: 0.0124\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 865.4325 - accuracy: 0.0124\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 850.6290 - accuracy: 0.0124\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 848.3899 - accuracy: 0.0124\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 908.6621 - accuracy: 0.0124\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1027.7355 - accuracy: 0.0124\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 953.5964 - accuracy: 0.0124\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 926.6459 - accuracy: 0.0124\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 908.9679 - accuracy: 0.0124\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 898.2444 - accuracy: 0.0124\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 887.9311 - accuracy: 0.0124\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 871.4607 - accuracy: 0.0124\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1223.3915 - accuracy: 0.0124\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 944.8314 - accuracy: 0.0124\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 923.8136 - accuracy: 0.0124\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 901.5934 - accuracy: 0.0124\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 905.3106 - accuracy: 0.0124\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1017.6662 - accuracy: 0.0124\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 930.3981 - accuracy: 0.0124\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 938.4689 - accuracy: 0.0124\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 937.7680 - accuracy: 0.0124\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 923.1019 - accuracy: 0.0124\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 901.2070 - accuracy: 0.0124\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 893.6616 - accuracy: 0.0124\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 917.7945 - accuracy: 0.0124\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 911.3380 - accuracy: 0.0124\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 912.9603 - accuracy: 0.0124\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 910.4662 - accuracy: 0.0124\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 887.3799 - accuracy: 0.0124\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 885.5513 - accuracy: 0.0124\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 901.6105 - accuracy: 0.0124\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 923.1677 - accuracy: 0.0124\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 908.9308 - accuracy: 0.0124\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 890.3646 - accuracy: 0.0124\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 878.6321 - accuracy: 0.0124\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 875.8012 - accuracy: 0.0124\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 874.6955 - accuracy: 0.0124\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 887.5202 - accuracy: 0.0124\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 863.2574 - accuracy: 0.0124\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 881.7986 - accuracy: 0.0124\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 855.9901 - accuracy: 0.0124\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 890.4550 - accuracy: 0.0124\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 902.1319 - accuracy: 0.0124\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 892.6951 - accuracy: 0.0124\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 885.2491 - accuracy: 0.0124\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 889.5446 - accuracy: 0.0124\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 883.6280 - accuracy: 0.0124\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 879.2061 - accuracy: 0.0124\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 887.0372 - accuracy: 0.0124\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 866.3384 - accuracy: 0.0124\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 866.7651 - accuracy: 0.0124\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 863.9621 - accuracy: 0.0124\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 845.4836 - accuracy: 0.0124\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 889.0447 - accuracy: 0.0124\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 944.4159 - accuracy: 0.0124\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 869.2144 - accuracy: 0.0124\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 856.1683 - accuracy: 0.0124\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 840.4067 - accuracy: 0.0124\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 860.2848 - accuracy: 0.0124\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 980.2729 - accuracy: 0.0124\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 892.7015 - accuracy: 0.0124\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 888.4283 - accuracy: 0.0124\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 868.9280 - accuracy: 0.0124\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 860.1347 - accuracy: 0.0124\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 852.3673 - accuracy: 0.0124\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 855.4710 - accuracy: 0.0124\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 873.3931 - accuracy: 0.0124\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 856.1201 - accuracy: 0.0124\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 993.4157 - accuracy: 0.0124\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 886.6602 - accuracy: 0.0124\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 855.5871 - accuracy: 0.0124\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 845.1080 - accuracy: 0.0124\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 851.7596 - accuracy: 0.0124\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 848.2228 - accuracy: 0.0124\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 833.1412 - accuracy: 0.0124\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 826.2452 - accuracy: 0.0124\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 830.7547 - accuracy: 0.0124\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 821.2711 - accuracy: 0.0124\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 881.8383 - accuracy: 0.0124\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 852.4076 - accuracy: 0.0124\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 822.2115 - accuracy: 0.0124\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 832.1700 - accuracy: 0.0124\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 816.6514 - accuracy: 0.0124\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 858.2767 - accuracy: 0.0124\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 837.2630 - accuracy: 0.0124\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 839.0667 - accuracy: 0.0124\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 816.5167 - accuracy: 0.0124\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 820.0165 - accuracy: 0.0124\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 834.4010 - accuracy: 0.0124\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3444.6589 - accuracy: 0.0144\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 953.0345 - accuracy: 0.0124\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 931.8391 - accuracy: 0.0124\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 936.5311 - accuracy: 0.0124\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 943.4869 - accuracy: 0.0124\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 937.6085 - accuracy: 0.0124\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 953.9273 - accuracy: 0.0124\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 959.4264 - accuracy: 0.0124\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 936.1926 - accuracy: 0.0124\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 919.8113 - accuracy: 0.0124\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 921.0993 - accuracy: 0.0124\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 920.0546 - accuracy: 0.0124\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 923.7757 - accuracy: 0.0124\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 918.5770 - accuracy: 0.0124\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 922.9091 - accuracy: 0.0124\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 918.5693 - accuracy: 0.0124\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 920.6548 - accuracy: 0.0124\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 916.5456 - accuracy: 0.0124\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 913.9988 - accuracy: 0.0124\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 918.5061 - accuracy: 0.0124\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 912.6205 - accuracy: 0.0124\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 909.3578 - accuracy: 0.0124\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 912.0041 - accuracy: 0.0124\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1183.1471 - accuracy: 0.0124\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 953.8273 - accuracy: 0.0124\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 992.3419 - accuracy: 0.0124\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 925.0762 - accuracy: 0.0124\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 911.1769 - accuracy: 0.0124\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 921.3254 - accuracy: 0.0124\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 907.7258 - accuracy: 0.0124\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 905.6246 - accuracy: 0.0124\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 908.1497 - accuracy: 0.0124\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 922.4343 - accuracy: 0.0124\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 899.4360 - accuracy: 0.0124\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 897.5400 - accuracy: 0.0124\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 896.0082 - accuracy: 0.0124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe623892650>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 88],\n",
       "        [ 34],\n",
       "        [ 19],\n",
       "        [100],\n",
       "        [ 73],\n",
       "        [ 89],\n",
       "        [ 59],\n",
       "        [ 52],\n",
       "        [ 20],\n",
       "        [ 74],\n",
       "        [  6],\n",
       "        [ 99],\n",
       "        [ 24],\n",
       "        [ 19],\n",
       "        [ 66]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = arr1[-15:]\n",
    "test_data = test_data.reshape((1, n_steps, n_features))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 220ms/step\n",
      "[[46.275166]]\n"
     ]
    }
   ],
   "source": [
    "predictNextNumber = model3.predict(test_data, verbose=1)\n",
    "print(predictNextNumber)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f293f16398db128e85df277de8eb5f9ab0a1b28857fa0f1c8543245825f1b931"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
