{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all essential libraries\n",
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "## Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>site off</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>88</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      MB033 MB034 MB035 MB036\n",
       "0 2021-01-01  site off     4    71    40\n",
       "1 2021-01-02        88    66    52    12\n",
       "2 2021-01-03        52    40    54    72\n",
       "3 2021-01-04        49    34    32    28\n",
       "4 2021-01-05        82    32    85    49"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Book01.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>70</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  MB033 MB034 MB035 MB036\n",
       "495 2022-05-11    70    42     6     2\n",
       "496 2022-05-12    92     3    99    64\n",
       "497 2022-05-13    84    82    24    30\n",
       "498 2022-05-14    98    50    19    60\n",
       "499 2022-05-15     3     0    66    48"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     0\n",
       "MB033    0\n",
       "MB034    0\n",
       "MB035    0\n",
       "MB036    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in train data\n",
    "df.isnull().sum()\n",
    " #No missing valuues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for better understanding of the data, We can eloborate as month and weekday wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      40\n",
       "1      12\n",
       "2      72\n",
       "3      28\n",
       "4      49\n",
       "       ..\n",
       "495     2\n",
       "496    64\n",
       "497    30\n",
       "498    60\n",
       "499    48\n",
       "Name: MB036, Length: 500, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MB036']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MB033'] = df['MB033'].replace(['site off'],0)\n",
    "df['MB034'] = df['MB034'].replace(['site off'],0)\n",
    "df['MB035'] = df['MB035'].replace(['site off'],0)\n",
    "df['MB036'] = df['MB036'].replace(['site off'],0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 12, 72, 28, 49, 16, 74, 67, 79, 71, 61, 68, 51,  2, 42, 81, 17,\n",
       "       77, 93, 40, 91, 80, 49,  8,  7,  2, 80,  8, 81, 21,  0, 92, 60, 69,\n",
       "       96, 52,  0, 80, 32, 15, 24, 85,  4, 92, 62, 94, 52, 59, 25, 93, 95,\n",
       "       68, 66,  1, 48, 28, 85, 26,  0, 83,  6, 99, 53, 24, 91, 96, 36, 55,\n",
       "       31, 19, 90, 93, 15, 45, 11, 85, 23,  5, 99, 65,  4, 80, 59, 22, 67,\n",
       "       96, 45, 58, 39,  0, 63, 17, 11,  9,  6, 25,  9, 90,  2, 75, 83,  7,\n",
       "       84, 53, 54, 80, 67, 83, 11, 24, 97, 18, 53, 15, 84, 47, 33, 74, 21,\n",
       "        0, 40,  0, 17, 88,  5, 26, 46, 70, 12, 53, 61, 55, 20, 44, 52, 24,\n",
       "       99, 83, 46, 56, 48, 81, 98, 67, 88, 48,  5, 75, 83, 84,  0, 97, 16,\n",
       "       32, 23, 24, 88, 41, 99, 60, 97,  9, 41, 21, 32, 87, 46, 36,  5,  4,\n",
       "       20,  4, 65, 70,  5, 76,  6, 94, 71, 46,  0, 34,  8, 75, 90, 18, 11,\n",
       "        3, 91, 78, 35, 87, 11, 30, 44, 33, 61, 40,  1, 12, 49, 76, 82,  1,\n",
       "       77, 16,  2, 84, 25, 27,  3,  0, 89, 58, 48, 47, 95, 35, 85, 61,  5,\n",
       "       27, 61, 37, 23, 68, 33, 64, 23, 22, 92, 43,  3, 52, 52, 62, 92, 58,\n",
       "       82, 50, 17, 61,  0, 82, 14, 88, 37, 64, 44, 14,  0, 36, 52, 40, 49,\n",
       "       60, 77, 10, 26, 22, 80, 78, 76, 75, 93, 68, 92, 97, 29,  0, 41, 94,\n",
       "        0, 70,  9, 37, 62, 36, 18, 17, 82, 58, 68, 22,  3, 32, 24, 81, 23,\n",
       "       50,  6,  6, 68, 84, 97,  5, 36, 15, 82, 96, 18,  3, 67,  0, 49, 44,\n",
       "       57, 70, 58, 56, 50, 57, 71, 39, 53, 50, 17, 66, 22, 38, 14, 88, 12,\n",
       "       56, 27, 16, 41, 32, 19, 40, 53, 90, 17,  0, 91, 29, 17, 42, 10, 82,\n",
       "       16, 72, 33, 90, 17, 97, 93, 72, 26, 38, 29, 33, 98, 75, 22, 75, 79,\n",
       "       10, 88, 78, 96, 25, 16, 95,  0, 15, 45, 39, 88, 90, 79, 40, 80, 43,\n",
       "       58, 78, 71, 76, 51, 40, 15,  2, 34, 52, 57, 74, 94, 43, 50, 64, 65,\n",
       "       29, 25, 97, 83,  0, 58, 33, 40, 14, 31, 37, 45, 92, 32,  7,  7, 44,\n",
       "       79,  2, 62, 24, 42, 24, 55, 95, 66, 94, 26, 69, 18, 66, 14,  0,  1,\n",
       "       81, 85, 91, 49, 75, 31, 55, 76, 50, 86, 38, 34,  1, 50, 43, 12, 52,\n",
       "       43, 16, 53, 33, 50, 14, 37, 54, 93, 75, 11,  0,  0, 46, 30, 33, 45,\n",
       "       68, 16, 12, 32, 82, 92, 83, 59, 84, 93, 56, 91, 83, 61, 64, 53, 55,\n",
       "       94, 69, 88, 22, 75, 98, 93, 36,  0, 51, 31, 79, 78,  2,  8, 54, 20,\n",
       "       98,  6,  2, 64, 30, 60, 48])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = df['MB036'].values\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def splitSequence(seq, n_steps):\n",
    "    \n",
    "    #Declare X and y as empty list\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        #get the last index\n",
    "        lastIndex = i + n_steps\n",
    "        \n",
    "        #if lastIndex is greater than length of sequence then break\n",
    "        if lastIndex > len(seq) - 1:\n",
    "            break\n",
    "            \n",
    "        #Create input and output sequence\n",
    "        seq_X, seq_y = seq[i:lastIndex], seq[lastIndex]\n",
    "        \n",
    "        #append seq_X, seq_y in X and y list\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        pass\n",
    "    #Convert X and y into numpy array\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y \n",
    "    \n",
    "    pass\n",
    "\n",
    "n_steps = 14\n",
    "X, y = splitSequence(arr1, n_steps = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((486, 14), (486,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 12 72 28 49 16 74 67 79 71 61 68 51  2] 42\n",
      "[12 72 28 49 16 74 67 79 71 61 68 51  2 42] 81\n",
      "[72 28 49 16 74 67 79 71 61 68 51  2 42 81] 17\n",
      "[28 49 16 74 67 79 71 61 68 51  2 42 81 17] 77\n",
      "[49 16 74 67 79 71 61 68 51  2 42 81 17 77] 93\n",
      "[16 74 67 79 71 61 68 51  2 42 81 17 77 93] 40\n",
      "[74 67 79 71 61 68 51  2 42 81 17 77 93 40] 91\n",
      "[67 79 71 61 68 51  2 42 81 17 77 93 40 91] 80\n",
      "[79 71 61 68 51  2 42 81 17 77 93 40 91 80] 49\n",
      "[71 61 68 51  2 42 81 17 77 93 40 91 80 49] 8\n",
      "[61 68 51  2 42 81 17 77 93 40 91 80 49  8] 7\n",
      "[68 51  2 42 81 17 77 93 40 91 80 49  8  7] 2\n",
      "[51  2 42 81 17 77 93 40 91 80 49  8  7  2] 80\n",
      "[ 2 42 81 17 77 93 40 91 80 49  8  7  2 80] 8\n",
      "[42 81 17 77 93 40 91 80 49  8  7  2 80  8] 81\n",
      "[81 17 77 93 40 91 80 49  8  7  2 80  8 81] 21\n",
      "[17 77 93 40 91 80 49  8  7  2 80  8 81 21] 0\n",
      "[77 93 40 91 80 49  8  7  2 80  8 81 21  0] 92\n",
      "[93 40 91 80 49  8  7  2 80  8 81 21  0 92] 60\n",
      "[40 91 80 49  8  7  2 80  8 81 21  0 92 60] 69\n",
      "[91 80 49  8  7  2 80  8 81 21  0 92 60 69] 96\n",
      "[80 49  8  7  2 80  8 81 21  0 92 60 69 96] 52\n",
      "[49  8  7  2 80  8 81 21  0 92 60 69 96 52] 0\n",
      "[ 8  7  2 80  8 81 21  0 92 60 69 96 52  0] 80\n",
      "[ 7  2 80  8 81 21  0 92 60 69 96 52  0 80] 32\n",
      "[ 2 80  8 81 21  0 92 60 69 96 52  0 80 32] 15\n",
      "[80  8 81 21  0 92 60 69 96 52  0 80 32 15] 24\n",
      "[ 8 81 21  0 92 60 69 96 52  0 80 32 15 24] 85\n",
      "[81 21  0 92 60 69 96 52  0 80 32 15 24 85] 4\n",
      "[21  0 92 60 69 96 52  0 80 32 15 24 85  4] 92\n",
      "[ 0 92 60 69 96 52  0 80 32 15 24 85  4 92] 62\n",
      "[92 60 69 96 52  0 80 32 15 24 85  4 92 62] 94\n",
      "[60 69 96 52  0 80 32 15 24 85  4 92 62 94] 52\n",
      "[69 96 52  0 80 32 15 24 85  4 92 62 94 52] 59\n",
      "[96 52  0 80 32 15 24 85  4 92 62 94 52 59] 25\n",
      "[52  0 80 32 15 24 85  4 92 62 94 52 59 25] 93\n",
      "[ 0 80 32 15 24 85  4 92 62 94 52 59 25 93] 95\n",
      "[80 32 15 24 85  4 92 62 94 52 59 25 93 95] 68\n",
      "[32 15 24 85  4 92 62 94 52 59 25 93 95 68] 66\n",
      "[15 24 85  4 92 62 94 52 59 25 93 95 68 66] 1\n",
      "[24 85  4 92 62 94 52 59 25 93 95 68 66  1] 48\n",
      "[85  4 92 62 94 52 59 25 93 95 68 66  1 48] 28\n",
      "[ 4 92 62 94 52 59 25 93 95 68 66  1 48 28] 85\n",
      "[92 62 94 52 59 25 93 95 68 66  1 48 28 85] 26\n",
      "[62 94 52 59 25 93 95 68 66  1 48 28 85 26] 0\n",
      "[94 52 59 25 93 95 68 66  1 48 28 85 26  0] 83\n",
      "[52 59 25 93 95 68 66  1 48 28 85 26  0 83] 6\n",
      "[59 25 93 95 68 66  1 48 28 85 26  0 83  6] 99\n",
      "[25 93 95 68 66  1 48 28 85 26  0 83  6 99] 53\n",
      "[93 95 68 66  1 48 28 85 26  0 83  6 99 53] 24\n",
      "[95 68 66  1 48 28 85 26  0 83  6 99 53 24] 91\n",
      "[68 66  1 48 28 85 26  0 83  6 99 53 24 91] 96\n",
      "[66  1 48 28 85 26  0 83  6 99 53 24 91 96] 36\n",
      "[ 1 48 28 85 26  0 83  6 99 53 24 91 96 36] 55\n",
      "[48 28 85 26  0 83  6 99 53 24 91 96 36 55] 31\n",
      "[28 85 26  0 83  6 99 53 24 91 96 36 55 31] 19\n",
      "[85 26  0 83  6 99 53 24 91 96 36 55 31 19] 90\n",
      "[26  0 83  6 99 53 24 91 96 36 55 31 19 90] 93\n",
      "[ 0 83  6 99 53 24 91 96 36 55 31 19 90 93] 15\n",
      "[83  6 99 53 24 91 96 36 55 31 19 90 93 15] 45\n",
      "[ 6 99 53 24 91 96 36 55 31 19 90 93 15 45] 11\n",
      "[99 53 24 91 96 36 55 31 19 90 93 15 45 11] 85\n",
      "[53 24 91 96 36 55 31 19 90 93 15 45 11 85] 23\n",
      "[24 91 96 36 55 31 19 90 93 15 45 11 85 23] 5\n",
      "[91 96 36 55 31 19 90 93 15 45 11 85 23  5] 99\n",
      "[96 36 55 31 19 90 93 15 45 11 85 23  5 99] 65\n",
      "[36 55 31 19 90 93 15 45 11 85 23  5 99 65] 4\n",
      "[55 31 19 90 93 15 45 11 85 23  5 99 65  4] 80\n",
      "[31 19 90 93 15 45 11 85 23  5 99 65  4 80] 59\n",
      "[19 90 93 15 45 11 85 23  5 99 65  4 80 59] 22\n",
      "[90 93 15 45 11 85 23  5 99 65  4 80 59 22] 67\n",
      "[93 15 45 11 85 23  5 99 65  4 80 59 22 67] 96\n",
      "[15 45 11 85 23  5 99 65  4 80 59 22 67 96] 45\n",
      "[45 11 85 23  5 99 65  4 80 59 22 67 96 45] 58\n",
      "[11 85 23  5 99 65  4 80 59 22 67 96 45 58] 39\n",
      "[85 23  5 99 65  4 80 59 22 67 96 45 58 39] 0\n",
      "[23  5 99 65  4 80 59 22 67 96 45 58 39  0] 63\n",
      "[ 5 99 65  4 80 59 22 67 96 45 58 39  0 63] 17\n",
      "[99 65  4 80 59 22 67 96 45 58 39  0 63 17] 11\n",
      "[65  4 80 59 22 67 96 45 58 39  0 63 17 11] 9\n",
      "[ 4 80 59 22 67 96 45 58 39  0 63 17 11  9] 6\n",
      "[80 59 22 67 96 45 58 39  0 63 17 11  9  6] 25\n",
      "[59 22 67 96 45 58 39  0 63 17 11  9  6 25] 9\n",
      "[22 67 96 45 58 39  0 63 17 11  9  6 25  9] 90\n",
      "[67 96 45 58 39  0 63 17 11  9  6 25  9 90] 2\n",
      "[96 45 58 39  0 63 17 11  9  6 25  9 90  2] 75\n",
      "[45 58 39  0 63 17 11  9  6 25  9 90  2 75] 83\n",
      "[58 39  0 63 17 11  9  6 25  9 90  2 75 83] 7\n",
      "[39  0 63 17 11  9  6 25  9 90  2 75 83  7] 84\n",
      "[ 0 63 17 11  9  6 25  9 90  2 75 83  7 84] 53\n",
      "[63 17 11  9  6 25  9 90  2 75 83  7 84 53] 54\n",
      "[17 11  9  6 25  9 90  2 75 83  7 84 53 54] 80\n",
      "[11  9  6 25  9 90  2 75 83  7 84 53 54 80] 67\n",
      "[ 9  6 25  9 90  2 75 83  7 84 53 54 80 67] 83\n",
      "[ 6 25  9 90  2 75 83  7 84 53 54 80 67 83] 11\n",
      "[25  9 90  2 75 83  7 84 53 54 80 67 83 11] 24\n",
      "[ 9 90  2 75 83  7 84 53 54 80 67 83 11 24] 97\n",
      "[90  2 75 83  7 84 53 54 80 67 83 11 24 97] 18\n",
      "[ 2 75 83  7 84 53 54 80 67 83 11 24 97 18] 53\n",
      "[75 83  7 84 53 54 80 67 83 11 24 97 18 53] 15\n",
      "[83  7 84 53 54 80 67 83 11 24 97 18 53 15] 84\n",
      "[ 7 84 53 54 80 67 83 11 24 97 18 53 15 84] 47\n",
      "[84 53 54 80 67 83 11 24 97 18 53 15 84 47] 33\n",
      "[53 54 80 67 83 11 24 97 18 53 15 84 47 33] 74\n",
      "[54 80 67 83 11 24 97 18 53 15 84 47 33 74] 21\n",
      "[80 67 83 11 24 97 18 53 15 84 47 33 74 21] 0\n",
      "[67 83 11 24 97 18 53 15 84 47 33 74 21  0] 40\n",
      "[83 11 24 97 18 53 15 84 47 33 74 21  0 40] 0\n",
      "[11 24 97 18 53 15 84 47 33 74 21  0 40  0] 17\n",
      "[24 97 18 53 15 84 47 33 74 21  0 40  0 17] 88\n",
      "[97 18 53 15 84 47 33 74 21  0 40  0 17 88] 5\n",
      "[18 53 15 84 47 33 74 21  0 40  0 17 88  5] 26\n",
      "[53 15 84 47 33 74 21  0 40  0 17 88  5 26] 46\n",
      "[15 84 47 33 74 21  0 40  0 17 88  5 26 46] 70\n",
      "[84 47 33 74 21  0 40  0 17 88  5 26 46 70] 12\n",
      "[47 33 74 21  0 40  0 17 88  5 26 46 70 12] 53\n",
      "[33 74 21  0 40  0 17 88  5 26 46 70 12 53] 61\n",
      "[74 21  0 40  0 17 88  5 26 46 70 12 53 61] 55\n",
      "[21  0 40  0 17 88  5 26 46 70 12 53 61 55] 20\n",
      "[ 0 40  0 17 88  5 26 46 70 12 53 61 55 20] 44\n",
      "[40  0 17 88  5 26 46 70 12 53 61 55 20 44] 52\n",
      "[ 0 17 88  5 26 46 70 12 53 61 55 20 44 52] 24\n",
      "[17 88  5 26 46 70 12 53 61 55 20 44 52 24] 99\n",
      "[88  5 26 46 70 12 53 61 55 20 44 52 24 99] 83\n",
      "[ 5 26 46 70 12 53 61 55 20 44 52 24 99 83] 46\n",
      "[26 46 70 12 53 61 55 20 44 52 24 99 83 46] 56\n",
      "[46 70 12 53 61 55 20 44 52 24 99 83 46 56] 48\n",
      "[70 12 53 61 55 20 44 52 24 99 83 46 56 48] 81\n",
      "[12 53 61 55 20 44 52 24 99 83 46 56 48 81] 98\n",
      "[53 61 55 20 44 52 24 99 83 46 56 48 81 98] 67\n",
      "[61 55 20 44 52 24 99 83 46 56 48 81 98 67] 88\n",
      "[55 20 44 52 24 99 83 46 56 48 81 98 67 88] 48\n",
      "[20 44 52 24 99 83 46 56 48 81 98 67 88 48] 5\n",
      "[44 52 24 99 83 46 56 48 81 98 67 88 48  5] 75\n",
      "[52 24 99 83 46 56 48 81 98 67 88 48  5 75] 83\n",
      "[24 99 83 46 56 48 81 98 67 88 48  5 75 83] 84\n",
      "[99 83 46 56 48 81 98 67 88 48  5 75 83 84] 0\n",
      "[83 46 56 48 81 98 67 88 48  5 75 83 84  0] 97\n",
      "[46 56 48 81 98 67 88 48  5 75 83 84  0 97] 16\n",
      "[56 48 81 98 67 88 48  5 75 83 84  0 97 16] 32\n",
      "[48 81 98 67 88 48  5 75 83 84  0 97 16 32] 23\n",
      "[81 98 67 88 48  5 75 83 84  0 97 16 32 23] 24\n",
      "[98 67 88 48  5 75 83 84  0 97 16 32 23 24] 88\n",
      "[67 88 48  5 75 83 84  0 97 16 32 23 24 88] 41\n",
      "[88 48  5 75 83 84  0 97 16 32 23 24 88 41] 99\n",
      "[48  5 75 83 84  0 97 16 32 23 24 88 41 99] 60\n",
      "[ 5 75 83 84  0 97 16 32 23 24 88 41 99 60] 97\n",
      "[75 83 84  0 97 16 32 23 24 88 41 99 60 97] 9\n",
      "[83 84  0 97 16 32 23 24 88 41 99 60 97  9] 41\n",
      "[84  0 97 16 32 23 24 88 41 99 60 97  9 41] 21\n",
      "[ 0 97 16 32 23 24 88 41 99 60 97  9 41 21] 32\n",
      "[97 16 32 23 24 88 41 99 60 97  9 41 21 32] 87\n",
      "[16 32 23 24 88 41 99 60 97  9 41 21 32 87] 46\n",
      "[32 23 24 88 41 99 60 97  9 41 21 32 87 46] 36\n",
      "[23 24 88 41 99 60 97  9 41 21 32 87 46 36] 5\n",
      "[24 88 41 99 60 97  9 41 21 32 87 46 36  5] 4\n",
      "[88 41 99 60 97  9 41 21 32 87 46 36  5  4] 20\n",
      "[41 99 60 97  9 41 21 32 87 46 36  5  4 20] 4\n",
      "[99 60 97  9 41 21 32 87 46 36  5  4 20  4] 65\n",
      "[60 97  9 41 21 32 87 46 36  5  4 20  4 65] 70\n",
      "[97  9 41 21 32 87 46 36  5  4 20  4 65 70] 5\n",
      "[ 9 41 21 32 87 46 36  5  4 20  4 65 70  5] 76\n",
      "[41 21 32 87 46 36  5  4 20  4 65 70  5 76] 6\n",
      "[21 32 87 46 36  5  4 20  4 65 70  5 76  6] 94\n",
      "[32 87 46 36  5  4 20  4 65 70  5 76  6 94] 71\n",
      "[87 46 36  5  4 20  4 65 70  5 76  6 94 71] 46\n",
      "[46 36  5  4 20  4 65 70  5 76  6 94 71 46] 0\n",
      "[36  5  4 20  4 65 70  5 76  6 94 71 46  0] 34\n",
      "[ 5  4 20  4 65 70  5 76  6 94 71 46  0 34] 8\n",
      "[ 4 20  4 65 70  5 76  6 94 71 46  0 34  8] 75\n",
      "[20  4 65 70  5 76  6 94 71 46  0 34  8 75] 90\n",
      "[ 4 65 70  5 76  6 94 71 46  0 34  8 75 90] 18\n",
      "[65 70  5 76  6 94 71 46  0 34  8 75 90 18] 11\n",
      "[70  5 76  6 94 71 46  0 34  8 75 90 18 11] 3\n",
      "[ 5 76  6 94 71 46  0 34  8 75 90 18 11  3] 91\n",
      "[76  6 94 71 46  0 34  8 75 90 18 11  3 91] 78\n",
      "[ 6 94 71 46  0 34  8 75 90 18 11  3 91 78] 35\n",
      "[94 71 46  0 34  8 75 90 18 11  3 91 78 35] 87\n",
      "[71 46  0 34  8 75 90 18 11  3 91 78 35 87] 11\n",
      "[46  0 34  8 75 90 18 11  3 91 78 35 87 11] 30\n",
      "[ 0 34  8 75 90 18 11  3 91 78 35 87 11 30] 44\n",
      "[34  8 75 90 18 11  3 91 78 35 87 11 30 44] 33\n",
      "[ 8 75 90 18 11  3 91 78 35 87 11 30 44 33] 61\n",
      "[75 90 18 11  3 91 78 35 87 11 30 44 33 61] 40\n",
      "[90 18 11  3 91 78 35 87 11 30 44 33 61 40] 1\n",
      "[18 11  3 91 78 35 87 11 30 44 33 61 40  1] 12\n",
      "[11  3 91 78 35 87 11 30 44 33 61 40  1 12] 49\n",
      "[ 3 91 78 35 87 11 30 44 33 61 40  1 12 49] 76\n",
      "[91 78 35 87 11 30 44 33 61 40  1 12 49 76] 82\n",
      "[78 35 87 11 30 44 33 61 40  1 12 49 76 82] 1\n",
      "[35 87 11 30 44 33 61 40  1 12 49 76 82  1] 77\n",
      "[87 11 30 44 33 61 40  1 12 49 76 82  1 77] 16\n",
      "[11 30 44 33 61 40  1 12 49 76 82  1 77 16] 2\n",
      "[30 44 33 61 40  1 12 49 76 82  1 77 16  2] 84\n",
      "[44 33 61 40  1 12 49 76 82  1 77 16  2 84] 25\n",
      "[33 61 40  1 12 49 76 82  1 77 16  2 84 25] 27\n",
      "[61 40  1 12 49 76 82  1 77 16  2 84 25 27] 3\n",
      "[40  1 12 49 76 82  1 77 16  2 84 25 27  3] 0\n",
      "[ 1 12 49 76 82  1 77 16  2 84 25 27  3  0] 89\n",
      "[12 49 76 82  1 77 16  2 84 25 27  3  0 89] 58\n",
      "[49 76 82  1 77 16  2 84 25 27  3  0 89 58] 48\n",
      "[76 82  1 77 16  2 84 25 27  3  0 89 58 48] 47\n",
      "[82  1 77 16  2 84 25 27  3  0 89 58 48 47] 95\n",
      "[ 1 77 16  2 84 25 27  3  0 89 58 48 47 95] 35\n",
      "[77 16  2 84 25 27  3  0 89 58 48 47 95 35] 85\n",
      "[16  2 84 25 27  3  0 89 58 48 47 95 35 85] 61\n",
      "[ 2 84 25 27  3  0 89 58 48 47 95 35 85 61] 5\n",
      "[84 25 27  3  0 89 58 48 47 95 35 85 61  5] 27\n",
      "[25 27  3  0 89 58 48 47 95 35 85 61  5 27] 61\n",
      "[27  3  0 89 58 48 47 95 35 85 61  5 27 61] 37\n",
      "[ 3  0 89 58 48 47 95 35 85 61  5 27 61 37] 23\n",
      "[ 0 89 58 48 47 95 35 85 61  5 27 61 37 23] 68\n",
      "[89 58 48 47 95 35 85 61  5 27 61 37 23 68] 33\n",
      "[58 48 47 95 35 85 61  5 27 61 37 23 68 33] 64\n",
      "[48 47 95 35 85 61  5 27 61 37 23 68 33 64] 23\n",
      "[47 95 35 85 61  5 27 61 37 23 68 33 64 23] 22\n",
      "[95 35 85 61  5 27 61 37 23 68 33 64 23 22] 92\n",
      "[35 85 61  5 27 61 37 23 68 33 64 23 22 92] 43\n",
      "[85 61  5 27 61 37 23 68 33 64 23 22 92 43] 3\n",
      "[61  5 27 61 37 23 68 33 64 23 22 92 43  3] 52\n",
      "[ 5 27 61 37 23 68 33 64 23 22 92 43  3 52] 52\n",
      "[27 61 37 23 68 33 64 23 22 92 43  3 52 52] 62\n",
      "[61 37 23 68 33 64 23 22 92 43  3 52 52 62] 92\n",
      "[37 23 68 33 64 23 22 92 43  3 52 52 62 92] 58\n",
      "[23 68 33 64 23 22 92 43  3 52 52 62 92 58] 82\n",
      "[68 33 64 23 22 92 43  3 52 52 62 92 58 82] 50\n",
      "[33 64 23 22 92 43  3 52 52 62 92 58 82 50] 17\n",
      "[64 23 22 92 43  3 52 52 62 92 58 82 50 17] 61\n",
      "[23 22 92 43  3 52 52 62 92 58 82 50 17 61] 0\n",
      "[22 92 43  3 52 52 62 92 58 82 50 17 61  0] 82\n",
      "[92 43  3 52 52 62 92 58 82 50 17 61  0 82] 14\n",
      "[43  3 52 52 62 92 58 82 50 17 61  0 82 14] 88\n",
      "[ 3 52 52 62 92 58 82 50 17 61  0 82 14 88] 37\n",
      "[52 52 62 92 58 82 50 17 61  0 82 14 88 37] 64\n",
      "[52 62 92 58 82 50 17 61  0 82 14 88 37 64] 44\n",
      "[62 92 58 82 50 17 61  0 82 14 88 37 64 44] 14\n",
      "[92 58 82 50 17 61  0 82 14 88 37 64 44 14] 0\n",
      "[58 82 50 17 61  0 82 14 88 37 64 44 14  0] 36\n",
      "[82 50 17 61  0 82 14 88 37 64 44 14  0 36] 52\n",
      "[50 17 61  0 82 14 88 37 64 44 14  0 36 52] 40\n",
      "[17 61  0 82 14 88 37 64 44 14  0 36 52 40] 49\n",
      "[61  0 82 14 88 37 64 44 14  0 36 52 40 49] 60\n",
      "[ 0 82 14 88 37 64 44 14  0 36 52 40 49 60] 77\n",
      "[82 14 88 37 64 44 14  0 36 52 40 49 60 77] 10\n",
      "[14 88 37 64 44 14  0 36 52 40 49 60 77 10] 26\n",
      "[88 37 64 44 14  0 36 52 40 49 60 77 10 26] 22\n",
      "[37 64 44 14  0 36 52 40 49 60 77 10 26 22] 80\n",
      "[64 44 14  0 36 52 40 49 60 77 10 26 22 80] 78\n",
      "[44 14  0 36 52 40 49 60 77 10 26 22 80 78] 76\n",
      "[14  0 36 52 40 49 60 77 10 26 22 80 78 76] 75\n",
      "[ 0 36 52 40 49 60 77 10 26 22 80 78 76 75] 93\n",
      "[36 52 40 49 60 77 10 26 22 80 78 76 75 93] 68\n",
      "[52 40 49 60 77 10 26 22 80 78 76 75 93 68] 92\n",
      "[40 49 60 77 10 26 22 80 78 76 75 93 68 92] 97\n",
      "[49 60 77 10 26 22 80 78 76 75 93 68 92 97] 29\n",
      "[60 77 10 26 22 80 78 76 75 93 68 92 97 29] 0\n",
      "[77 10 26 22 80 78 76 75 93 68 92 97 29  0] 41\n",
      "[10 26 22 80 78 76 75 93 68 92 97 29  0 41] 94\n",
      "[26 22 80 78 76 75 93 68 92 97 29  0 41 94] 0\n",
      "[22 80 78 76 75 93 68 92 97 29  0 41 94  0] 70\n",
      "[80 78 76 75 93 68 92 97 29  0 41 94  0 70] 9\n",
      "[78 76 75 93 68 92 97 29  0 41 94  0 70  9] 37\n",
      "[76 75 93 68 92 97 29  0 41 94  0 70  9 37] 62\n",
      "[75 93 68 92 97 29  0 41 94  0 70  9 37 62] 36\n",
      "[93 68 92 97 29  0 41 94  0 70  9 37 62 36] 18\n",
      "[68 92 97 29  0 41 94  0 70  9 37 62 36 18] 17\n",
      "[92 97 29  0 41 94  0 70  9 37 62 36 18 17] 82\n",
      "[97 29  0 41 94  0 70  9 37 62 36 18 17 82] 58\n",
      "[29  0 41 94  0 70  9 37 62 36 18 17 82 58] 68\n",
      "[ 0 41 94  0 70  9 37 62 36 18 17 82 58 68] 22\n",
      "[41 94  0 70  9 37 62 36 18 17 82 58 68 22] 3\n",
      "[94  0 70  9 37 62 36 18 17 82 58 68 22  3] 32\n",
      "[ 0 70  9 37 62 36 18 17 82 58 68 22  3 32] 24\n",
      "[70  9 37 62 36 18 17 82 58 68 22  3 32 24] 81\n",
      "[ 9 37 62 36 18 17 82 58 68 22  3 32 24 81] 23\n",
      "[37 62 36 18 17 82 58 68 22  3 32 24 81 23] 50\n",
      "[62 36 18 17 82 58 68 22  3 32 24 81 23 50] 6\n",
      "[36 18 17 82 58 68 22  3 32 24 81 23 50  6] 6\n",
      "[18 17 82 58 68 22  3 32 24 81 23 50  6  6] 68\n",
      "[17 82 58 68 22  3 32 24 81 23 50  6  6 68] 84\n",
      "[82 58 68 22  3 32 24 81 23 50  6  6 68 84] 97\n",
      "[58 68 22  3 32 24 81 23 50  6  6 68 84 97] 5\n",
      "[68 22  3 32 24 81 23 50  6  6 68 84 97  5] 36\n",
      "[22  3 32 24 81 23 50  6  6 68 84 97  5 36] 15\n",
      "[ 3 32 24 81 23 50  6  6 68 84 97  5 36 15] 82\n",
      "[32 24 81 23 50  6  6 68 84 97  5 36 15 82] 96\n",
      "[24 81 23 50  6  6 68 84 97  5 36 15 82 96] 18\n",
      "[81 23 50  6  6 68 84 97  5 36 15 82 96 18] 3\n",
      "[23 50  6  6 68 84 97  5 36 15 82 96 18  3] 67\n",
      "[50  6  6 68 84 97  5 36 15 82 96 18  3 67] 0\n",
      "[ 6  6 68 84 97  5 36 15 82 96 18  3 67  0] 49\n",
      "[ 6 68 84 97  5 36 15 82 96 18  3 67  0 49] 44\n",
      "[68 84 97  5 36 15 82 96 18  3 67  0 49 44] 57\n",
      "[84 97  5 36 15 82 96 18  3 67  0 49 44 57] 70\n",
      "[97  5 36 15 82 96 18  3 67  0 49 44 57 70] 58\n",
      "[ 5 36 15 82 96 18  3 67  0 49 44 57 70 58] 56\n",
      "[36 15 82 96 18  3 67  0 49 44 57 70 58 56] 50\n",
      "[15 82 96 18  3 67  0 49 44 57 70 58 56 50] 57\n",
      "[82 96 18  3 67  0 49 44 57 70 58 56 50 57] 71\n",
      "[96 18  3 67  0 49 44 57 70 58 56 50 57 71] 39\n",
      "[18  3 67  0 49 44 57 70 58 56 50 57 71 39] 53\n",
      "[ 3 67  0 49 44 57 70 58 56 50 57 71 39 53] 50\n",
      "[67  0 49 44 57 70 58 56 50 57 71 39 53 50] 17\n",
      "[ 0 49 44 57 70 58 56 50 57 71 39 53 50 17] 66\n",
      "[49 44 57 70 58 56 50 57 71 39 53 50 17 66] 22\n",
      "[44 57 70 58 56 50 57 71 39 53 50 17 66 22] 38\n",
      "[57 70 58 56 50 57 71 39 53 50 17 66 22 38] 14\n",
      "[70 58 56 50 57 71 39 53 50 17 66 22 38 14] 88\n",
      "[58 56 50 57 71 39 53 50 17 66 22 38 14 88] 12\n",
      "[56 50 57 71 39 53 50 17 66 22 38 14 88 12] 56\n",
      "[50 57 71 39 53 50 17 66 22 38 14 88 12 56] 27\n",
      "[57 71 39 53 50 17 66 22 38 14 88 12 56 27] 16\n",
      "[71 39 53 50 17 66 22 38 14 88 12 56 27 16] 41\n",
      "[39 53 50 17 66 22 38 14 88 12 56 27 16 41] 32\n",
      "[53 50 17 66 22 38 14 88 12 56 27 16 41 32] 19\n",
      "[50 17 66 22 38 14 88 12 56 27 16 41 32 19] 40\n",
      "[17 66 22 38 14 88 12 56 27 16 41 32 19 40] 53\n",
      "[66 22 38 14 88 12 56 27 16 41 32 19 40 53] 90\n",
      "[22 38 14 88 12 56 27 16 41 32 19 40 53 90] 17\n",
      "[38 14 88 12 56 27 16 41 32 19 40 53 90 17] 0\n",
      "[14 88 12 56 27 16 41 32 19 40 53 90 17  0] 91\n",
      "[88 12 56 27 16 41 32 19 40 53 90 17  0 91] 29\n",
      "[12 56 27 16 41 32 19 40 53 90 17  0 91 29] 17\n",
      "[56 27 16 41 32 19 40 53 90 17  0 91 29 17] 42\n",
      "[27 16 41 32 19 40 53 90 17  0 91 29 17 42] 10\n",
      "[16 41 32 19 40 53 90 17  0 91 29 17 42 10] 82\n",
      "[41 32 19 40 53 90 17  0 91 29 17 42 10 82] 16\n",
      "[32 19 40 53 90 17  0 91 29 17 42 10 82 16] 72\n",
      "[19 40 53 90 17  0 91 29 17 42 10 82 16 72] 33\n",
      "[40 53 90 17  0 91 29 17 42 10 82 16 72 33] 90\n",
      "[53 90 17  0 91 29 17 42 10 82 16 72 33 90] 17\n",
      "[90 17  0 91 29 17 42 10 82 16 72 33 90 17] 97\n",
      "[17  0 91 29 17 42 10 82 16 72 33 90 17 97] 93\n",
      "[ 0 91 29 17 42 10 82 16 72 33 90 17 97 93] 72\n",
      "[91 29 17 42 10 82 16 72 33 90 17 97 93 72] 26\n",
      "[29 17 42 10 82 16 72 33 90 17 97 93 72 26] 38\n",
      "[17 42 10 82 16 72 33 90 17 97 93 72 26 38] 29\n",
      "[42 10 82 16 72 33 90 17 97 93 72 26 38 29] 33\n",
      "[10 82 16 72 33 90 17 97 93 72 26 38 29 33] 98\n",
      "[82 16 72 33 90 17 97 93 72 26 38 29 33 98] 75\n",
      "[16 72 33 90 17 97 93 72 26 38 29 33 98 75] 22\n",
      "[72 33 90 17 97 93 72 26 38 29 33 98 75 22] 75\n",
      "[33 90 17 97 93 72 26 38 29 33 98 75 22 75] 79\n",
      "[90 17 97 93 72 26 38 29 33 98 75 22 75 79] 10\n",
      "[17 97 93 72 26 38 29 33 98 75 22 75 79 10] 88\n",
      "[97 93 72 26 38 29 33 98 75 22 75 79 10 88] 78\n",
      "[93 72 26 38 29 33 98 75 22 75 79 10 88 78] 96\n",
      "[72 26 38 29 33 98 75 22 75 79 10 88 78 96] 25\n",
      "[26 38 29 33 98 75 22 75 79 10 88 78 96 25] 16\n",
      "[38 29 33 98 75 22 75 79 10 88 78 96 25 16] 95\n",
      "[29 33 98 75 22 75 79 10 88 78 96 25 16 95] 0\n",
      "[33 98 75 22 75 79 10 88 78 96 25 16 95  0] 15\n",
      "[98 75 22 75 79 10 88 78 96 25 16 95  0 15] 45\n",
      "[75 22 75 79 10 88 78 96 25 16 95  0 15 45] 39\n",
      "[22 75 79 10 88 78 96 25 16 95  0 15 45 39] 88\n",
      "[75 79 10 88 78 96 25 16 95  0 15 45 39 88] 90\n",
      "[79 10 88 78 96 25 16 95  0 15 45 39 88 90] 79\n",
      "[10 88 78 96 25 16 95  0 15 45 39 88 90 79] 40\n",
      "[88 78 96 25 16 95  0 15 45 39 88 90 79 40] 80\n",
      "[78 96 25 16 95  0 15 45 39 88 90 79 40 80] 43\n",
      "[96 25 16 95  0 15 45 39 88 90 79 40 80 43] 58\n",
      "[25 16 95  0 15 45 39 88 90 79 40 80 43 58] 78\n",
      "[16 95  0 15 45 39 88 90 79 40 80 43 58 78] 71\n",
      "[95  0 15 45 39 88 90 79 40 80 43 58 78 71] 76\n",
      "[ 0 15 45 39 88 90 79 40 80 43 58 78 71 76] 51\n",
      "[15 45 39 88 90 79 40 80 43 58 78 71 76 51] 40\n",
      "[45 39 88 90 79 40 80 43 58 78 71 76 51 40] 15\n",
      "[39 88 90 79 40 80 43 58 78 71 76 51 40 15] 2\n",
      "[88 90 79 40 80 43 58 78 71 76 51 40 15  2] 34\n",
      "[90 79 40 80 43 58 78 71 76 51 40 15  2 34] 52\n",
      "[79 40 80 43 58 78 71 76 51 40 15  2 34 52] 57\n",
      "[40 80 43 58 78 71 76 51 40 15  2 34 52 57] 74\n",
      "[80 43 58 78 71 76 51 40 15  2 34 52 57 74] 94\n",
      "[43 58 78 71 76 51 40 15  2 34 52 57 74 94] 43\n",
      "[58 78 71 76 51 40 15  2 34 52 57 74 94 43] 50\n",
      "[78 71 76 51 40 15  2 34 52 57 74 94 43 50] 64\n",
      "[71 76 51 40 15  2 34 52 57 74 94 43 50 64] 65\n",
      "[76 51 40 15  2 34 52 57 74 94 43 50 64 65] 29\n",
      "[51 40 15  2 34 52 57 74 94 43 50 64 65 29] 25\n",
      "[40 15  2 34 52 57 74 94 43 50 64 65 29 25] 97\n",
      "[15  2 34 52 57 74 94 43 50 64 65 29 25 97] 83\n",
      "[ 2 34 52 57 74 94 43 50 64 65 29 25 97 83] 0\n",
      "[34 52 57 74 94 43 50 64 65 29 25 97 83  0] 58\n",
      "[52 57 74 94 43 50 64 65 29 25 97 83  0 58] 33\n",
      "[57 74 94 43 50 64 65 29 25 97 83  0 58 33] 40\n",
      "[74 94 43 50 64 65 29 25 97 83  0 58 33 40] 14\n",
      "[94 43 50 64 65 29 25 97 83  0 58 33 40 14] 31\n",
      "[43 50 64 65 29 25 97 83  0 58 33 40 14 31] 37\n",
      "[50 64 65 29 25 97 83  0 58 33 40 14 31 37] 45\n",
      "[64 65 29 25 97 83  0 58 33 40 14 31 37 45] 92\n",
      "[65 29 25 97 83  0 58 33 40 14 31 37 45 92] 32\n",
      "[29 25 97 83  0 58 33 40 14 31 37 45 92 32] 7\n",
      "[25 97 83  0 58 33 40 14 31 37 45 92 32  7] 7\n",
      "[97 83  0 58 33 40 14 31 37 45 92 32  7  7] 44\n",
      "[83  0 58 33 40 14 31 37 45 92 32  7  7 44] 79\n",
      "[ 0 58 33 40 14 31 37 45 92 32  7  7 44 79] 2\n",
      "[58 33 40 14 31 37 45 92 32  7  7 44 79  2] 62\n",
      "[33 40 14 31 37 45 92 32  7  7 44 79  2 62] 24\n",
      "[40 14 31 37 45 92 32  7  7 44 79  2 62 24] 42\n",
      "[14 31 37 45 92 32  7  7 44 79  2 62 24 42] 24\n",
      "[31 37 45 92 32  7  7 44 79  2 62 24 42 24] 55\n",
      "[37 45 92 32  7  7 44 79  2 62 24 42 24 55] 95\n",
      "[45 92 32  7  7 44 79  2 62 24 42 24 55 95] 66\n",
      "[92 32  7  7 44 79  2 62 24 42 24 55 95 66] 94\n",
      "[32  7  7 44 79  2 62 24 42 24 55 95 66 94] 26\n",
      "[ 7  7 44 79  2 62 24 42 24 55 95 66 94 26] 69\n",
      "[ 7 44 79  2 62 24 42 24 55 95 66 94 26 69] 18\n",
      "[44 79  2 62 24 42 24 55 95 66 94 26 69 18] 66\n",
      "[79  2 62 24 42 24 55 95 66 94 26 69 18 66] 14\n",
      "[ 2 62 24 42 24 55 95 66 94 26 69 18 66 14] 0\n",
      "[62 24 42 24 55 95 66 94 26 69 18 66 14  0] 1\n",
      "[24 42 24 55 95 66 94 26 69 18 66 14  0  1] 81\n",
      "[42 24 55 95 66 94 26 69 18 66 14  0  1 81] 85\n",
      "[24 55 95 66 94 26 69 18 66 14  0  1 81 85] 91\n",
      "[55 95 66 94 26 69 18 66 14  0  1 81 85 91] 49\n",
      "[95 66 94 26 69 18 66 14  0  1 81 85 91 49] 75\n",
      "[66 94 26 69 18 66 14  0  1 81 85 91 49 75] 31\n",
      "[94 26 69 18 66 14  0  1 81 85 91 49 75 31] 55\n",
      "[26 69 18 66 14  0  1 81 85 91 49 75 31 55] 76\n",
      "[69 18 66 14  0  1 81 85 91 49 75 31 55 76] 50\n",
      "[18 66 14  0  1 81 85 91 49 75 31 55 76 50] 86\n",
      "[66 14  0  1 81 85 91 49 75 31 55 76 50 86] 38\n",
      "[14  0  1 81 85 91 49 75 31 55 76 50 86 38] 34\n",
      "[ 0  1 81 85 91 49 75 31 55 76 50 86 38 34] 1\n",
      "[ 1 81 85 91 49 75 31 55 76 50 86 38 34  1] 50\n",
      "[81 85 91 49 75 31 55 76 50 86 38 34  1 50] 43\n",
      "[85 91 49 75 31 55 76 50 86 38 34  1 50 43] 12\n",
      "[91 49 75 31 55 76 50 86 38 34  1 50 43 12] 52\n",
      "[49 75 31 55 76 50 86 38 34  1 50 43 12 52] 43\n",
      "[75 31 55 76 50 86 38 34  1 50 43 12 52 43] 16\n",
      "[31 55 76 50 86 38 34  1 50 43 12 52 43 16] 53\n",
      "[55 76 50 86 38 34  1 50 43 12 52 43 16 53] 33\n",
      "[76 50 86 38 34  1 50 43 12 52 43 16 53 33] 50\n",
      "[50 86 38 34  1 50 43 12 52 43 16 53 33 50] 14\n",
      "[86 38 34  1 50 43 12 52 43 16 53 33 50 14] 37\n",
      "[38 34  1 50 43 12 52 43 16 53 33 50 14 37] 54\n",
      "[34  1 50 43 12 52 43 16 53 33 50 14 37 54] 93\n",
      "[ 1 50 43 12 52 43 16 53 33 50 14 37 54 93] 75\n",
      "[50 43 12 52 43 16 53 33 50 14 37 54 93 75] 11\n",
      "[43 12 52 43 16 53 33 50 14 37 54 93 75 11] 0\n",
      "[12 52 43 16 53 33 50 14 37 54 93 75 11  0] 0\n",
      "[52 43 16 53 33 50 14 37 54 93 75 11  0  0] 46\n",
      "[43 16 53 33 50 14 37 54 93 75 11  0  0 46] 30\n",
      "[16 53 33 50 14 37 54 93 75 11  0  0 46 30] 33\n",
      "[53 33 50 14 37 54 93 75 11  0  0 46 30 33] 45\n",
      "[33 50 14 37 54 93 75 11  0  0 46 30 33 45] 68\n",
      "[50 14 37 54 93 75 11  0  0 46 30 33 45 68] 16\n",
      "[14 37 54 93 75 11  0  0 46 30 33 45 68 16] 12\n",
      "[37 54 93 75 11  0  0 46 30 33 45 68 16 12] 32\n",
      "[54 93 75 11  0  0 46 30 33 45 68 16 12 32] 82\n",
      "[93 75 11  0  0 46 30 33 45 68 16 12 32 82] 92\n",
      "[75 11  0  0 46 30 33 45 68 16 12 32 82 92] 83\n",
      "[11  0  0 46 30 33 45 68 16 12 32 82 92 83] 59\n",
      "[ 0  0 46 30 33 45 68 16 12 32 82 92 83 59] 84\n",
      "[ 0 46 30 33 45 68 16 12 32 82 92 83 59 84] 93\n",
      "[46 30 33 45 68 16 12 32 82 92 83 59 84 93] 56\n",
      "[30 33 45 68 16 12 32 82 92 83 59 84 93 56] 91\n",
      "[33 45 68 16 12 32 82 92 83 59 84 93 56 91] 83\n",
      "[45 68 16 12 32 82 92 83 59 84 93 56 91 83] 61\n",
      "[68 16 12 32 82 92 83 59 84 93 56 91 83 61] 64\n",
      "[16 12 32 82 92 83 59 84 93 56 91 83 61 64] 53\n",
      "[12 32 82 92 83 59 84 93 56 91 83 61 64 53] 55\n",
      "[32 82 92 83 59 84 93 56 91 83 61 64 53 55] 94\n",
      "[82 92 83 59 84 93 56 91 83 61 64 53 55 94] 69\n",
      "[92 83 59 84 93 56 91 83 61 64 53 55 94 69] 88\n",
      "[83 59 84 93 56 91 83 61 64 53 55 94 69 88] 22\n",
      "[59 84 93 56 91 83 61 64 53 55 94 69 88 22] 75\n",
      "[84 93 56 91 83 61 64 53 55 94 69 88 22 75] 98\n",
      "[93 56 91 83 61 64 53 55 94 69 88 22 75 98] 93\n",
      "[56 91 83 61 64 53 55 94 69 88 22 75 98 93] 36\n",
      "[91 83 61 64 53 55 94 69 88 22 75 98 93 36] 0\n",
      "[83 61 64 53 55 94 69 88 22 75 98 93 36  0] 51\n",
      "[61 64 53 55 94 69 88 22 75 98 93 36  0 51] 31\n",
      "[64 53 55 94 69 88 22 75 98 93 36  0 51 31] 79\n",
      "[53 55 94 69 88 22 75 98 93 36  0 51 31 79] 78\n",
      "[55 94 69 88 22 75 98 93 36  0 51 31 79 78] 2\n",
      "[94 69 88 22 75 98 93 36  0 51 31 79 78  2] 8\n",
      "[69 88 22 75 98 93 36  0 51 31 79 78  2  8] 54\n",
      "[88 22 75 98 93 36  0 51 31 79 78  2  8 54] 20\n",
      "[22 75 98 93 36  0 51 31 79 78  2  8 54 20] 98\n",
      "[75 98 93 36  0 51 31 79 78  2  8 54 20 98] 6\n",
      "[98 93 36  0 51 31 79 78  2  8 54 20 98  6] 2\n",
      "[93 36  0 51 31 79 78  2  8 54 20 98  6  2] 64\n",
      "[36  0 51 31 79 78  2  8 54 20 98  6  2 64] 30\n",
      "[ 0 51 31 79 78  2  8 54 20 98  6  2 64 30] 60\n",
      "[51 31 79 78  2  8 54 20 98  6  2 64 30 60] 48\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[40]\n",
      "  [12]\n",
      "  [72]\n",
      "  [28]\n",
      "  [49]\n",
      "  [16]\n",
      "  [74]\n",
      "  [67]\n",
      "  [79]\n",
      "  [71]\n",
      "  [61]\n",
      "  [68]\n",
      "  [51]\n",
      "  [ 2]]\n",
      "\n",
      " [[12]\n",
      "  [72]\n",
      "  [28]\n",
      "  [49]\n",
      "  [16]\n",
      "  [74]\n",
      "  [67]\n",
      "  [79]\n",
      "  [71]\n",
      "  [61]\n",
      "  [68]\n",
      "  [51]\n",
      "  [ 2]\n",
      "  [42]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = tf.keras.Sequential()\n",
    "model4.add(layers.LSTM(100, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model4.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.rnn.lstm.LSTM at 0x7f9f2cf49f10>,\n",
       " <keras.layers.core.dense.Dense at 0x7f9f4ab9d150>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer=tf.keras.optimizers.Adam(0.02), loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 13ms/step - loss: 2608113.5000 - accuracy: 0.0144\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2833.0610 - accuracy: 0.0103\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2217.3071 - accuracy: 0.0123\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2147.4602 - accuracy: 0.0103\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1849.7578 - accuracy: 0.0082\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1007.8384 - accuracy: 0.0103\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1047.7747 - accuracy: 0.0103\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1034.8218 - accuracy: 0.0103\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 994.0112 - accuracy: 0.0103\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 991.4382 - accuracy: 0.0103\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 979.8030 - accuracy: 0.0103\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 976.2316 - accuracy: 0.0103\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 981.1766 - accuracy: 0.0103\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 978.8137 - accuracy: 0.0103\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 974.2750 - accuracy: 0.0103\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 972.5900 - accuracy: 0.0103\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 978.1972 - accuracy: 0.0103\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 992.6348 - accuracy: 0.0103\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 974.3578 - accuracy: 0.0103\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 957.6954 - accuracy: 0.0103\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 962.0305 - accuracy: 0.0103\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 965.2435 - accuracy: 0.0103\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 966.8953 - accuracy: 0.0103\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 967.0594 - accuracy: 0.0103\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 969.4475 - accuracy: 0.0103\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 959.9813 - accuracy: 0.0103\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 961.2855 - accuracy: 0.0103\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 984.8503 - accuracy: 0.0103\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 985.8301 - accuracy: 0.0103\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 953.7755 - accuracy: 0.0103\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 963.2487 - accuracy: 0.0103\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 969.8303 - accuracy: 0.0103\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 953.5048 - accuracy: 0.0103\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 968.1257 - accuracy: 0.0103\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 954.2474 - accuracy: 0.0103\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 964.8654 - accuracy: 0.0103\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 961.9651 - accuracy: 0.0103\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 959.2969 - accuracy: 0.0103\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 973.6714 - accuracy: 0.0103\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 951.0754 - accuracy: 0.0103\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 970.3731 - accuracy: 0.0103\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 959.0720 - accuracy: 0.0103\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 962.4964 - accuracy: 0.0103\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 953.0795 - accuracy: 0.0103\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 956.1553 - accuracy: 0.0103\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 988.9026 - accuracy: 0.0103\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 950.9980 - accuracy: 0.0103\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 952.4877 - accuracy: 0.0103\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 974.1446 - accuracy: 0.0103\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 953.9250 - accuracy: 0.0103\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 945.7625 - accuracy: 0.0103\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 943.7751 - accuracy: 0.0103\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 960.9209 - accuracy: 0.0103\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 951.1247 - accuracy: 0.0103\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 943.4977 - accuracy: 0.0103\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 947.5411 - accuracy: 0.0103\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 945.2150 - accuracy: 0.0103\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 952.3970 - accuracy: 0.0103\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 954.2809 - accuracy: 0.0103\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 957.8753 - accuracy: 0.0103\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 954.3463 - accuracy: 0.0103\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 966.3317 - accuracy: 0.0103\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 978.7180 - accuracy: 0.0103\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 954.2719 - accuracy: 0.0103\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 959.9408 - accuracy: 0.0103\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 955.6402 - accuracy: 0.0103\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 958.9792 - accuracy: 0.0103\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 965.1867 - accuracy: 0.0103\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 981.9166 - accuracy: 0.0103\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 971.4929 - accuracy: 0.0103\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 975.7650 - accuracy: 0.0103\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 968.5469 - accuracy: 0.0103\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 946.5654 - accuracy: 0.0103\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 967.5059 - accuracy: 0.0103\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 950.6093 - accuracy: 0.0103\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 950.1872 - accuracy: 0.0103\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 951.7007 - accuracy: 0.0103\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 947.8729 - accuracy: 0.0103\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 949.5554 - accuracy: 0.0103\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 948.7600 - accuracy: 0.0103\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 949.2544 - accuracy: 0.0103\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 948.3055 - accuracy: 0.0103\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 955.2012 - accuracy: 0.0103\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 951.4227 - accuracy: 0.0103\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 947.8214 - accuracy: 0.0103\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 949.5201 - accuracy: 0.0103\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 960.1658 - accuracy: 0.0103\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 966.5720 - accuracy: 0.0103\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 947.6915 - accuracy: 0.0103\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 975.3253 - accuracy: 0.0103\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 942.4144 - accuracy: 0.0103\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 948.7924 - accuracy: 0.0103\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 945.8160 - accuracy: 0.0103\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 952.7492 - accuracy: 0.0103\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 951.6472 - accuracy: 0.0103\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 947.9998 - accuracy: 0.0103\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 945.4983 - accuracy: 0.0103\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 947.0510 - accuracy: 0.0103\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 949.8633 - accuracy: 0.0103\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 951.4232 - accuracy: 0.0103\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 955.4211 - accuracy: 0.0103\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 952.0233 - accuracy: 0.0103\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 945.7098 - accuracy: 0.0103\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 951.4404 - accuracy: 0.0103\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 963.6940 - accuracy: 0.0103\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 959.3007 - accuracy: 0.0103\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 960.4650 - accuracy: 0.0103\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7219272.5000 - accuracy: 0.0103\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4787.8911 - accuracy: 0.0226\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1142.1989 - accuracy: 0.0103\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1133.0696 - accuracy: 0.0103\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 1035.2931 - accuracy: 0.0103\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1024.8987 - accuracy: 0.0103\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1006.6002 - accuracy: 0.0103\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1020.3450 - accuracy: 0.0103\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1032.0133 - accuracy: 0.0103\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1010.1597 - accuracy: 0.0103\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1000.8568 - accuracy: 0.0103\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1014.7497 - accuracy: 0.0103\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 970.5565 - accuracy: 0.0103\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 972.7639 - accuracy: 0.0103\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 962.8857 - accuracy: 0.0103\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 963.5005 - accuracy: 0.0103\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 959.7626 - accuracy: 0.0103\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 960.5011 - accuracy: 0.0103\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 967.0117 - accuracy: 0.0103\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1019.5933 - accuracy: 0.0103\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 983.0598 - accuracy: 0.0103\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 966.2529 - accuracy: 0.0103\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 982.6026 - accuracy: 0.0103\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 980.1375 - accuracy: 0.0103\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 993.2765 - accuracy: 0.0103\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 969.4692 - accuracy: 0.0103\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 959.2213 - accuracy: 0.0103\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 964.7786 - accuracy: 0.0103\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 974.7071 - accuracy: 0.0103\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 965.3712 - accuracy: 0.0103\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 954.8792 - accuracy: 0.0103\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 957.4653 - accuracy: 0.0103\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 948.2766 - accuracy: 0.0103\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 950.2100 - accuracy: 0.0103\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 967.9274 - accuracy: 0.0103\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 958.7502 - accuracy: 0.0103\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 959.4229 - accuracy: 0.0103\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 958.3090 - accuracy: 0.0103\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 949.0245 - accuracy: 0.0103\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 951.2554 - accuracy: 0.0103\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 945.2546 - accuracy: 0.0103\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 945.3597 - accuracy: 0.0103\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4362.2339 - accuracy: 0.0103\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9756.0283 - accuracy: 0.0432\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1600.6725 - accuracy: 0.0123\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1053.3619 - accuracy: 0.0103\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1077.1158 - accuracy: 0.0103\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1011.1331 - accuracy: 0.0103\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1069.4524 - accuracy: 0.0103\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1114.3730 - accuracy: 0.0103\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1139.4391 - accuracy: 0.0103\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1119.6488 - accuracy: 0.0103\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1134.6013 - accuracy: 0.0103\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1130.6383 - accuracy: 0.0103\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1191.9447 - accuracy: 0.0103\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1051.3264 - accuracy: 0.0103\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1074.1780 - accuracy: 0.0103\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1049.4957 - accuracy: 0.0103\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1036.1171 - accuracy: 0.0103\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1028.0104 - accuracy: 0.0103\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1041.5574 - accuracy: 0.0103\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1032.6786 - accuracy: 0.0103\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1006.5145 - accuracy: 0.0103\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1024.4678 - accuracy: 0.0103\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1010.9680 - accuracy: 0.0103\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 981.9122 - accuracy: 0.0103\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1060.2717 - accuracy: 0.0103\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 993.1985 - accuracy: 0.0103\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 984.9557 - accuracy: 0.0103\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 979.0454 - accuracy: 0.0103\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 971.8687 - accuracy: 0.0103\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 973.1094 - accuracy: 0.0103\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 969.5780 - accuracy: 0.0103\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 990.2740 - accuracy: 0.0103\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 973.5699 - accuracy: 0.0103\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 989.5177 - accuracy: 0.0103\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 975.0771 - accuracy: 0.0103\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 978.0594 - accuracy: 0.0103\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 966.7641 - accuracy: 0.0103\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 973.1857 - accuracy: 0.0103\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 992.0987 - accuracy: 0.0103\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 978.0354 - accuracy: 0.0103\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 961.8361 - accuracy: 0.0103\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 958.5100 - accuracy: 0.0103\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 997.9914 - accuracy: 0.0103\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 960.8637 - accuracy: 0.0103\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 977.7205 - accuracy: 0.0103\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 965.5117 - accuracy: 0.0103\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 958.8411 - accuracy: 0.0103\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 962.4463 - accuracy: 0.0103\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 999.4927 - accuracy: 0.0103\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 965.8667 - accuracy: 0.0103\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 958.9824 - accuracy: 0.0103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f2cf2b410>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 31, 37, 45, 92, 32,  7,  7, 44, 79,  2, 62, 24, 42, 24, 55, 95,\n",
       "       66, 94, 26, 69, 18, 66, 14,  0,  1, 81, 85, 91, 49, 75, 31, 55, 76,\n",
       "       50, 86, 38, 34,  1, 50, 43, 12, 52, 43, 16, 53, 33, 50, 14, 37, 54,\n",
       "       93, 75, 11,  0,  0, 46, 30, 33, 45, 68, 16, 12, 32, 82, 92, 83, 59,\n",
       "       84, 93, 56, 91, 83, 61, 64, 53, 55, 94, 69, 88, 22, 75, 98, 93, 36,\n",
       "        0, 51, 31, 79, 78,  2,  8, 54, 20, 98,  6,  2, 64, 30, 60])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = arr1[-101:-1]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[31],\n",
       "        [79],\n",
       "        [78],\n",
       "        [ 2],\n",
       "        [ 8],\n",
       "        [54],\n",
       "        [20],\n",
       "        [98],\n",
       "        [ 6],\n",
       "        [ 2],\n",
       "        [64],\n",
       "        [30],\n",
       "        [60],\n",
       "        [48]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = arr1[-14:]\n",
    "test_data = test_data.reshape((1, n_steps, n_features))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.42857142857143"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 463ms/step\n",
      "[[55.269073]]\n"
     ]
    }
   ],
   "source": [
    "predictNextNumber = model4.predict(test_data, verbose=1)\n",
    "print(predictNextNumber)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f293f16398db128e85df277de8eb5f9ab0a1b28857fa0f1c8543245825f1b931"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
