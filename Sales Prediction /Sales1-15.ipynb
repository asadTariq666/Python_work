{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all essential libraries\n",
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "## Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>site off</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>88</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      MB033 MB034 MB035 MB036\n",
       "0 2021-01-01  site off     4    71    40\n",
       "1 2021-01-02        88    66    52    12\n",
       "2 2021-01-03        52    40    54    72\n",
       "3 2021-01-04        49    34    32    28\n",
       "4 2021-01-05        82    32    85    49"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Book01.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MB033</th>\n",
       "      <th>MB034</th>\n",
       "      <th>MB035</th>\n",
       "      <th>MB036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>70</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  MB033 MB034 MB035 MB036\n",
       "495 2022-05-11    70    42     6     2\n",
       "496 2022-05-12    92     3    99    64\n",
       "497 2022-05-13    84    82    24    30\n",
       "498 2022-05-14    98    50    19    60\n",
       "499 2022-05-15     3     0    66    48"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     0\n",
       "MB033    0\n",
       "MB034    0\n",
       "MB035    0\n",
       "MB036    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in train data\n",
    "df.isnull().sum()\n",
    " #No missing valuues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for better understanding of the data, We can eloborate as month and weekday wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      site off\n",
       "1            88\n",
       "2            52\n",
       "3            49\n",
       "4            82\n",
       "         ...   \n",
       "495          70\n",
       "496          92\n",
       "497          84\n",
       "498          98\n",
       "499           3\n",
       "Name: MB033, Length: 500, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MB033']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MB033'] = df['MB033'].replace(['site off'],0)\n",
    "df['MB034'] = df['MB034'].replace(['site off'],0)\n",
    "df['MB035'] = df['MB035'].replace(['site off'],0)\n",
    "df['MB036'] = df['MB036'].replace(['site off'],0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  88,  52,  49,  82,   0,  62,  77,  60,  37,  58,  64,  88,\n",
       "        49,  38,  87,  22,  40,  85,  54,  87,  10,  60,  23,  66,  67,\n",
       "        11,  76,  40,  68,  63,   0,  72,  67,  42,  85,  11,  22,  91,\n",
       "        68,  19,  74,  45,   7,  57,   0,  54,  24,  80,  52,  51,  18,\n",
       "         7,  72,  85,  77,  35,  93,  64,   0,  70,  97,   6,  42,  52,\n",
       "        98,  11,  36,  82,  28,  84,   2,  68,  67,  54,   5,  82,  95,\n",
       "        42,  72,  95,  94,  15,  42,  46,  95,  26,  91,  67,  31,   0,\n",
       "        51,  30,  24,  72,  13, 100,  36,  69,  76,   5,  52,  71,  62,\n",
       "        60,  57,  41,  39,  63,  63,  38,  93,   2,  39,  93,  44,  77,\n",
       "        97,  54,  14,   0,  78,  27,  65,   9,   8,  36,  26,  54,  30,\n",
       "        87,  39,  49,  20,  41,  33,  70,  89,   8,  76,  14,  63,  41,\n",
       "        58,  61,  56,  20,  88,  58,  71,  55,   0,  88,  45,  39,  29,\n",
       "        97,   1,  25,  23,  15,  47,  15,  47,  75,  21,  39,  30,  65,\n",
       "        33,  94,   9,  70,  74,  72,  19,  38,  40,  71,  27,  14,   0,\n",
       "         8,  13,  27,  75,  58,   5,  91,  57,   5,  61,  84,  64,  83,\n",
       "        60,  11,  81,  47,  74,  37,  76,  56,  19,  56,  35,  82,  35,\n",
       "        40,  88,  77,  28,   0,  14,  39,  19,   2,  45,  21,  86,  44,\n",
       "        81,  61,  63,  44,  45,  18,  40,  95,  44,  30,  11,  60,   3,\n",
       "        37,  91,  63,  29,  84,   9,  28,  63,  59,   0,  81,  80,  60,\n",
       "        87,  28,  46,  28,  60,  25,  98,  84,  75,  45,  69,   8,  43,\n",
       "        22,  15,  70,  87,  63,   1,   4,  81,  69,  57,  67,  61,  94,\n",
       "         0,  14,  41,  80,  21,  17,  94,  98,  62,  80,  53,  86,  50,\n",
       "        21,  70,  94,  75,  51,  35,  76,  64,  46,  43,  62,  46,  43,\n",
       "        56,  79,  32,  50,   2,   0,  86,  34,  26,  61,  79,  76,  71,\n",
       "        65,  89,   9,  57,  74,   5,  84,   3,  93,  43,  69,  83,  69,\n",
       "        40,  14,  82,  37,  49,  37,  31,  61,   6,   0,  74,  39,  69,\n",
       "        32,   7,  26,  13,  88,  61,  65,  30,   9,  62,  81,  12,  64,\n",
       "        22,  73,  72,   6,  15,  99,  34,  13,  61,  77,  35,  46,   4,\n",
       "        54,   0,  71,  53,  11,  81,  33,  77,  39,  47,  54,  77,  76,\n",
       "        28,  38,  72,  31,  54,  38,  58,  46,  18,  49,  41,   3,  71,\n",
       "        41,  24,  94,  38,   2,  99,   0,  56,  17,   8,  63,  86,  67,\n",
       "        40,   7,  38,  25,   3,  58,  92,  26,  98,  15,  44,  24,  77,\n",
       "        29,  42,  43,  82,  44,  59,  85,  86,   0,  92,  66,  59,  30,\n",
       "        69,  53,  50,  64,  12,  95,  47,  38,  94,  84,  40,  10,  62,\n",
       "        98,  89,  31,  59,  68,  95,  97,  91,  89,  57,  87,  34,  87,\n",
       "         0,  35,  25,  66,  53,  21,  12,  77,  31,  71,  49,  99,   7,\n",
       "        15,  99,  86,  69,  92,  61,  52,  68,  83,  67,  13,  77,  15,\n",
       "        68,  48,  80,  91,   0,  35,  28,  97,  25,  13,  24,  22,  24,\n",
       "         1,  70,  92,  84,  98,   3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = df['MB033'].values\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def splitSequence(seq, n_steps):\n",
    "    \n",
    "    #Declare X and y as empty list\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        #get the last index\n",
    "        lastIndex = i + n_steps\n",
    "        \n",
    "        #if lastIndex is greater than length of sequence then break\n",
    "        if lastIndex > len(seq) - 1:\n",
    "            break\n",
    "            \n",
    "        #Create input and output sequence\n",
    "        seq_X, seq_y = seq[i:lastIndex], seq[lastIndex]\n",
    "        \n",
    "        #append seq_X, seq_y in X and y list\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        pass\n",
    "    #Convert X and y into numpy array\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y \n",
    "    \n",
    "    pass\n",
    "\n",
    "n_steps = 10\n",
    "X, y = splitSequence(arr1, n_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((490, 10), (490,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 88 52 49 82  0 62 77 60 37] 58\n",
      "[88 52 49 82  0 62 77 60 37 58] 64\n",
      "[52 49 82  0 62 77 60 37 58 64] 88\n",
      "[49 82  0 62 77 60 37 58 64 88] 49\n",
      "[82  0 62 77 60 37 58 64 88 49] 38\n",
      "[ 0 62 77 60 37 58 64 88 49 38] 87\n",
      "[62 77 60 37 58 64 88 49 38 87] 22\n",
      "[77 60 37 58 64 88 49 38 87 22] 40\n",
      "[60 37 58 64 88 49 38 87 22 40] 85\n",
      "[37 58 64 88 49 38 87 22 40 85] 54\n",
      "[58 64 88 49 38 87 22 40 85 54] 87\n",
      "[64 88 49 38 87 22 40 85 54 87] 10\n",
      "[88 49 38 87 22 40 85 54 87 10] 60\n",
      "[49 38 87 22 40 85 54 87 10 60] 23\n",
      "[38 87 22 40 85 54 87 10 60 23] 66\n",
      "[87 22 40 85 54 87 10 60 23 66] 67\n",
      "[22 40 85 54 87 10 60 23 66 67] 11\n",
      "[40 85 54 87 10 60 23 66 67 11] 76\n",
      "[85 54 87 10 60 23 66 67 11 76] 40\n",
      "[54 87 10 60 23 66 67 11 76 40] 68\n",
      "[87 10 60 23 66 67 11 76 40 68] 63\n",
      "[10 60 23 66 67 11 76 40 68 63] 0\n",
      "[60 23 66 67 11 76 40 68 63  0] 72\n",
      "[23 66 67 11 76 40 68 63  0 72] 67\n",
      "[66 67 11 76 40 68 63  0 72 67] 42\n",
      "[67 11 76 40 68 63  0 72 67 42] 85\n",
      "[11 76 40 68 63  0 72 67 42 85] 11\n",
      "[76 40 68 63  0 72 67 42 85 11] 22\n",
      "[40 68 63  0 72 67 42 85 11 22] 91\n",
      "[68 63  0 72 67 42 85 11 22 91] 68\n",
      "[63  0 72 67 42 85 11 22 91 68] 19\n",
      "[ 0 72 67 42 85 11 22 91 68 19] 74\n",
      "[72 67 42 85 11 22 91 68 19 74] 45\n",
      "[67 42 85 11 22 91 68 19 74 45] 7\n",
      "[42 85 11 22 91 68 19 74 45  7] 57\n",
      "[85 11 22 91 68 19 74 45  7 57] 0\n",
      "[11 22 91 68 19 74 45  7 57  0] 54\n",
      "[22 91 68 19 74 45  7 57  0 54] 24\n",
      "[91 68 19 74 45  7 57  0 54 24] 80\n",
      "[68 19 74 45  7 57  0 54 24 80] 52\n",
      "[19 74 45  7 57  0 54 24 80 52] 51\n",
      "[74 45  7 57  0 54 24 80 52 51] 18\n",
      "[45  7 57  0 54 24 80 52 51 18] 7\n",
      "[ 7 57  0 54 24 80 52 51 18  7] 72\n",
      "[57  0 54 24 80 52 51 18  7 72] 85\n",
      "[ 0 54 24 80 52 51 18  7 72 85] 77\n",
      "[54 24 80 52 51 18  7 72 85 77] 35\n",
      "[24 80 52 51 18  7 72 85 77 35] 93\n",
      "[80 52 51 18  7 72 85 77 35 93] 64\n",
      "[52 51 18  7 72 85 77 35 93 64] 0\n",
      "[51 18  7 72 85 77 35 93 64  0] 70\n",
      "[18  7 72 85 77 35 93 64  0 70] 97\n",
      "[ 7 72 85 77 35 93 64  0 70 97] 6\n",
      "[72 85 77 35 93 64  0 70 97  6] 42\n",
      "[85 77 35 93 64  0 70 97  6 42] 52\n",
      "[77 35 93 64  0 70 97  6 42 52] 98\n",
      "[35 93 64  0 70 97  6 42 52 98] 11\n",
      "[93 64  0 70 97  6 42 52 98 11] 36\n",
      "[64  0 70 97  6 42 52 98 11 36] 82\n",
      "[ 0 70 97  6 42 52 98 11 36 82] 28\n",
      "[70 97  6 42 52 98 11 36 82 28] 84\n",
      "[97  6 42 52 98 11 36 82 28 84] 2\n",
      "[ 6 42 52 98 11 36 82 28 84  2] 68\n",
      "[42 52 98 11 36 82 28 84  2 68] 67\n",
      "[52 98 11 36 82 28 84  2 68 67] 54\n",
      "[98 11 36 82 28 84  2 68 67 54] 5\n",
      "[11 36 82 28 84  2 68 67 54  5] 82\n",
      "[36 82 28 84  2 68 67 54  5 82] 95\n",
      "[82 28 84  2 68 67 54  5 82 95] 42\n",
      "[28 84  2 68 67 54  5 82 95 42] 72\n",
      "[84  2 68 67 54  5 82 95 42 72] 95\n",
      "[ 2 68 67 54  5 82 95 42 72 95] 94\n",
      "[68 67 54  5 82 95 42 72 95 94] 15\n",
      "[67 54  5 82 95 42 72 95 94 15] 42\n",
      "[54  5 82 95 42 72 95 94 15 42] 46\n",
      "[ 5 82 95 42 72 95 94 15 42 46] 95\n",
      "[82 95 42 72 95 94 15 42 46 95] 26\n",
      "[95 42 72 95 94 15 42 46 95 26] 91\n",
      "[42 72 95 94 15 42 46 95 26 91] 67\n",
      "[72 95 94 15 42 46 95 26 91 67] 31\n",
      "[95 94 15 42 46 95 26 91 67 31] 0\n",
      "[94 15 42 46 95 26 91 67 31  0] 51\n",
      "[15 42 46 95 26 91 67 31  0 51] 30\n",
      "[42 46 95 26 91 67 31  0 51 30] 24\n",
      "[46 95 26 91 67 31  0 51 30 24] 72\n",
      "[95 26 91 67 31  0 51 30 24 72] 13\n",
      "[26 91 67 31  0 51 30 24 72 13] 100\n",
      "[ 91  67  31   0  51  30  24  72  13 100] 36\n",
      "[ 67  31   0  51  30  24  72  13 100  36] 69\n",
      "[ 31   0  51  30  24  72  13 100  36  69] 76\n",
      "[  0  51  30  24  72  13 100  36  69  76] 5\n",
      "[ 51  30  24  72  13 100  36  69  76   5] 52\n",
      "[ 30  24  72  13 100  36  69  76   5  52] 71\n",
      "[ 24  72  13 100  36  69  76   5  52  71] 62\n",
      "[ 72  13 100  36  69  76   5  52  71  62] 60\n",
      "[ 13 100  36  69  76   5  52  71  62  60] 57\n",
      "[100  36  69  76   5  52  71  62  60  57] 41\n",
      "[36 69 76  5 52 71 62 60 57 41] 39\n",
      "[69 76  5 52 71 62 60 57 41 39] 63\n",
      "[76  5 52 71 62 60 57 41 39 63] 63\n",
      "[ 5 52 71 62 60 57 41 39 63 63] 38\n",
      "[52 71 62 60 57 41 39 63 63 38] 93\n",
      "[71 62 60 57 41 39 63 63 38 93] 2\n",
      "[62 60 57 41 39 63 63 38 93  2] 39\n",
      "[60 57 41 39 63 63 38 93  2 39] 93\n",
      "[57 41 39 63 63 38 93  2 39 93] 44\n",
      "[41 39 63 63 38 93  2 39 93 44] 77\n",
      "[39 63 63 38 93  2 39 93 44 77] 97\n",
      "[63 63 38 93  2 39 93 44 77 97] 54\n",
      "[63 38 93  2 39 93 44 77 97 54] 14\n",
      "[38 93  2 39 93 44 77 97 54 14] 0\n",
      "[93  2 39 93 44 77 97 54 14  0] 78\n",
      "[ 2 39 93 44 77 97 54 14  0 78] 27\n",
      "[39 93 44 77 97 54 14  0 78 27] 65\n",
      "[93 44 77 97 54 14  0 78 27 65] 9\n",
      "[44 77 97 54 14  0 78 27 65  9] 8\n",
      "[77 97 54 14  0 78 27 65  9  8] 36\n",
      "[97 54 14  0 78 27 65  9  8 36] 26\n",
      "[54 14  0 78 27 65  9  8 36 26] 54\n",
      "[14  0 78 27 65  9  8 36 26 54] 30\n",
      "[ 0 78 27 65  9  8 36 26 54 30] 87\n",
      "[78 27 65  9  8 36 26 54 30 87] 39\n",
      "[27 65  9  8 36 26 54 30 87 39] 49\n",
      "[65  9  8 36 26 54 30 87 39 49] 20\n",
      "[ 9  8 36 26 54 30 87 39 49 20] 41\n",
      "[ 8 36 26 54 30 87 39 49 20 41] 33\n",
      "[36 26 54 30 87 39 49 20 41 33] 70\n",
      "[26 54 30 87 39 49 20 41 33 70] 89\n",
      "[54 30 87 39 49 20 41 33 70 89] 8\n",
      "[30 87 39 49 20 41 33 70 89  8] 76\n",
      "[87 39 49 20 41 33 70 89  8 76] 14\n",
      "[39 49 20 41 33 70 89  8 76 14] 63\n",
      "[49 20 41 33 70 89  8 76 14 63] 41\n",
      "[20 41 33 70 89  8 76 14 63 41] 58\n",
      "[41 33 70 89  8 76 14 63 41 58] 61\n",
      "[33 70 89  8 76 14 63 41 58 61] 56\n",
      "[70 89  8 76 14 63 41 58 61 56] 20\n",
      "[89  8 76 14 63 41 58 61 56 20] 88\n",
      "[ 8 76 14 63 41 58 61 56 20 88] 58\n",
      "[76 14 63 41 58 61 56 20 88 58] 71\n",
      "[14 63 41 58 61 56 20 88 58 71] 55\n",
      "[63 41 58 61 56 20 88 58 71 55] 0\n",
      "[41 58 61 56 20 88 58 71 55  0] 88\n",
      "[58 61 56 20 88 58 71 55  0 88] 45\n",
      "[61 56 20 88 58 71 55  0 88 45] 39\n",
      "[56 20 88 58 71 55  0 88 45 39] 29\n",
      "[20 88 58 71 55  0 88 45 39 29] 97\n",
      "[88 58 71 55  0 88 45 39 29 97] 1\n",
      "[58 71 55  0 88 45 39 29 97  1] 25\n",
      "[71 55  0 88 45 39 29 97  1 25] 23\n",
      "[55  0 88 45 39 29 97  1 25 23] 15\n",
      "[ 0 88 45 39 29 97  1 25 23 15] 47\n",
      "[88 45 39 29 97  1 25 23 15 47] 15\n",
      "[45 39 29 97  1 25 23 15 47 15] 47\n",
      "[39 29 97  1 25 23 15 47 15 47] 75\n",
      "[29 97  1 25 23 15 47 15 47 75] 21\n",
      "[97  1 25 23 15 47 15 47 75 21] 39\n",
      "[ 1 25 23 15 47 15 47 75 21 39] 30\n",
      "[25 23 15 47 15 47 75 21 39 30] 65\n",
      "[23 15 47 15 47 75 21 39 30 65] 33\n",
      "[15 47 15 47 75 21 39 30 65 33] 94\n",
      "[47 15 47 75 21 39 30 65 33 94] 9\n",
      "[15 47 75 21 39 30 65 33 94  9] 70\n",
      "[47 75 21 39 30 65 33 94  9 70] 74\n",
      "[75 21 39 30 65 33 94  9 70 74] 72\n",
      "[21 39 30 65 33 94  9 70 74 72] 19\n",
      "[39 30 65 33 94  9 70 74 72 19] 38\n",
      "[30 65 33 94  9 70 74 72 19 38] 40\n",
      "[65 33 94  9 70 74 72 19 38 40] 71\n",
      "[33 94  9 70 74 72 19 38 40 71] 27\n",
      "[94  9 70 74 72 19 38 40 71 27] 14\n",
      "[ 9 70 74 72 19 38 40 71 27 14] 0\n",
      "[70 74 72 19 38 40 71 27 14  0] 8\n",
      "[74 72 19 38 40 71 27 14  0  8] 13\n",
      "[72 19 38 40 71 27 14  0  8 13] 27\n",
      "[19 38 40 71 27 14  0  8 13 27] 75\n",
      "[38 40 71 27 14  0  8 13 27 75] 58\n",
      "[40 71 27 14  0  8 13 27 75 58] 5\n",
      "[71 27 14  0  8 13 27 75 58  5] 91\n",
      "[27 14  0  8 13 27 75 58  5 91] 57\n",
      "[14  0  8 13 27 75 58  5 91 57] 5\n",
      "[ 0  8 13 27 75 58  5 91 57  5] 61\n",
      "[ 8 13 27 75 58  5 91 57  5 61] 84\n",
      "[13 27 75 58  5 91 57  5 61 84] 64\n",
      "[27 75 58  5 91 57  5 61 84 64] 83\n",
      "[75 58  5 91 57  5 61 84 64 83] 60\n",
      "[58  5 91 57  5 61 84 64 83 60] 11\n",
      "[ 5 91 57  5 61 84 64 83 60 11] 81\n",
      "[91 57  5 61 84 64 83 60 11 81] 47\n",
      "[57  5 61 84 64 83 60 11 81 47] 74\n",
      "[ 5 61 84 64 83 60 11 81 47 74] 37\n",
      "[61 84 64 83 60 11 81 47 74 37] 76\n",
      "[84 64 83 60 11 81 47 74 37 76] 56\n",
      "[64 83 60 11 81 47 74 37 76 56] 19\n",
      "[83 60 11 81 47 74 37 76 56 19] 56\n",
      "[60 11 81 47 74 37 76 56 19 56] 35\n",
      "[11 81 47 74 37 76 56 19 56 35] 82\n",
      "[81 47 74 37 76 56 19 56 35 82] 35\n",
      "[47 74 37 76 56 19 56 35 82 35] 40\n",
      "[74 37 76 56 19 56 35 82 35 40] 88\n",
      "[37 76 56 19 56 35 82 35 40 88] 77\n",
      "[76 56 19 56 35 82 35 40 88 77] 28\n",
      "[56 19 56 35 82 35 40 88 77 28] 0\n",
      "[19 56 35 82 35 40 88 77 28  0] 14\n",
      "[56 35 82 35 40 88 77 28  0 14] 39\n",
      "[35 82 35 40 88 77 28  0 14 39] 19\n",
      "[82 35 40 88 77 28  0 14 39 19] 2\n",
      "[35 40 88 77 28  0 14 39 19  2] 45\n",
      "[40 88 77 28  0 14 39 19  2 45] 21\n",
      "[88 77 28  0 14 39 19  2 45 21] 86\n",
      "[77 28  0 14 39 19  2 45 21 86] 44\n",
      "[28  0 14 39 19  2 45 21 86 44] 81\n",
      "[ 0 14 39 19  2 45 21 86 44 81] 61\n",
      "[14 39 19  2 45 21 86 44 81 61] 63\n",
      "[39 19  2 45 21 86 44 81 61 63] 44\n",
      "[19  2 45 21 86 44 81 61 63 44] 45\n",
      "[ 2 45 21 86 44 81 61 63 44 45] 18\n",
      "[45 21 86 44 81 61 63 44 45 18] 40\n",
      "[21 86 44 81 61 63 44 45 18 40] 95\n",
      "[86 44 81 61 63 44 45 18 40 95] 44\n",
      "[44 81 61 63 44 45 18 40 95 44] 30\n",
      "[81 61 63 44 45 18 40 95 44 30] 11\n",
      "[61 63 44 45 18 40 95 44 30 11] 60\n",
      "[63 44 45 18 40 95 44 30 11 60] 3\n",
      "[44 45 18 40 95 44 30 11 60  3] 37\n",
      "[45 18 40 95 44 30 11 60  3 37] 91\n",
      "[18 40 95 44 30 11 60  3 37 91] 63\n",
      "[40 95 44 30 11 60  3 37 91 63] 29\n",
      "[95 44 30 11 60  3 37 91 63 29] 84\n",
      "[44 30 11 60  3 37 91 63 29 84] 9\n",
      "[30 11 60  3 37 91 63 29 84  9] 28\n",
      "[11 60  3 37 91 63 29 84  9 28] 63\n",
      "[60  3 37 91 63 29 84  9 28 63] 59\n",
      "[ 3 37 91 63 29 84  9 28 63 59] 0\n",
      "[37 91 63 29 84  9 28 63 59  0] 81\n",
      "[91 63 29 84  9 28 63 59  0 81] 80\n",
      "[63 29 84  9 28 63 59  0 81 80] 60\n",
      "[29 84  9 28 63 59  0 81 80 60] 87\n",
      "[84  9 28 63 59  0 81 80 60 87] 28\n",
      "[ 9 28 63 59  0 81 80 60 87 28] 46\n",
      "[28 63 59  0 81 80 60 87 28 46] 28\n",
      "[63 59  0 81 80 60 87 28 46 28] 60\n",
      "[59  0 81 80 60 87 28 46 28 60] 25\n",
      "[ 0 81 80 60 87 28 46 28 60 25] 98\n",
      "[81 80 60 87 28 46 28 60 25 98] 84\n",
      "[80 60 87 28 46 28 60 25 98 84] 75\n",
      "[60 87 28 46 28 60 25 98 84 75] 45\n",
      "[87 28 46 28 60 25 98 84 75 45] 69\n",
      "[28 46 28 60 25 98 84 75 45 69] 8\n",
      "[46 28 60 25 98 84 75 45 69  8] 43\n",
      "[28 60 25 98 84 75 45 69  8 43] 22\n",
      "[60 25 98 84 75 45 69  8 43 22] 15\n",
      "[25 98 84 75 45 69  8 43 22 15] 70\n",
      "[98 84 75 45 69  8 43 22 15 70] 87\n",
      "[84 75 45 69  8 43 22 15 70 87] 63\n",
      "[75 45 69  8 43 22 15 70 87 63] 1\n",
      "[45 69  8 43 22 15 70 87 63  1] 4\n",
      "[69  8 43 22 15 70 87 63  1  4] 81\n",
      "[ 8 43 22 15 70 87 63  1  4 81] 69\n",
      "[43 22 15 70 87 63  1  4 81 69] 57\n",
      "[22 15 70 87 63  1  4 81 69 57] 67\n",
      "[15 70 87 63  1  4 81 69 57 67] 61\n",
      "[70 87 63  1  4 81 69 57 67 61] 94\n",
      "[87 63  1  4 81 69 57 67 61 94] 0\n",
      "[63  1  4 81 69 57 67 61 94  0] 14\n",
      "[ 1  4 81 69 57 67 61 94  0 14] 41\n",
      "[ 4 81 69 57 67 61 94  0 14 41] 80\n",
      "[81 69 57 67 61 94  0 14 41 80] 21\n",
      "[69 57 67 61 94  0 14 41 80 21] 17\n",
      "[57 67 61 94  0 14 41 80 21 17] 94\n",
      "[67 61 94  0 14 41 80 21 17 94] 98\n",
      "[61 94  0 14 41 80 21 17 94 98] 62\n",
      "[94  0 14 41 80 21 17 94 98 62] 80\n",
      "[ 0 14 41 80 21 17 94 98 62 80] 53\n",
      "[14 41 80 21 17 94 98 62 80 53] 86\n",
      "[41 80 21 17 94 98 62 80 53 86] 50\n",
      "[80 21 17 94 98 62 80 53 86 50] 21\n",
      "[21 17 94 98 62 80 53 86 50 21] 70\n",
      "[17 94 98 62 80 53 86 50 21 70] 94\n",
      "[94 98 62 80 53 86 50 21 70 94] 75\n",
      "[98 62 80 53 86 50 21 70 94 75] 51\n",
      "[62 80 53 86 50 21 70 94 75 51] 35\n",
      "[80 53 86 50 21 70 94 75 51 35] 76\n",
      "[53 86 50 21 70 94 75 51 35 76] 64\n",
      "[86 50 21 70 94 75 51 35 76 64] 46\n",
      "[50 21 70 94 75 51 35 76 64 46] 43\n",
      "[21 70 94 75 51 35 76 64 46 43] 62\n",
      "[70 94 75 51 35 76 64 46 43 62] 46\n",
      "[94 75 51 35 76 64 46 43 62 46] 43\n",
      "[75 51 35 76 64 46 43 62 46 43] 56\n",
      "[51 35 76 64 46 43 62 46 43 56] 79\n",
      "[35 76 64 46 43 62 46 43 56 79] 32\n",
      "[76 64 46 43 62 46 43 56 79 32] 50\n",
      "[64 46 43 62 46 43 56 79 32 50] 2\n",
      "[46 43 62 46 43 56 79 32 50  2] 0\n",
      "[43 62 46 43 56 79 32 50  2  0] 86\n",
      "[62 46 43 56 79 32 50  2  0 86] 34\n",
      "[46 43 56 79 32 50  2  0 86 34] 26\n",
      "[43 56 79 32 50  2  0 86 34 26] 61\n",
      "[56 79 32 50  2  0 86 34 26 61] 79\n",
      "[79 32 50  2  0 86 34 26 61 79] 76\n",
      "[32 50  2  0 86 34 26 61 79 76] 71\n",
      "[50  2  0 86 34 26 61 79 76 71] 65\n",
      "[ 2  0 86 34 26 61 79 76 71 65] 89\n",
      "[ 0 86 34 26 61 79 76 71 65 89] 9\n",
      "[86 34 26 61 79 76 71 65 89  9] 57\n",
      "[34 26 61 79 76 71 65 89  9 57] 74\n",
      "[26 61 79 76 71 65 89  9 57 74] 5\n",
      "[61 79 76 71 65 89  9 57 74  5] 84\n",
      "[79 76 71 65 89  9 57 74  5 84] 3\n",
      "[76 71 65 89  9 57 74  5 84  3] 93\n",
      "[71 65 89  9 57 74  5 84  3 93] 43\n",
      "[65 89  9 57 74  5 84  3 93 43] 69\n",
      "[89  9 57 74  5 84  3 93 43 69] 83\n",
      "[ 9 57 74  5 84  3 93 43 69 83] 69\n",
      "[57 74  5 84  3 93 43 69 83 69] 40\n",
      "[74  5 84  3 93 43 69 83 69 40] 14\n",
      "[ 5 84  3 93 43 69 83 69 40 14] 82\n",
      "[84  3 93 43 69 83 69 40 14 82] 37\n",
      "[ 3 93 43 69 83 69 40 14 82 37] 49\n",
      "[93 43 69 83 69 40 14 82 37 49] 37\n",
      "[43 69 83 69 40 14 82 37 49 37] 31\n",
      "[69 83 69 40 14 82 37 49 37 31] 61\n",
      "[83 69 40 14 82 37 49 37 31 61] 6\n",
      "[69 40 14 82 37 49 37 31 61  6] 0\n",
      "[40 14 82 37 49 37 31 61  6  0] 74\n",
      "[14 82 37 49 37 31 61  6  0 74] 39\n",
      "[82 37 49 37 31 61  6  0 74 39] 69\n",
      "[37 49 37 31 61  6  0 74 39 69] 32\n",
      "[49 37 31 61  6  0 74 39 69 32] 7\n",
      "[37 31 61  6  0 74 39 69 32  7] 26\n",
      "[31 61  6  0 74 39 69 32  7 26] 13\n",
      "[61  6  0 74 39 69 32  7 26 13] 88\n",
      "[ 6  0 74 39 69 32  7 26 13 88] 61\n",
      "[ 0 74 39 69 32  7 26 13 88 61] 65\n",
      "[74 39 69 32  7 26 13 88 61 65] 30\n",
      "[39 69 32  7 26 13 88 61 65 30] 9\n",
      "[69 32  7 26 13 88 61 65 30  9] 62\n",
      "[32  7 26 13 88 61 65 30  9 62] 81\n",
      "[ 7 26 13 88 61 65 30  9 62 81] 12\n",
      "[26 13 88 61 65 30  9 62 81 12] 64\n",
      "[13 88 61 65 30  9 62 81 12 64] 22\n",
      "[88 61 65 30  9 62 81 12 64 22] 73\n",
      "[61 65 30  9 62 81 12 64 22 73] 72\n",
      "[65 30  9 62 81 12 64 22 73 72] 6\n",
      "[30  9 62 81 12 64 22 73 72  6] 15\n",
      "[ 9 62 81 12 64 22 73 72  6 15] 99\n",
      "[62 81 12 64 22 73 72  6 15 99] 34\n",
      "[81 12 64 22 73 72  6 15 99 34] 13\n",
      "[12 64 22 73 72  6 15 99 34 13] 61\n",
      "[64 22 73 72  6 15 99 34 13 61] 77\n",
      "[22 73 72  6 15 99 34 13 61 77] 35\n",
      "[73 72  6 15 99 34 13 61 77 35] 46\n",
      "[72  6 15 99 34 13 61 77 35 46] 4\n",
      "[ 6 15 99 34 13 61 77 35 46  4] 54\n",
      "[15 99 34 13 61 77 35 46  4 54] 0\n",
      "[99 34 13 61 77 35 46  4 54  0] 71\n",
      "[34 13 61 77 35 46  4 54  0 71] 53\n",
      "[13 61 77 35 46  4 54  0 71 53] 11\n",
      "[61 77 35 46  4 54  0 71 53 11] 81\n",
      "[77 35 46  4 54  0 71 53 11 81] 33\n",
      "[35 46  4 54  0 71 53 11 81 33] 77\n",
      "[46  4 54  0 71 53 11 81 33 77] 39\n",
      "[ 4 54  0 71 53 11 81 33 77 39] 47\n",
      "[54  0 71 53 11 81 33 77 39 47] 54\n",
      "[ 0 71 53 11 81 33 77 39 47 54] 77\n",
      "[71 53 11 81 33 77 39 47 54 77] 76\n",
      "[53 11 81 33 77 39 47 54 77 76] 28\n",
      "[11 81 33 77 39 47 54 77 76 28] 38\n",
      "[81 33 77 39 47 54 77 76 28 38] 72\n",
      "[33 77 39 47 54 77 76 28 38 72] 31\n",
      "[77 39 47 54 77 76 28 38 72 31] 54\n",
      "[39 47 54 77 76 28 38 72 31 54] 38\n",
      "[47 54 77 76 28 38 72 31 54 38] 58\n",
      "[54 77 76 28 38 72 31 54 38 58] 46\n",
      "[77 76 28 38 72 31 54 38 58 46] 18\n",
      "[76 28 38 72 31 54 38 58 46 18] 49\n",
      "[28 38 72 31 54 38 58 46 18 49] 41\n",
      "[38 72 31 54 38 58 46 18 49 41] 3\n",
      "[72 31 54 38 58 46 18 49 41  3] 71\n",
      "[31 54 38 58 46 18 49 41  3 71] 41\n",
      "[54 38 58 46 18 49 41  3 71 41] 24\n",
      "[38 58 46 18 49 41  3 71 41 24] 94\n",
      "[58 46 18 49 41  3 71 41 24 94] 38\n",
      "[46 18 49 41  3 71 41 24 94 38] 2\n",
      "[18 49 41  3 71 41 24 94 38  2] 99\n",
      "[49 41  3 71 41 24 94 38  2 99] 0\n",
      "[41  3 71 41 24 94 38  2 99  0] 56\n",
      "[ 3 71 41 24 94 38  2 99  0 56] 17\n",
      "[71 41 24 94 38  2 99  0 56 17] 8\n",
      "[41 24 94 38  2 99  0 56 17  8] 63\n",
      "[24 94 38  2 99  0 56 17  8 63] 86\n",
      "[94 38  2 99  0 56 17  8 63 86] 67\n",
      "[38  2 99  0 56 17  8 63 86 67] 40\n",
      "[ 2 99  0 56 17  8 63 86 67 40] 7\n",
      "[99  0 56 17  8 63 86 67 40  7] 38\n",
      "[ 0 56 17  8 63 86 67 40  7 38] 25\n",
      "[56 17  8 63 86 67 40  7 38 25] 3\n",
      "[17  8 63 86 67 40  7 38 25  3] 58\n",
      "[ 8 63 86 67 40  7 38 25  3 58] 92\n",
      "[63 86 67 40  7 38 25  3 58 92] 26\n",
      "[86 67 40  7 38 25  3 58 92 26] 98\n",
      "[67 40  7 38 25  3 58 92 26 98] 15\n",
      "[40  7 38 25  3 58 92 26 98 15] 44\n",
      "[ 7 38 25  3 58 92 26 98 15 44] 24\n",
      "[38 25  3 58 92 26 98 15 44 24] 77\n",
      "[25  3 58 92 26 98 15 44 24 77] 29\n",
      "[ 3 58 92 26 98 15 44 24 77 29] 42\n",
      "[58 92 26 98 15 44 24 77 29 42] 43\n",
      "[92 26 98 15 44 24 77 29 42 43] 82\n",
      "[26 98 15 44 24 77 29 42 43 82] 44\n",
      "[98 15 44 24 77 29 42 43 82 44] 59\n",
      "[15 44 24 77 29 42 43 82 44 59] 85\n",
      "[44 24 77 29 42 43 82 44 59 85] 86\n",
      "[24 77 29 42 43 82 44 59 85 86] 0\n",
      "[77 29 42 43 82 44 59 85 86  0] 92\n",
      "[29 42 43 82 44 59 85 86  0 92] 66\n",
      "[42 43 82 44 59 85 86  0 92 66] 59\n",
      "[43 82 44 59 85 86  0 92 66 59] 30\n",
      "[82 44 59 85 86  0 92 66 59 30] 69\n",
      "[44 59 85 86  0 92 66 59 30 69] 53\n",
      "[59 85 86  0 92 66 59 30 69 53] 50\n",
      "[85 86  0 92 66 59 30 69 53 50] 64\n",
      "[86  0 92 66 59 30 69 53 50 64] 12\n",
      "[ 0 92 66 59 30 69 53 50 64 12] 95\n",
      "[92 66 59 30 69 53 50 64 12 95] 47\n",
      "[66 59 30 69 53 50 64 12 95 47] 38\n",
      "[59 30 69 53 50 64 12 95 47 38] 94\n",
      "[30 69 53 50 64 12 95 47 38 94] 84\n",
      "[69 53 50 64 12 95 47 38 94 84] 40\n",
      "[53 50 64 12 95 47 38 94 84 40] 10\n",
      "[50 64 12 95 47 38 94 84 40 10] 62\n",
      "[64 12 95 47 38 94 84 40 10 62] 98\n",
      "[12 95 47 38 94 84 40 10 62 98] 89\n",
      "[95 47 38 94 84 40 10 62 98 89] 31\n",
      "[47 38 94 84 40 10 62 98 89 31] 59\n",
      "[38 94 84 40 10 62 98 89 31 59] 68\n",
      "[94 84 40 10 62 98 89 31 59 68] 95\n",
      "[84 40 10 62 98 89 31 59 68 95] 97\n",
      "[40 10 62 98 89 31 59 68 95 97] 91\n",
      "[10 62 98 89 31 59 68 95 97 91] 89\n",
      "[62 98 89 31 59 68 95 97 91 89] 57\n",
      "[98 89 31 59 68 95 97 91 89 57] 87\n",
      "[89 31 59 68 95 97 91 89 57 87] 34\n",
      "[31 59 68 95 97 91 89 57 87 34] 87\n",
      "[59 68 95 97 91 89 57 87 34 87] 0\n",
      "[68 95 97 91 89 57 87 34 87  0] 35\n",
      "[95 97 91 89 57 87 34 87  0 35] 25\n",
      "[97 91 89 57 87 34 87  0 35 25] 66\n",
      "[91 89 57 87 34 87  0 35 25 66] 53\n",
      "[89 57 87 34 87  0 35 25 66 53] 21\n",
      "[57 87 34 87  0 35 25 66 53 21] 12\n",
      "[87 34 87  0 35 25 66 53 21 12] 77\n",
      "[34 87  0 35 25 66 53 21 12 77] 31\n",
      "[87  0 35 25 66 53 21 12 77 31] 71\n",
      "[ 0 35 25 66 53 21 12 77 31 71] 49\n",
      "[35 25 66 53 21 12 77 31 71 49] 99\n",
      "[25 66 53 21 12 77 31 71 49 99] 7\n",
      "[66 53 21 12 77 31 71 49 99  7] 15\n",
      "[53 21 12 77 31 71 49 99  7 15] 99\n",
      "[21 12 77 31 71 49 99  7 15 99] 86\n",
      "[12 77 31 71 49 99  7 15 99 86] 69\n",
      "[77 31 71 49 99  7 15 99 86 69] 92\n",
      "[31 71 49 99  7 15 99 86 69 92] 61\n",
      "[71 49 99  7 15 99 86 69 92 61] 52\n",
      "[49 99  7 15 99 86 69 92 61 52] 68\n",
      "[99  7 15 99 86 69 92 61 52 68] 83\n",
      "[ 7 15 99 86 69 92 61 52 68 83] 67\n",
      "[15 99 86 69 92 61 52 68 83 67] 13\n",
      "[99 86 69 92 61 52 68 83 67 13] 77\n",
      "[86 69 92 61 52 68 83 67 13 77] 15\n",
      "[69 92 61 52 68 83 67 13 77 15] 68\n",
      "[92 61 52 68 83 67 13 77 15 68] 48\n",
      "[61 52 68 83 67 13 77 15 68 48] 80\n",
      "[52 68 83 67 13 77 15 68 48 80] 91\n",
      "[68 83 67 13 77 15 68 48 80 91] 0\n",
      "[83 67 13 77 15 68 48 80 91  0] 35\n",
      "[67 13 77 15 68 48 80 91  0 35] 28\n",
      "[13 77 15 68 48 80 91  0 35 28] 97\n",
      "[77 15 68 48 80 91  0 35 28 97] 25\n",
      "[15 68 48 80 91  0 35 28 97 25] 13\n",
      "[68 48 80 91  0 35 28 97 25 13] 24\n",
      "[48 80 91  0 35 28 97 25 13 24] 22\n",
      "[80 91  0 35 28 97 25 13 24 22] 24\n",
      "[91  0 35 28 97 25 13 24 22 24] 1\n",
      "[ 0 35 28 97 25 13 24 22 24  1] 70\n",
      "[35 28 97 25 13 24 22 24  1 70] 92\n",
      "[28 97 25 13 24 22 24  1 70 92] 84\n",
      "[97 25 13 24 22 24  1 70 92 84] 98\n",
      "[25 13 24 22 24  1 70 92 84 98] 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0]\n",
      "  [88]\n",
      "  [52]\n",
      "  [49]\n",
      "  [82]\n",
      "  [ 0]\n",
      "  [62]\n",
      "  [77]\n",
      "  [60]\n",
      "  [37]]\n",
      "\n",
      " [[88]\n",
      "  [52]\n",
      "  [49]\n",
      "  [82]\n",
      "  [ 0]\n",
      "  [62]\n",
      "  [77]\n",
      "  [60]\n",
      "  [37]\n",
      "  [58]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.LSTM(100, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.rnn.lstm.LSTM at 0x7fb23f346710>,\n",
       " <keras.layers.core.dense.Dense at 0x7fb23f343a50>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 8ms/step - loss: 12275.4619 - accuracy: 0.0082\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1673.3016 - accuracy: 0.0061\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 969.3262 - accuracy: 0.0061\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 892.9152 - accuracy: 0.0061\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 886.8249 - accuracy: 0.0061\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 905.7025 - accuracy: 0.0061\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 894.6605 - accuracy: 0.0061\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 888.5651 - accuracy: 0.0061\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 888.1373 - accuracy: 0.0061\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 885.7380 - accuracy: 0.0061\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 850.8809 - accuracy: 0.0061\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 853.7562 - accuracy: 0.0061\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 897.0736 - accuracy: 0.0061\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 886.4656 - accuracy: 0.0061\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 857.3362 - accuracy: 0.0061\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 843.0759 - accuracy: 0.0061\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 841.4382 - accuracy: 0.0061\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 829.5665 - accuracy: 0.0061\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 830.1890 - accuracy: 0.0061\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 848.5412 - accuracy: 0.0061\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 838.5364 - accuracy: 0.0061\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 828.1846 - accuracy: 0.0061\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 815.0966 - accuracy: 0.0061\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 823.2165 - accuracy: 0.0061\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 831.5470 - accuracy: 0.0061\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 816.7534 - accuracy: 0.0061\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 820.6808 - accuracy: 0.0061\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 813.7762 - accuracy: 0.0061\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 801.0630 - accuracy: 0.0061\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 836.3859 - accuracy: 0.0061\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 800.8361 - accuracy: 0.0061\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 779.6353 - accuracy: 0.0061\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 823.9758 - accuracy: 0.0061\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 797.0327 - accuracy: 0.0061\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 795.7028 - accuracy: 0.0061\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 808.2943 - accuracy: 0.0061\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 794.5710 - accuracy: 0.0061\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 796.7452 - accuracy: 0.0061\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 803.3991 - accuracy: 0.0061\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 800.0875 - accuracy: 0.0061\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 792.2399 - accuracy: 0.0061\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 817.3057 - accuracy: 0.0061\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 837.4556 - accuracy: 0.0061\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 870.1583 - accuracy: 0.0061\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 830.7096 - accuracy: 0.0061\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 807.1764 - accuracy: 0.0061\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 810.3812 - accuracy: 0.0061\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 814.6464 - accuracy: 0.0061\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 801.2645 - accuracy: 0.0061\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 788.8707 - accuracy: 0.0061\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 776.0939 - accuracy: 0.0061\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 796.7547 - accuracy: 0.0061\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 820.0740 - accuracy: 0.0061\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 796.9807 - accuracy: 0.0061\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 792.3322 - accuracy: 0.0061\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 772.2227 - accuracy: 0.0061\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 801.1292 - accuracy: 0.0061\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 797.2488 - accuracy: 0.0061\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 783.0474 - accuracy: 0.0061\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 776.2999 - accuracy: 0.0061\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 771.8948 - accuracy: 0.0061\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 813.9461 - accuracy: 0.0061\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 798.9256 - accuracy: 0.0061\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 765.4688 - accuracy: 0.0061\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 781.5967 - accuracy: 0.0061\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 780.1780 - accuracy: 0.0061\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 780.4745 - accuracy: 0.0061\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 783.3568 - accuracy: 0.0061\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 768.2432 - accuracy: 0.0061\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 766.1359 - accuracy: 0.0061\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 752.0676 - accuracy: 0.0061\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 755.5251 - accuracy: 0.0061\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 762.7097 - accuracy: 0.0061\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 782.4832 - accuracy: 0.0061\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 785.5540 - accuracy: 0.0061\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 769.5575 - accuracy: 0.0061\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 771.9088 - accuracy: 0.0061\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 781.8337 - accuracy: 0.0061\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 789.6746 - accuracy: 0.0061\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 771.0073 - accuracy: 0.0061\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 830.2533 - accuracy: 0.0061\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 804.4962 - accuracy: 0.0061\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 778.1104 - accuracy: 0.0061\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 772.2822 - accuracy: 0.0061\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 755.6705 - accuracy: 0.0061\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 773.6893 - accuracy: 0.0061\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 767.5179 - accuracy: 0.0061\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 742.7992 - accuracy: 0.0061\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 738.1868 - accuracy: 0.0061\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 754.5703 - accuracy: 0.0061\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 718.6869 - accuracy: 0.0061\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 787.9776 - accuracy: 0.0061\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 817.0674 - accuracy: 0.0061\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 845.2880 - accuracy: 0.0061\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 818.5439 - accuracy: 0.0061\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 808.5051 - accuracy: 0.0061\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 788.9910 - accuracy: 0.0061\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 785.1601 - accuracy: 0.0061\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 829.0877 - accuracy: 0.0061\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 798.3421 - accuracy: 0.0061\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 783.8849 - accuracy: 0.0061\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 761.8513 - accuracy: 0.0061\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 784.8688 - accuracy: 0.0061\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 804.8602 - accuracy: 0.0061\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 768.2220 - accuracy: 0.0061\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 753.4199 - accuracy: 0.0061\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 739.5617 - accuracy: 0.0061\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 752.8227 - accuracy: 0.0061\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 780.6951 - accuracy: 0.0061\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 773.9165 - accuracy: 0.0061\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 748.6956 - accuracy: 0.0061\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 747.2463 - accuracy: 0.0061\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 740.7878 - accuracy: 0.0061\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 756.1653 - accuracy: 0.0061\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 737.6638 - accuracy: 0.0061\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 746.6896 - accuracy: 0.0061\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 753.4854 - accuracy: 0.0061\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 726.5414 - accuracy: 0.0061\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 772.1597 - accuracy: 0.0061\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 765.1948 - accuracy: 0.0061\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 750.5565 - accuracy: 0.0061\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 751.6359 - accuracy: 0.0061\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 752.7059 - accuracy: 0.0061\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 762.7460 - accuracy: 0.0061\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 762.5117 - accuracy: 0.0061\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 755.3440 - accuracy: 0.0061\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 749.9236 - accuracy: 0.0061\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 774.7275 - accuracy: 0.0061\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 812.7388 - accuracy: 0.0061\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3766.4399 - accuracy: 0.0061\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 923.4464 - accuracy: 0.0061\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 901.2363 - accuracy: 0.0061\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 869.6841 - accuracy: 0.0061\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 831.9786 - accuracy: 0.0061\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 835.2271 - accuracy: 0.0061\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 821.2856 - accuracy: 0.0061\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 805.4841 - accuracy: 0.0061\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 813.5675 - accuracy: 0.0061\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 833.0597 - accuracy: 0.0061\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 802.7923 - accuracy: 0.0061\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 818.8391 - accuracy: 0.0061\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 788.1018 - accuracy: 0.0061\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 786.7098 - accuracy: 0.0061\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 795.3613 - accuracy: 0.0061\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 803.7908 - accuracy: 0.0061\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 776.9310 - accuracy: 0.0061\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 787.5203 - accuracy: 0.0061\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 808.8636 - accuracy: 0.0061\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 803.1457 - accuracy: 0.0061\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 782.5833 - accuracy: 0.0061\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 801.4579 - accuracy: 0.0061\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 800.3194 - accuracy: 0.0061\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 790.5248 - accuracy: 0.0061\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 836.0154 - accuracy: 0.0061\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 806.6746 - accuracy: 0.0061\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 782.7720 - accuracy: 0.0061\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 794.0649 - accuracy: 0.0061\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 777.3674 - accuracy: 0.0061\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 802.9769 - accuracy: 0.0061\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 800.5683 - accuracy: 0.0061\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 795.3986 - accuracy: 0.0061\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 780.1791 - accuracy: 0.0061\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 814.5562 - accuracy: 0.0061\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 792.5342 - accuracy: 0.0061\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 807.8144 - accuracy: 0.0061\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 799.7814 - accuracy: 0.0061\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 811.6789 - accuracy: 0.0061\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 805.8118 - accuracy: 0.0061\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 796.5148 - accuracy: 0.0061\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 793.8174 - accuracy: 0.0061\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 794.5406 - accuracy: 0.0061\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 773.5758 - accuracy: 0.0061\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 777.1376 - accuracy: 0.0061\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 777.9321 - accuracy: 0.0061\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 779.3712 - accuracy: 0.0061\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 761.9746 - accuracy: 0.0061\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 767.0276 - accuracy: 0.0061\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 798.4323 - accuracy: 0.0061\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 796.4557 - accuracy: 0.0061\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 792.6956 - accuracy: 0.0061\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 825.5486 - accuracy: 0.0061\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 815.2788 - accuracy: 0.0061\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 807.8407 - accuracy: 0.0061\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 784.8650 - accuracy: 0.0061\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 785.3773 - accuracy: 0.0061\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 781.7728 - accuracy: 0.0061\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 755.8123 - accuracy: 0.0061\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 761.1863 - accuracy: 0.0061\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 741.4651 - accuracy: 0.0061\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 742.7462 - accuracy: 0.0061\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 746.3398 - accuracy: 0.0061\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 782.1969 - accuracy: 0.0061\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 778.2396 - accuracy: 0.0061\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 780.8978 - accuracy: 0.0061\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 776.3011 - accuracy: 0.0061\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 738.9474 - accuracy: 0.0061\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 775.1883 - accuracy: 0.0061\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 751.9517 - accuracy: 0.0061\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 769.7034 - accuracy: 0.0061\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 743.2019 - accuracy: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb23f336350>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[13],\n",
       "        [24],\n",
       "        [22],\n",
       "        [24],\n",
       "        [ 1],\n",
       "        [70],\n",
       "        [92],\n",
       "        [84],\n",
       "        [98],\n",
       "        [ 3]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = arr1[-10:]\n",
    "test_data = test_data.reshape((1, n_steps, n_features))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 277ms/step\n",
      "[[64.90368]]\n"
     ]
    }
   ],
   "source": [
    "predictNextNumber = model.predict(test_data, verbose=1)\n",
    "print(predictNextNumber)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f293f16398db128e85df277de8eb5f9ab0a1b28857fa0f1c8543245825f1b931"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
