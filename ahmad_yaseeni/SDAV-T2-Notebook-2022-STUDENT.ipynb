{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cems.uwe.ac.uk/~pa-legg/images/uwe_banner.png\">\n",
    "\n",
    "# UFCFEL-15-3 Security Data Analytics and Visualisation\n",
    "# Portfolio Assignment 2: Machine Learning for Malware Analysis (2022)\n",
    "---\n",
    "\n",
    "The completion of this worksheet is worth a **maximum of 35 marks** towards your portfolio assignment for the UFCFEL-15-3 Security Data Analytics and Visualisation (SDAV) module.\n",
    "\n",
    "### Brief\n",
    "---\n",
    "\n",
    "In this task, you have been given a large sample of derived malware features that describe 14 different malware variants (2000 samples of each). The purpose of this task is to understand the underlying concepts of classification, and **your task will be to develop two classifiers that can classify malware varients**. The first part will focus on a small hand-made classifier using only 3 malware classes, to understand the principles of search space and minimisation of a function. The second part will focus on using off-the-shelf libraries to scale up the classification to all 14 classes of malware present in the dataset.\n",
    "\n",
    "### Assessment and Marking\n",
    "---\n",
    "\n",
    "For each question you will see the maximum number of marks you may be awarded for a complete answer in brackets.\n",
    "\n",
    "**Part 1: Developing a Classifier \"by hand\" - (Total Marks: 20)**\n",
    "\n",
    "* **Task 1:** Find the Centroid point of each of the three groups (3)\n",
    "* **Task 2:** Plot the centroids on a Scatter Plot against the train data colour-coded by group (3)\n",
    "* **Task 3:** For each item in test_data, measure the distance to each centroid point, assign membership to the group of minimum distance, and compare with the expected test data label to obtain a score of successful classifications (12)\n",
    "* **Task 4:** Provide a final accuracy score for the performance of your \"by hand\" classifier (2)\n",
    "\n",
    "**Part 2: Developing a large-scale ML classifier - (Total Marks: 15)**\n",
    "\n",
    "* **Task 5:** Scale the Input Features for further processing using the StandardScaler function (1)\n",
    "* **Task 6:** Obtain numerical labels for each class using the LabelEncoder function (1)\n",
    "* **(Advanced) Task 7:** Prepare the dataset for ML testing, using the Train-Test-Split function of sklearn (2)\n",
    "* **(Advanced) Task 8:** Use a Multi-Layer Perceptron (MLP) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)\n",
    "* **(Advanced) Task 9:** Use a Random Forest (RF) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)\n",
    "* **(Advanced) Task 10:** Show how ML parameters can improve the models to achieve a high accuracy score of over 80% (3)\n",
    "\n",
    "This assignment should be submitted as as PDF to your Blackboard portfolio submission as per the instructions in the assignment specification available on Blackboard. A copy of your work should also be provided via a UWE Gitlab repository, with an accessible link provided with your portfolio.\n",
    " \n",
    "### Contact\n",
    "---\n",
    "\n",
    "Questions about this assignment should be directed to your module leader (Phil.Legg@uwe.ac.uk). You can use the Blackboard Q&A feature to ask questions related to this module and this assignment, as well as the on-site teaching sessions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224862.0</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>12985.0</td>\n",
       "      <td>7387.0</td>\n",
       "      <td>13132.0</td>\n",
       "      <td>5112.0</td>\n",
       "      <td>8661.0</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>14978.0</td>\n",
       "      <td>5656.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>9344.0</td>\n",
       "      <td>2415.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>3023.0</td>\n",
       "      <td>11949.0</td>\n",
       "      <td>3662.0</td>\n",
       "      <td>5552.0</td>\n",
       "      <td>77433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21802.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>2133.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1453.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>4882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24407.0</td>\n",
       "      <td>11682.0</td>\n",
       "      <td>7189.0</td>\n",
       "      <td>6538.0</td>\n",
       "      <td>7687.0</td>\n",
       "      <td>6848.0</td>\n",
       "      <td>4974.0</td>\n",
       "      <td>5377.0</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>11642.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5795.0</td>\n",
       "      <td>6053.0</td>\n",
       "      <td>6426.0</td>\n",
       "      <td>5435.0</td>\n",
       "      <td>4961.0</td>\n",
       "      <td>5026.0</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>5685.0</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7132.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>1516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5321.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>...</td>\n",
       "      <td>933.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>1559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>23849.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>...</td>\n",
       "      <td>993.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>4342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>9267.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>...</td>\n",
       "      <td>998.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>2683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>25357.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2781.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>4267.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>...</td>\n",
       "      <td>563.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>29010.0</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>2969.0</td>\n",
       "      <td>5358.0</td>\n",
       "      <td>2827.0</td>\n",
       "      <td>4598.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>4045.0</td>\n",
       "      <td>2496.0</td>\n",
       "      <td>3718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>217.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>4005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>4956.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>992.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2       3        4       5       6       7    \\\n",
       "0      224862.0  15842.0  12985.0  7387.0  13132.0  5112.0  8661.0  7990.0   \n",
       "1       21802.0   2127.0   2076.0  2028.0   1871.0  1622.0  1939.0  1502.0   \n",
       "2       24407.0  11682.0   7189.0  6538.0   7687.0  6848.0  4974.0  5377.0   \n",
       "3        7132.0    461.0    647.0   371.0    581.0   269.0   646.0   262.0   \n",
       "4        5321.0   1108.0    985.0   955.0    958.0   890.0   971.0   919.0   \n",
       "...         ...      ...      ...     ...      ...     ...     ...     ...   \n",
       "27995   23849.0   1489.0   1573.0  2649.0   1560.0  1025.0   922.0  1020.0   \n",
       "27996    9267.0   1056.0    981.0   930.0   1573.0   819.0   879.0  1064.0   \n",
       "27997   25357.0    874.0   1008.0  2781.0   1518.0   939.0  4267.0   968.0   \n",
       "27998   29010.0   6476.0   2969.0  5358.0   2827.0  4598.0  2172.0  4045.0   \n",
       "27999    4956.0    185.0     74.0    92.0    133.0    94.0    56.0    46.0   \n",
       "\n",
       "           8        9    ...     246     247     248     249     250     251  \\\n",
       "0      14978.0   5656.0  ...  3714.0  2892.0  9344.0  2415.0  2742.0  3023.0   \n",
       "1       2133.0   1689.0  ...  1664.0  1607.0  1788.0  1394.0  1327.0  1453.0   \n",
       "2       7049.0  11642.0  ...  5795.0  6053.0  6426.0  5435.0  4961.0  5026.0   \n",
       "3        243.0    165.0  ...   151.0   276.0   299.0   294.0   294.0   354.0   \n",
       "4        945.0    963.0  ...   933.0   975.0   945.0   924.0   879.0   952.0   \n",
       "...        ...      ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "27995   1042.0    938.0  ...   993.0   968.0  1165.0  1041.0  1258.0  1753.0   \n",
       "27996   1029.0    893.0  ...   998.0   911.0   990.0  1039.0   930.0   833.0   \n",
       "27997   1103.0   1032.0  ...   563.0   557.0   974.0   706.0   514.0   632.0   \n",
       "27998   2496.0   3718.0  ...   217.0   146.0   544.0   232.0    95.0   140.0   \n",
       "27999    145.0     93.0  ...    50.0    61.0   810.0  1109.0   109.0    62.0   \n",
       "\n",
       "           252     253     254      255  \n",
       "0      11949.0  3662.0  5552.0  77433.0  \n",
       "1       1785.0  1559.0  1755.0   4882.0  \n",
       "2       5376.0  4180.0  5685.0   5775.0  \n",
       "3        506.0   569.0   940.0   1516.0  \n",
       "4        956.0   900.0   942.0   1559.0  \n",
       "...        ...     ...     ...      ...  \n",
       "27995   1203.0   958.0  1315.0   4342.0  \n",
       "27996    904.0   891.0   976.0   2683.0  \n",
       "27997    657.0   584.0   535.0   2431.0  \n",
       "27998    294.0   163.0   182.0   4005.0  \n",
       "27999    209.0   112.0    84.0    992.0  \n",
       "\n",
       "[28000 rows x 256 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('./T2_data/malware_data.csv', header=None)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0      high\n",
       "1      high\n",
       "2      high\n",
       "3      high\n",
       "4      high\n",
       "...     ...\n",
       "27995  zbot\n",
       "27996  zbot\n",
       "27997  zbot\n",
       "27998  zbot\n",
       "27999  zbot\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('./T2_data/malware_label.csv', header=None)\n",
    "labels = labels.drop(0, axis=1)\n",
    "labels = labels.rename(columns = {1:'label'})\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells above, we have created two DataFrames: ***features*** and ***labels***.\n",
    "\n",
    "***Features***: This table contains 28000 instances of malware, where each instance of malware is characterised by 256 distinct features relating to how it performs and its impact on the associated systems.\n",
    "\n",
    "***Labels***: This table contains 28000 rows, where each row is the label of the malware class, related to the features table. There are 2000 samples of each malware varient, and 14 varients in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Developing a Classifier \"by hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3114896.0</td>\n",
       "      <td>10815.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3436940.0</td>\n",
       "      <td>9551.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812649.0</td>\n",
       "      <td>15343.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3067845.0</td>\n",
       "      <td>10541.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51591.0</td>\n",
       "      <td>21367.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>78591.0</td>\n",
       "      <td>7734.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>80429.0</td>\n",
       "      <td>5114.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2898.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>183376.0</td>\n",
       "      <td>8477.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>11580.0</td>\n",
       "      <td>5921.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x        y    labels\n",
       "0    3114896.0  10815.0  wannacry\n",
       "1    3436940.0   9551.0  wannacry\n",
       "2    1812649.0  15343.0  wannacry\n",
       "3    3067845.0  10541.0  wannacry\n",
       "4      51591.0  21367.0  wannacry\n",
       "..         ...      ...       ...\n",
       "145    78591.0   7734.0      razy\n",
       "146    80429.0   5114.0      razy\n",
       "147     2898.0     98.0      razy\n",
       "148   183376.0   8477.0      razy\n",
       "149    11580.0   5921.0      razy\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# DO NOT MODIFY THIS CELL - this cell is splitting the data to provide a suitable subset of data to work with for this task.\n",
    "# If you change this cell your output will differ from that expected and could impact your mark.\n",
    "\n",
    "\n",
    "mal1_index = 17000\n",
    "mal2_index = 21000\n",
    "mal3_index = 12000\n",
    "mal_range = 50\n",
    "mal_test_range = 30\n",
    "\n",
    "train_data = np.vstack([ features[mal1_index:mal1_index+mal_range][[0,1]].values, features[mal2_index:mal2_index+mal_range][[0,1]].values, features[mal3_index:mal3_index+mal_range][[0,1]].values ])\n",
    "train_data = pd.DataFrame(train_data)\n",
    "train_labels = np.vstack([ labels[mal1_index:mal1_index+mal_range].values, labels[mal2_index:mal2_index+mal_range].values, labels[mal3_index:mal3_index+mal_range].values ])\n",
    "train_labels = pd.DataFrame(train_labels)\n",
    "train_data['labels'] = train_labels\n",
    "train_data = train_data.rename(columns={0:'x', 1:'y'})\n",
    "\n",
    "test_data = np.vstack([ features[mal1_index+mal_range:mal1_index+mal_range+mal_test_range][[0,1]].values, features[mal2_index+mal_range:mal2_index+mal_range+mal_test_range][[0,1]].values, features[mal3_index+mal_range:mal3_index+mal_range+mal_test_range][[0,1]].values ])\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_labels = np.vstack([ labels[mal1_index+mal_range:mal1_index+mal_range+mal_test_range].values, labels[mal2_index+mal_range:mal2_index+mal_range+mal_test_range].values, labels[mal3_index+mal_range:mal3_index+mal_range+mal_test_range].values ])\n",
    "test_labels = pd.DataFrame(test_labels)\n",
    "test_data['labels'] = test_labels\n",
    "test_data = test_data.rename(columns={0:'x', 1:'y'})\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Find the Centroid point of each of the three groups (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids of Wannacry Label:  2181660.66 , 11087.1\n",
      "Centroids of startsurf Label:  478778.12 , 3754.04\n",
      "Centroids of razy Label:  100505.22 , 6158.28\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "wannacry_centroid_x = train_data.loc[train_data['labels'] == 'wannacry'].x.sum()/50\n",
    "wannacry_centroid_y = train_data.loc[train_data['labels'] == 'wannacry'].y.sum()/50\n",
    "\n",
    "startsurf_centroid_x = train_data.loc[train_data['labels'] == 'startsurf'].x.sum()/50\n",
    "startsurf_centroid_y = train_data.loc[train_data['labels'] == 'startsurf'].y.sum()/50\n",
    "\n",
    "razy_centroid_x = train_data.loc[train_data['labels'] == 'razy'].x.sum()/50\n",
    "razy_centroid_y = train_data.loc[train_data['labels'] == 'razy'].y.sum()/50\n",
    "\n",
    "print('Centroids of Wannacry Label: ', wannacry_centroid_x,',',wannacry_centroid_y)\n",
    "\n",
    "print('Centroids of startsurf Label: ', startsurf_centroid_x,',',startsurf_centroid_y)\n",
    "\n",
    "print('Centroids of razy Label: ', razy_centroid_x,',',razy_centroid_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Plot the centroids on a Scatter Plot against the train data colour-coded by group (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "scatter_x = np.array(train_data['x'])\n",
    "scatter_y = np.array(train_data['y'])\n",
    "group = np.array(train_data.labels)\n",
    "for g in np.unique(group):\n",
    "    i = np.where(group == g)\n",
    "    ax.scatter(scatter_x[i], scatter_y[i], label=g)\n",
    "\n",
    "plt.scatter(wannacry_centroid_x, wannacry_centroid_y,  marker = \"x\", s=300, \n",
    "    linewidths = 5, zorder = 10, c='green')\n",
    "plt.scatter(startsurf_centroid_x, startsurf_centroid_y,  marker = \"x\", s=300, \n",
    "    linewidths = 5, zorder = 10, c='orange')\n",
    "plt.scatter(razy_centroid_x, razy_centroid_y,  marker = \"x\", s=300, \n",
    "    linewidths = 5, zorder = 10, c='blue')\n",
    "ax.legend()\n",
    "plt.xlabel(' X')\n",
    "plt.ylabel(' Y')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: For each item in test_data, measure the distance to each centroid point, assign membership to the group of minimum distance, and compare with the expected test data label to obtain a score of successful classifications (12)\n",
    "\n",
    "*Hint: You may find the clustering activity worksheet helpful for how to approach this task*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_c1 = []\n",
    "distances_c2 = []\n",
    "distances_c3 = []\n",
    "predicted_label=[]\n",
    "for i in range(len(test_data)):\n",
    "    distances_c1.append((test_data.x[i] - wannacry_centroid_x)**2 +(test_data.y[i]- wannacry_centroid_y)**2)\n",
    "    distances_c2.append((test_data.x[i] - startsurf_centroid_x)**2 +(test_data.y[i]- startsurf_centroid_y)**2)\n",
    "    distances_c3.append((test_data.x[i] - razy_centroid_x)**2 +(test_data.y[i]- razy_centroid_y)**2)\n",
    "    if(distances_c1[i]<=distances_c2[i] and distances_c1[i]<=distances_c3[i]):\n",
    "        predicted_label.append('wannacry')\n",
    "    elif(distances_c2[i]<=distances_c1[i] and distances_c2[i]<=distances_c3[i]):\n",
    "        predicted_label.append('startsurf')\n",
    "    elif(distances_c3[i]<=distances_c1[i] and distances_c3[i]<=distances_c2[i]):\n",
    "        predicted_label.append('razy')\n",
    "        \n",
    "se = pd.Series(predicted_label)\n",
    "test_data['predicted_label'] = se.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Provide a final accuracy score for the performance of your \"by hand\" classifier (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of hand made classifier is:  70.0 %\n"
     ]
    }
   ],
   "source": [
    "count_of_correct_classification = len(test_data.loc[test_data['predicted_label'] == test_data['labels']])\n",
    "count_of_test_data = len(test_data)\n",
    "\n",
    "print('Accuracy score of hand made classifier is: ',count_of_correct_classification/count_of_test_data*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of hand made classification is:  70.0 %\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "print('Accuracy score of hand made classification is: ',accuracy_score(test_data['predicted_label'] ,test_data['labels'])*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Developing a large-scale ML classifier\n",
    "\n",
    "We will now extend the earlier principles for the full dataset. Essentially the task is the same, we want to find the parameters that allow us to clearly separate groups for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 5: Scale the Input Features for further processing using the StandardScaler function (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.097820</td>\n",
       "      <td>0.672159</td>\n",
       "      <td>0.826630</td>\n",
       "      <td>0.380661</td>\n",
       "      <td>0.647650</td>\n",
       "      <td>0.204495</td>\n",
       "      <td>0.792002</td>\n",
       "      <td>0.691117</td>\n",
       "      <td>1.028243</td>\n",
       "      <td>0.432558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191715</td>\n",
       "      <td>0.044177</td>\n",
       "      <td>0.845365</td>\n",
       "      <td>-0.010620</td>\n",
       "      <td>0.038420</td>\n",
       "      <td>0.068183</td>\n",
       "      <td>1.190714</td>\n",
       "      <td>0.135741</td>\n",
       "      <td>0.178144</td>\n",
       "      <td>0.406173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.355085</td>\n",
       "      <td>-0.291567</td>\n",
       "      <td>-0.274569</td>\n",
       "      <td>-0.254820</td>\n",
       "      <td>-0.323318</td>\n",
       "      <td>-0.234858</td>\n",
       "      <td>-0.178266</td>\n",
       "      <td>-0.244002</td>\n",
       "      <td>-0.310024</td>\n",
       "      <td>-0.182924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155188</td>\n",
       "      <td>-0.155994</td>\n",
       "      <td>-0.248598</td>\n",
       "      <td>-0.175093</td>\n",
       "      <td>-0.166129</td>\n",
       "      <td>-0.179846</td>\n",
       "      <td>-0.248456</td>\n",
       "      <td>-0.168900</td>\n",
       "      <td>-0.218099</td>\n",
       "      <td>-0.238666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.351784</td>\n",
       "      <td>0.379844</td>\n",
       "      <td>0.241558</td>\n",
       "      <td>0.279985</td>\n",
       "      <td>0.178160</td>\n",
       "      <td>0.423038</td>\n",
       "      <td>0.259812</td>\n",
       "      <td>0.314504</td>\n",
       "      <td>0.202153</td>\n",
       "      <td>1.361289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543863</td>\n",
       "      <td>0.536584</td>\n",
       "      <td>0.422895</td>\n",
       "      <td>0.475873</td>\n",
       "      <td>0.359192</td>\n",
       "      <td>0.384618</td>\n",
       "      <td>0.260011</td>\n",
       "      <td>0.210779</td>\n",
       "      <td>0.192024</td>\n",
       "      <td>-0.230729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.373671</td>\n",
       "      <td>-0.408634</td>\n",
       "      <td>-0.418818</td>\n",
       "      <td>-0.451310</td>\n",
       "      <td>-0.434547</td>\n",
       "      <td>-0.405185</td>\n",
       "      <td>-0.364900</td>\n",
       "      <td>-0.422724</td>\n",
       "      <td>-0.506936</td>\n",
       "      <td>-0.419373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411219</td>\n",
       "      <td>-0.363332</td>\n",
       "      <td>-0.464176</td>\n",
       "      <td>-0.352293</td>\n",
       "      <td>-0.315456</td>\n",
       "      <td>-0.353466</td>\n",
       "      <td>-0.429556</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.303149</td>\n",
       "      <td>-0.268583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.375965</td>\n",
       "      <td>-0.363170</td>\n",
       "      <td>-0.384699</td>\n",
       "      <td>-0.382059</td>\n",
       "      <td>-0.402040</td>\n",
       "      <td>-0.327008</td>\n",
       "      <td>-0.317989</td>\n",
       "      <td>-0.328030</td>\n",
       "      <td>-0.433797</td>\n",
       "      <td>-0.295563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278888</td>\n",
       "      <td>-0.254445</td>\n",
       "      <td>-0.370648</td>\n",
       "      <td>-0.250806</td>\n",
       "      <td>-0.230890</td>\n",
       "      <td>-0.258994</td>\n",
       "      <td>-0.365838</td>\n",
       "      <td>-0.264363</td>\n",
       "      <td>-0.302941</td>\n",
       "      <td>-0.268201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.097820  0.672159  0.826630  0.380661  0.647650  0.204495  0.792002   \n",
       "1 -0.355085 -0.291567 -0.274569 -0.254820 -0.323318 -0.234858 -0.178266   \n",
       "2 -0.351784  0.379844  0.241558  0.279985  0.178160  0.423038  0.259812   \n",
       "3 -0.373671 -0.408634 -0.418818 -0.451310 -0.434547 -0.405185 -0.364900   \n",
       "4 -0.375965 -0.363170 -0.384699 -0.382059 -0.402040 -0.327008 -0.317989   \n",
       "\n",
       "        7         8         9    ...       246       247       248       249  \\\n",
       "0  0.691117  1.028243  0.432558  ...  0.191715  0.044177  0.845365 -0.010620   \n",
       "1 -0.244002 -0.310024 -0.182924  ... -0.155188 -0.155994 -0.248598 -0.175093   \n",
       "2  0.314504  0.202153  1.361289  ...  0.543863  0.536584  0.422895  0.475873   \n",
       "3 -0.422724 -0.506936 -0.419373  ... -0.411219 -0.363332 -0.464176 -0.352293   \n",
       "4 -0.328030 -0.433797 -0.295563  ... -0.278888 -0.254445 -0.370648 -0.250806   \n",
       "\n",
       "        250       251       252       253       254       255  \n",
       "0  0.038420  0.068183  1.190714  0.135741  0.178144  0.406173  \n",
       "1 -0.166129 -0.179846 -0.248456 -0.168900 -0.218099 -0.238666  \n",
       "2  0.359192  0.384618  0.260011  0.210779  0.192024 -0.230729  \n",
       "3 -0.315456 -0.353466 -0.429556 -0.312311 -0.303149 -0.268583  \n",
       "4 -0.230890 -0.258994 -0.365838 -0.264363 -0.302941 -0.268201  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_features = StandardScaler().fit_transform(features.values)\n",
    "scaled_features_df = pd.DataFrame(scaled_features, index=features.index, columns=features.columns)\n",
    "scaled_features_df.head()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Obtain numerical labels for each class using the LabelEncoder function (1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         7\n",
       "1         7\n",
       "2         7\n",
       "3         7\n",
       "4         7\n",
       "         ..\n",
       "27995    13\n",
       "27996    13\n",
       "27997    13\n",
       "27998    13\n",
       "27999    13\n",
       "Length: 28000, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_encoded=  pd.Series(le.fit_transform(labels))\n",
    "label_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 7: Prepare the dataset for ML testing, using the Train-Test-Split function of sklearn (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21000, 256), (7000, 256), (21000,), (7000,))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "  \n",
    "# using the train test split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_df,label_encoded ,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 8: Use a Multi-Layer Perceptron (MLP) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8254285714285714"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of MLP Classifier is:  82.54285714285714 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score of MLP Classifier is: ',accuracy_score(y_test, y_pred)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 9: Use a Random Forest (RF) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "# Predicting \n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default decision-trees : 87.9286 %\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy score with default decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 10: Show how ML parameters can improve the models to achieve a high accuracy score of over 80% (3)\n",
    "\n",
    "*Marks wil be awarded for how your tuning improves accuracy beyond 80%.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score is already above 80% for both classifiers. Good classification depends on following factors\n",
    "\n",
    "- **Data Normalization**\n",
    "  \n",
    "  We stadandardize our data for normalization and avoided feature dominance by any of the feature.\n",
    "\n",
    "- **Good split bwtween training and test data to avoid over and underfitting**\n",
    "\n",
    "\n",
    "  We divided the dataset in to 75/25% training and test dataset. It is a good split and minimizes overfitting and underfitting in the classification.\n",
    "\n",
    "- If our accuracy was below 80% in the MLP classifier, we could have added hidden layers to improve accuracy. \n",
    "\n",
    "- If our accuracy was below 80% in the Random Forest classifier, we could have increased n_estimators to improve accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(90,90,90))\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred = mlp.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of MLP Classifier with hidden layers is:  83.6 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score of MLP Classifier with hidden layers is: ',accuracy_score(y_test, y_pred)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=42,criterion='entropy')\n",
    "rfc.fit(X_train, y_train)\n",
    "# Predicting \n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with 100 decision-trees : 87.7143 %\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)*100),'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
