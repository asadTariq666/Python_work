{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Existing model found at flowers. hd5. Loading.***\n",
      "\n",
      "\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "115/120 [===========================>..] - ETA: 16s - loss: 0.4316WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1200 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1200 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: flowers. hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: flowers. hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 555s 5s/step - loss: 0.4316 - val_loss: 0.3926\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model \n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.layers import Dense, GlobalAveragePooling2D \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.optimizers import SGD \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os. path\n",
    "\n",
    "MODEL_FILE = \"flowers. hd5\"\n",
    "\n",
    "# Create a model if none exists. Freezes all training except in\n",
    "# newly attached output layers. We can specify the number of nodes\n",
    "# in the hidden penultimate layer, and the number of output\n",
    "# categories.\n",
    "def create_model(num_hidden, num_classes):\n",
    "    base_model = InceptionV3 (include_top= False, weights ='imagenet')\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D() (x)\n",
    "    X = Dense(num_hidden, activation='relu') (x)\n",
    "    predictions = Dense(num_classes, activation='softmax') (x)\n",
    "    \n",
    "\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs = predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Loads an existing model file, then sets only the last \n",
    "# # 3 layers (which we added) to trainable.\n",
    "def load_existing (model_file):\n",
    "    # Load the model \n",
    "    model = load_model(model_file)\n",
    "    # Set only last 3 layers as trainable \n",
    "    numlayers = len(model.layers)\n",
    "    for layer in model.layers[:numlayers-3]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[numlayers-3:]:\n",
    "        layer.trainable = True\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model_file, train_path, validation_path, num_hidden=200, num_classes=5,steps=32, num_epochs=20):\n",
    "    if os.path.exists(model_file):\n",
    "        print(\"\\n*** Existing model found at %s. Loading.***\\n\\n\" % model_file)\n",
    "        model = load_existing (model_file) \n",
    "    else:\n",
    "        print(\"\\n*** Creating new model ***\\n\\n\")\n",
    "        model = create_model(num_hidden, num_classes)\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy'),\n",
    "    # Create a checkpoint \n",
    "    checkpoint = ModelCheckpoint(model_file)\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator (rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_path, target_size=(249, 249), batch_size=32, class_mode = \"categorical\")\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(validation_path, target_size=(249,249), batch_size=32, class_mode='categorical')\n",
    "\n",
    "    model.fit( train_generator, steps_per_epoch = steps, epochs = num_epochs, callbacks = [checkpoint], validation_data = validation_generator, validation_steps = 50)\n",
    "    # Train last two layers \n",
    "    for layer in model.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers [249:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer = SGD(lr=0.00001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "def main():\n",
    "    train(MODEL_FILE, train_path=\"flower_photos\", validation_path=\"flower_photos\", steps=120, num_epochs=10) \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/asadtariq/opt/anaconda3/envs/pythonProject/lib/python3.7/site-packages (8.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'samples/daisy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dk/9q84mn0j1nzfg85t9zx5d1480000gn/T/ipykernel_98558/2703900163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"We think with certainty %3.2f that image %s is %s.\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/dk/9q84mn0j1nzfg85t9zx5d1480000gn/T/ipykernel_98558/2703900163.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"We think with certainty %3.2f that image %s is %s.\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dk/9q84mn0j1nzfg85t9zx5d1480000gn/T/ipykernel_98558/2703900163.py\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(image_fname)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m249\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m249\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mimgarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pythonProject/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'samples/daisy'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model \n",
    "import tensorflow as tf \n",
    "from tensorflow.python.keras.backend import set_session \n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "from os import listdir \n",
    "from os. path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "MODEL_NAME='flowers. hd5'\n",
    "# Our samples directory \n",
    "SAMPLE_PATH = 'samples'\n",
    "dict={0:'daisy', 1:'dandelion'}\n",
    "# Takes in a loaded model, an image in numpy matrix format, \n",
    "# And a label dictionary\n",
    "session = tf.compat.v1.Session(graph = tf.compat.v1.Graph())\n",
    "def classify(model, image):\n",
    "    with session.graph.as_default():\n",
    "        set_session(session) \n",
    "        result = model.predict(image) \n",
    "        themax = np.argmax(result)\n",
    "\n",
    "    return (dict[themax], result[0][themax], themax)\n",
    "\n",
    "# Load image \n",
    "def load_image(image_fname):\n",
    "    img = Image.open(image_fname) \n",
    "    img = img.resize((249, 249)) \n",
    "    imgarray = np.array(img)/255.0 \n",
    "    final = np.expand_dims(imgarray, axis=0) \n",
    "    return final\n",
    "\n",
    "\n",
    "#Test main \n",
    "def main(): \n",
    "    with session.graph.as_default():\n",
    "        set_session(session) \n",
    "        model = load_model(MODEL_NAME)\n",
    "        sample_files = listdir(SAMPLE_PATH)\n",
    "    for filename in sample_files:\n",
    "        filename = join(SAMPLE_PATH, filename) \n",
    "        img = load_image(filename) \n",
    "        label, prob,_ = classify(model, img)\n",
    "        print(\"We think with certainty %3.2f that image %s is %s.\"%(prob, filename, label))\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f293f16398db128e85df277de8eb5f9ab0a1b28857fa0f1c8543245825f1b931"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
