{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CS312 S22\n",
    "\n",
    "\n",
    "# Assignment 2 Coding\n",
    "\n",
    "***\n",
    "\n",
    "**Name**: \n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- You may not use late days on the exam coding nor can you drop your exam coding grades. \n",
    "- If you have a question for us, post it as a **PRIVATE** message on Piazza.  If we decide that the question is appropriate for the entire class, then we will add it to a exam coding clarifications thread. (NB: you should use public posts for the epidemiology \"warmup\" prompts).\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. The exam coding assignmnet is designed to be completed using only the packages in the first given code cell.\n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "- There is *not a prescribed API* for these problems.  You may answer coding questions with whatever syntax or object typing you deem fit.  Your evaluation will primarily live in the clarity of how well you present your final results, so don't skip over any interpretations!  Your code should still be commented and readable to ensure you followed the given course algorithm.\n",
    "- There are two ways to quickly make a .pdf out of this notebook for Gradescope submission.  Either:\n",
    " - Use File -> Download as PDF via LaTeX.  This will require your system path find a working install of a TeX compiler\n",
    " - Easier: Use File ->  Print Preview, and then Right-Click -> Print using your default browser and \"Print to PDF\"\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) | [Bottom](#bot)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old stalwarts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n",
    "#new friends\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm #this line is now always in our opener\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "from patsy import dmatrices # for making design matrices out of categorical features #instead of sm.add_constant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<a id='p1'></a>\n",
    "## (40 pts) Problem 1: Simulation and Hypothesis Testing\n",
    "***\n",
    "\n",
    "One measure we're often interested in for modeling is whether or not our data \"looks\" normally distributed. We have explored two diagnoses for this briefly whereby we compare histograms of residuals or \"QQ\" plots of residuals to the corresponding results of the normal. \n",
    "\n",
    "In tihs problem we'll explore a simplified variant of another common diagnostic that's **more general** for whether or a not a list of numbers comes from a specified distribution.  I recommend skimming [this link](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) about the Kolmogorov-Smirnov test.  Before we begin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) How Similar are two distributions?\n",
    "\n",
    "Consider trying to tell somebody that the uniform random variable $X \\sim U[-2,2]$ is \"very different\" from the Normal $Z \\sim N(0,1)$.  How would you do so?  We could plot their *pdf*s, but the **height** of a pdf is pretty meaningless, since probability lives in **area**.  Instead, we could maybe compare their **cdfs**.\n",
    "\n",
    "Your task:\n",
    "\n",
    "- Create a `linspace` of 1,000 values from -4 to 4.\n",
    "- At those values as the $x$-axis, make a plot with two lines: the cdf of $Z$ and the cdf of $X$ as given above\n",
    "- Print $\\arg \\max_y |F_Z(y)-F_X(y)|$, the **maximum** value of the absolute *difference* between the cdfs $F_Z$ and $F_X$ at your linspace locations.  In other words: how far vertically apart were the two cdfs at their *most* far apart location?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = np.linspace(-4, 4, num=1000)\n",
    "y = stats.norm.cdf(space)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) How about *data* versus a distribution?\n",
    "\n",
    "You should agree that it should maybe be possible to tell two random variables apart from their cdfs.  But what about data **from** a distribution?  This means we have noise or randomness, and it's harder to tell the difference between similar distributions!\n",
    "\n",
    "Our tool for this is called the **empirical** cumulative density function ([ecdf]([https://en.wikipedia.org/wiki/Empirical_distribution_function])), which is roughly equivalent to the cdf version of a histogram: draw a picture of the *observed* cdf, which naturally will be a little \"blocky\" like a histogram.\n",
    "\n",
    "Formally, the ecdf of a data set $X$ with $n$ observations is given by:\n",
    "\n",
    "$$ecdf_X(x)=\\frac{\\text{# of elements of X that are less than or equal to x}}{n}$$\n",
    "\n",
    "You can implement this function by hand, but you may also use `statsmodels.distributions.empirical_distribution.ECDF`.\n",
    "\n",
    "\n",
    "Your task:\n",
    "\n",
    "- **Simulate** 100 numbers from $X \\sim U[-2,2]$ (see `stats.uniform.rvs` for syntax)\n",
    "- Create a `linspace` of 1,000 values from -4 to 4.\n",
    "- Using the `linspace` values as the $x$-axis, again make a plot with two lines: the cdf of the normal $Z$ but this time compared to the ecdf of the simulated $X$ values.\n",
    "- Print $\\arg \\max_y |F_Z(y)-ecdf_X(y)|$, the **maximum** value of the absolute *difference* between the cdfs $F_Z$ and $F_X$ at your linspace locations.\n",
    "- How does it compare to the \"true\" value in part A?  Run your code a few times and report at least 5 such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) How about for Normals?\n",
    "\n",
    "The **distribution** of the numbers you compute in part $B$ is the basis of one measure for whether or not *data* fits a *proposed* distribution.  Our goal is to create a hypothesis test from scratch (recall HW6 # 3 for a similar concept) that gives us the ability to figure out how big of a distance we should get for these measures if the data **does** match the proposed distribution.\n",
    "\n",
    "In other words, we're going to simulate from the null hypothesis and use it to apply to data.  Our motivating example is the `hubble.csv` data from HW7 and nb15, which had 24 observations.\n",
    "\n",
    "**C1)** Your task:\n",
    "- 1) Simulate 24 data points $X$ from the $N(4,10)$ distribution.\n",
    "- 2) **Standardize** $X$ by converting it to a vector of Z-score: $X=\\frac{X-\\bar{X}}{S_X}$\n",
    "- 3) At the same linspace as in parts A/B, compute the maximum distance between the ecdf of the standarized $X$ and the cdf of the N(0,1)$.\n",
    "- Repeat steps 1-3 1000 times until you have a simulated distribution of max distances observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C2) ** Make a histogram of your simulated max values observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C3) ** Create a one-tailed hypothesis test corresponding to the *alternative* hypothesis of \"the data does not come from the normal distribution\" by using a test that rejects the null hypothesis if the distance between ecdf and cdf is $>c$ for some $c$.  If your tolerance for type I error is .10, what do you choose for $c$ on a data set of 24 observations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C4) ** Apply your hypothesis test in part C3 to the `hubble.csv` data by standardizing it and computing its ecdf's distance-from-normal.  The hubble data doesn't **look** very normal, but could we actually conclude that it definitely wasn't normal?  What does this tell you about data sets with only 24 observations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p3'></a>\n",
    "## (60 pts) Problems 2-3: Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Anage](https://genomics.senescence.info/species/index.html) database is a large repositiory of biological information, and includes various properties of various animals with an eye towards understanding the effects of aging in different species.  Most of the columns should be self-explanatory, but for more information you can consult their overview, [here](https://genomics.senescence.info/help.html#anage).\n",
    "\n",
    "A couple of [acronyms](https://genomics.senescence.info/software/demographic.html) in the columns: IMR stands for \"initial mortality rate,\" and represents non-age related deaths.  MRDT is the \"mortality doubling rate,\" and is a measure for the age-related species deaths.\n",
    "\n",
    "Unlike the *descriptive* analysis we did of this data set in the first exam coding, on this problem we will attempt to handle *prediction*.  As before, we will target the birth weight column, this time as the **response** to a linear model. \n",
    "\n",
    "The data is loaded in with a couple of preliminary explorations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HAGRID', 'Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus',\n",
      "       'Species', 'Common name', 'Female maturity (days)',\n",
      "       'Male maturity (days)', 'Gestation/Incubation (days)', 'Weaning (days)',\n",
      "       'Litter/Clutch size', 'Litters/Clutches per year',\n",
      "       'Inter-litter/Interbirth interval', 'Birth weight (g)',\n",
      "       'Weaning weight (g)', 'Adult weight (g)', 'Growth rate (1/days)',\n",
      "       'Maximum longevity (yrs)', 'Source', 'Specimen origin', 'Sample size',\n",
      "       'Data quality', 'IMR (per yr)', 'MRDT (yrs)', 'Metabolic rate (W)',\n",
      "       'Body mass (g)', 'Temperature (K)', 'References'],\n",
      "      dtype='object')\n",
      "(4224, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAGRID</th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Class</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>Common name</th>\n",
       "      <th>Female maturity (days)</th>\n",
       "      <th>...</th>\n",
       "      <th>Source</th>\n",
       "      <th>Specimen origin</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Data quality</th>\n",
       "      <th>IMR (per yr)</th>\n",
       "      <th>MRDT (yrs)</th>\n",
       "      <th>Metabolic rate (W)</th>\n",
       "      <th>Body mass (g)</th>\n",
       "      <th>Temperature (K)</th>\n",
       "      <th>References</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Branchiopoda</td>\n",
       "      <td>Diplostraca</td>\n",
       "      <td>Daphniidae</td>\n",
       "      <td>Daphnia</td>\n",
       "      <td>pulicaria</td>\n",
       "      <td>Daphnia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>medium</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.294130e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>Drosophilidae</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>melanogaster</td>\n",
       "      <td>Fruit fly</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>captivity</td>\n",
       "      <td>large</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.203250e+37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>Apidae</td>\n",
       "      <td>Apis</td>\n",
       "      <td>mellifera</td>\n",
       "      <td>Honey bee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>812</td>\n",
       "      <td>unknown</td>\n",
       "      <td>medium</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.340740e+54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HAGRID   Kingdom      Phylum         Class        Order         Family  \\\n",
       "0     3.0  Animalia  Arthropoda  Branchiopoda  Diplostraca     Daphniidae   \n",
       "1     5.0  Animalia  Arthropoda       Insecta      Diptera  Drosophilidae   \n",
       "2     6.0  Animalia  Arthropoda       Insecta  Hymenoptera         Apidae   \n",
       "\n",
       "        Genus       Species Common name  Female maturity (days)  ...  Source  \\\n",
       "0     Daphnia     pulicaria     Daphnia                     NaN  ...     NaN   \n",
       "1  Drosophila  melanogaster   Fruit fly                     7.0  ...     NaN   \n",
       "2        Apis     mellifera   Honey bee                     NaN  ...     812   \n",
       "\n",
       "   Specimen origin  Sample size  Data quality  IMR (per yr)  MRDT (yrs)  \\\n",
       "0          unknown       medium    acceptable           NaN         NaN   \n",
       "1        captivity        large    acceptable          0.05        0.04   \n",
       "2          unknown       medium    acceptable           NaN         NaN   \n",
       "\n",
       "   Metabolic rate (W)  Body mass (g)  Temperature (K)    References  \n",
       "0                 NaN            NaN              NaN  1.294130e+11  \n",
       "1                 NaN            NaN              NaN  2.203250e+37  \n",
       "2                 NaN            NaN              NaN  6.340740e+54  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/AnAge.csv', encoding='UTF-8')\n",
    "print(df.columns) #information available: many numeric columns are blank for many species\n",
    "print(df.shape) #4224 species available\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (40 pts) Problem 2: Single-Predictor Regression\n",
    "\n",
    "### A) A naive model\n",
    "Suppose our goal is to predict the `Birth weight (g)` of a species using only its `Temperature (K)`.  \n",
    "\n",
    "Your task:\n",
    "- Create a new data frame with only these two columns.  Then drop any rows with missing observations.\n",
    "-  Make a linear model with birth weight as the response, predicted by temperature.  Print the summary table, and write the final model in a markdown cell.\n",
    "- Make a series of 3 side-by-side plots.  Lefthand plot: scatter plot of the data set and overlay the line of best least-squares fit.  Middle plot: histogram of residuals of best least-squares fit are the y-axis.  Righthand plot: scatter plot where the original x-values are the x-axis and the residuals are the y-axis.\n",
    "- Does this model seem appropriate?  For each of the 4 major assumptions of the simple linear regression model, use your plots in part B to decide whether or not the data set meets those assumptions (don't spend too much time here, just look things over!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) A better model\n",
    "\n",
    "You should have **emphatically** decided that there were problems in your model.  But you may already have known this: the `Birth weight (g)` is logarithmic, so it might make sense for our erorrs to be as well.  One solution is to **replace** `Birth weight (g)` as our target with the logarithm of birth weight instead, and then try to predict *that* using `Temperature (K)`.\n",
    "\n",
    "Your task: repeat all 5 steps of the analysis in part A, this time using the natural logarithm of `Birth weight (g)` as the response variable.\n",
    "- Create a new data frame with only these two columns.  Then drop any rows with missing observations.\n",
    "-  Make a linear model with log birth weight as the response, predicted by temperature.  Print the summary table, and write the final model in a markdown cell.\n",
    "- Make a series of 3 side-by-side plots.  Lefthand plot: scatter plot of the data set and overlay the line of best least-squares fit.  Middle plot: histogram of residuals of best least-squares fit are the y-axis.  Righthand plot: scatter plot where the original x-values are the x-axis and the residuals are the y-axis.\n",
    "- Does this model seem appropriate?  For each of the 4 major assumptions of the simple linear regression model, use your plots in part B to decide whether or not the data set meets those assumptions.\n",
    "- Does your data set appear to have outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part C) Improvements: \n",
    "\n",
    "If the data set violated any assumptions in part B, adjust the model accordingly if possible.  Consider removing outliers, adding higher order polynomial terms, etc.  If you adjust the model, make another table and set of plots as in parts A and B of the new fit and the new residuals.\n",
    "\n",
    "\n",
    "Then, write a sentence or two describing your thought process.  If you did not adjust a model, why not?  If you did, what are the effects?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p3'></a>\n",
    "\n",
    "## [20 points] Problem 3: Go Big: Multiple Linear Regression\n",
    "\n",
    "This problem is an open-ended problem where we will approach the same problem as in #2 but you may use more columns in the context of Multiple Linear Regression.  \n",
    "\n",
    "Your goal is to demonstrate that you have an understanding of how to choose between columns and validate/check for problems in a multiple linear regression problem.  \n",
    "\n",
    "The data set has been scrubbed to only include non-missing values of the following columns:\n",
    "- The numerical column `Gestation/Incubation (days)`\n",
    "- The numerical column `Litter/Clutch size`\n",
    "- The numerical column `Maximum longevity (yrs)`\n",
    "- The numerical column `Temperature (K)`\n",
    "- The numerical column `Weaning (days)`\n",
    "\n",
    "It also includes the **categorical** column `Order`, which you may use as a categorical predictor (use `pd.get_dummies`).  Use of this column make the problem harder, but will generate better fits.  Using it and carefully determining **which** orders can be used to help prediction is worth up to 5 points of extra credit.\n",
    "\n",
    "The target/response is still `Birth weight (g)`, but as before you should apply a logarithm to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birth weight (g)</th>\n",
       "      <th>Common name</th>\n",
       "      <th>Order</th>\n",
       "      <th>Gestation/Incubation (days)</th>\n",
       "      <th>Litter/Clutch size</th>\n",
       "      <th>Weaning (days)</th>\n",
       "      <th>Maximum longevity (yrs)</th>\n",
       "      <th>Metabolic rate (W)</th>\n",
       "      <th>Temperature (K)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>7.67</td>\n",
       "      <td>Lesser hedgehog tenrec</td>\n",
       "      <td>Afrosoricida</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>307.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>11.50</td>\n",
       "      <td>Streaked tenrec</td>\n",
       "      <td>Afrosoricida</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.380</td>\n",
       "      <td>308.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>3.95</td>\n",
       "      <td>Dobson's shrew tenrec</td>\n",
       "      <td>Afrosoricida</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.315</td>\n",
       "      <td>304.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Birth weight (g)             Common name         Order  \\\n",
       "1530              7.67  Lesser hedgehog tenrec  Afrosoricida   \n",
       "1532             11.50         Streaked tenrec  Afrosoricida   \n",
       "1533              3.95   Dobson's shrew tenrec  Afrosoricida   \n",
       "\n",
       "      Gestation/Incubation (days)  Litter/Clutch size  Weaning (days)  \\\n",
       "1530                         55.0                6.00            29.0   \n",
       "1532                         59.0                4.00            21.0   \n",
       "1533                         61.0                2.67            29.0   \n",
       "\n",
       "      Maximum longevity (yrs)  Metabolic rate (W)  Temperature (K)  \n",
       "1530                     19.0               0.750           307.85  \n",
       "1532                      2.7               0.380           308.15  \n",
       "1533                      5.6               0.315           304.05  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmlr=df[['Birth weight (g)','Common name' , 'Order', 'Gestation/Incubation (days)', 'Litter/Clutch size',\\\n",
    "          'Weaning (days)', 'Maximum longevity (yrs)', 'Metabolic rate (W)', 'Temperature (K)']]\n",
    "dfmlr=dfmlr.dropna()\n",
    "print(dfmlr.shape)\n",
    "dfmlr.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Rubric Notes:**\n",
    "This problem is by design very open-ended.  It is meant to reflect a real-world problem solving process.  For this problem, at the very least, you should:\n",
    "- Include and explain which method you're using to remove redundant columns in part B\n",
    "- Include a (short) sentence for **each** of the diagnositic plots in part C, determining whether your current model is meeting the standard assumptions of multiple linear regression\n",
    "- Include some code, sentences, and/or visualizations demonstrating what *alternative models* you tried and/or considered.\n",
    "- Include a sentence interpreting why your final model **makes sense** in the context of the problem - and it if doesn't, you'll want to try to explain why not.\n",
    "\n",
    "Graders will look for the both the diagnostic plots and **plenty** of complete English sentences describing what you're doing and why you think it will help answer the data science question: how do we create the best model we can to quantify how price can be explained and predicted by the features of the house.\n",
    "\n",
    "As a quick heuristic: you should be able to find models with adjusted $R^2$ to above 75% using only minor adjustments on the initially provided numerical columns, and above 90% if youuse the categorical column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 3 A: Explore**\n",
    "\n",
    "Make pairwise scatter plots of the continuous predictors/covariates, both against each other and against the outcome (log weight).   Does the relationship between the independent variables and the dependent variables appear to be linear?  Do there appear to be independent variables that are collinear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 3 B: Make a Model**\n",
    "\n",
    "By adding columns to a minimal model or by subtracting columns from the full model, use one of the criteria in the class to create a reasonable candidate model.  These may include:\n",
    "\n",
    "- stepwise optimization of adjusted $R^2$\n",
    "- stepwise inclusion/removal of most or least-significant T-tests on coefficients\n",
    "- removing columns based on VIFs\n",
    "\n",
    "Use a markdown cell to explain exactly what method you're using to construct your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 3 C: Validate your Model**\n",
    "\n",
    "\n",
    "Perform a thorough discussion of the underlying regression assumptions of your model in part 1B.  You should plot a predictor vs. residuals plot for each column and histogram OR qqplot of the overall residuals.  Make sure to also check for non-linearity, which lives in the predictor vs. residuals plots for each column.  \n",
    "\n",
    "*Hint:* Consider applying similar functions to your predictor columns as you did to the response, as they're also in similar all-positive, right-skewed units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 3 D: Tune your Model**\n",
    "\n",
    "\n",
    "Based on your work in parts 1B and 1C, **iterate** on your model.  Consider removing terms or adding higher-order polynomials one at a time unless you are satisfied that your model captures the data as well as possible.  Each time you add or subtract a term from your model, you should repeat the steps in parts B and C: a summary table and exploration of assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 3 E: Explain your Model**\n",
    "\n",
    "**Justify** your choices: there are a lot of ways to choose a \"best\" model: we've mentioned e.g. only including significant predictors versus F-tests versus optimizing R-squared.  Explain what terms you chose and why they were appropriate! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "[Back to top](#top)\n",
    "<a id='bot'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
