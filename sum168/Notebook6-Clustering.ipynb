{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Notebook6-Clustering.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"m9icUMz-jeaz","colab_type":"text"},"source":["# Outline\n","- K-means clustering\n","- Agglomerative clustering\n","- Evaluation"]},{"cell_type":"code","metadata":{"id":"TzpzNx8Ojea3","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap, colorConverter, LinearSegmentedColormap\n","import numpy as np\n","\n","color_map_1 = ListedColormap(['#0000aa', '#ff2020', '#ffaa20'])\n","color_map_2 = ListedColormap(['b', 'g', 'r', 'm', 'y', 'orange' ])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZVqeBH69jebF","colab_type":"text"},"source":["## 1. K-means\n","- Step 1: assigning each data point to the closest cluster center.\n","- Step 2: setting each cluster center as the mean of the data points that are assigned to it."]},{"cell_type":"markdown","metadata":{"id":"V8HNNQUzjebG","colab_type":"text"},"source":["### 1.1 The first K-means model"]},{"cell_type":"code","metadata":{"id":"K3TXbme0jebJ","colab_type":"code","colab":{}},"source":["from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","\n","# Generate isotropic Gaussian blobs, control the centers and standard deviations of each cluster. \n","X, y = make_blobs(random_state=1)\n","\n","# build the clustering model\n","kmeans = KMeans(n_clusters=3)\n","kmeans.fit(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"31lp6deBjebQ","colab_type":"code","colab":{}},"source":["# predict labels: kmeans.labels_ or kmeans.predict(X)\n","print(kmeans.labels_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vkfb0CpTjebW","colab_type":"code","colab":{}},"source":["# cluster centers\n","kmeans.cluster_centers_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"locghwsZjebd","colab_type":"code","colab":{}},"source":["\n","plt.scatter(X[:,0], X[:,1], s=10, c=kmeans.labels_, cmap=color_map_1)\n","plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], \n","            s=50, facecolors='none', edgecolors='black', zorder=50, linewidth=2,\n","            c=kmeans.predict(kmeans.cluster_centers_), cmap=color_map_1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eI6TBxC1jebj","colab_type":"text"},"source":["### 1.2 Try different cluster numbers"]},{"cell_type":"code","metadata":{"id":"kaS5v03Zjebk","colab_type":"code","colab":{}},"source":["\n","f, axarr = plt.subplots(2, 2) \n","f.set_size_inches(10,10)\n","\n","for i, cluster_num in enumerate([2, 4, 5, 6]):\n","    kmeans = KMeans(n_clusters=cluster_num)\n","    kmeans.fit(X)\n","    \n","    axarr[int(i/2)][i%2].scatter(X[:,0], X[:,1], s=10, c=kmeans.labels_, cmap=color_map_2)\n","    axarr[int(i/2)][i%2].scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], \n","            s=50, facecolors='none', edgecolors='black', zorder=50, linewidth=2,\n","            c=kmeans.predict(kmeans.cluster_centers_), cmap=color_map_1)\n","    \n","    axarr[int(i/2)][i%2].set_title('Cluster number = {}'.format(cluster_num))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYoSZ8d9jebp","colab_type":"text"},"source":["## 2. Agglomerative Clustering"]},{"cell_type":"code","metadata":{"id":"7MSm-1sojebr","colab_type":"code","colab":{}},"source":["from sklearn.cluster import AgglomerativeClustering\n","X, y = make_blobs(random_state=1)\n","\n","agg = AgglomerativeClustering(n_clusters=3)\n","assignment = agg.fit_predict(X)\n","\n","plt.scatter(X[:, 0], X[:, 1],  s=10, c=assignment, cmap=color_map_1)\n","plt.legend([\"Cluster 0\", \"Cluster 1\", \"Cluster 2\"], loc=\"best\")\n","plt.xlabel(\"Feature 0\")\n","plt.ylabel(\"Feature 1\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uziuRRjSjebw","colab_type":"code","colab":{}},"source":["# import the dendrogram function and the ward clustering function from SciPy\n","from scipy.cluster.hierarchy import dendrogram, ward\n","\n","X, y = make_blobs(random_state=0, n_samples=12)\n","\n","# apply the ward clustering to the data array X\n","# The SciPy ward function returns an array that specifies the distances\n","# bridged when performing agglomerative clustering\n","linkage_array = ward(X)\n","\n","# now we plot the dendrogram for the linkage_array containing the distances between clusters\n","dendrogram(linkage_array)\n","\n","# mark the cuts in the tree that signify two or three clusters\n","ax = plt.gca()\n","bounds = ax.get_xbound()\n","ax.plot(bounds, [7.25, 7.25], '--', c='k')\n","ax.plot(bounds, [4, 4], '--', c='k')\n","\n","ax.text(bounds[1], 7.25, ' two clusters', va='center', fontdict={'size': 15})\n","ax.text(bounds[1], 4, ' three clusters', va='center', fontdict={'size': 15})\n","plt.xlabel(\"Sample index\")\n","plt.ylabel(\"Cluster distance\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zmzyfro4jeb1","colab_type":"text"},"source":["## 3. Evaluation"]},{"cell_type":"markdown","metadata":{"id":"BHHOHW5ojeb2","colab_type":"text"},"source":["#### With groundtruth"]},{"cell_type":"code","metadata":{"id":"eSIRHbrgjeb3","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","\n","X, y = make_blobs(random_state=0)\n","y_pred = KMeans(n_clusters=3).fit_predict(X)\n","print(y)\n","print(y_pred)\n","\n","# ARI\n","# close to 0.0 for random labeling independently of the number of clusters and samples and \n","# exactly 1.0 when the clusterings are identical.\n","print(f'ARI = {metrics.adjusted_rand_score(y_pred,y)}')\n","\n","# AMI\n","# The AMI returns 1 when the two partitions are identical. \n","# The AMI is close to 0 when randomly labellings.\n","print(f'AMI = {metrics.adjusted_mutual_info_score(y_pred,y, average_method=\"arithmetic\")}')\n","\n","# NMI\n","# Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling\n","print(f'NMI = {metrics.normalized_mutual_info_score(y_pred,y, average_method=\"arithmetic\")}')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"itviHIi2jeb-","colab_type":"text"},"source":["#### Without groundtruth"]},{"cell_type":"code","metadata":{"id":"CwfW73s1jecA","colab_type":"code","colab":{}},"source":["from sklearn.metrics.cluster import silhouette_score\n","print(f\"Cluster silhouette = {silhouette_score(X, y_pred)}\")\n","\n","y_rand = np.random.choice([0,1,2], size=len(X))\n","print(f\"Random silhouette = {silhouette_score(X, y_rand)}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jz9nWWyPjecF","colab_type":"text"},"source":["#### Compare different algorithms"]},{"cell_type":"code","metadata":{"id":"ujnHwOg8jecG","colab_type":"code","colab":{}},"source":["from sklearn.metrics.cluster import silhouette_score, adjusted_rand_score\n","from sklearn.datasets import make_moons\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","\n","# generate data\n","X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n","X_scaled = StandardScaler().fit_transform(X)  # Rescale the data to zero mean and unit variance\n","\n","fig, axes = plt.subplots(1, 4, figsize=(15, 3), subplot_kw={'xticks': (), 'yticks': ()})\n","\n","# plot random assignment\n","# create a random cluster assignment for reference:\n","random_state = np.random.RandomState(seed=0)\n","random_clusters = random_state.randint(low=0, high=2, size=len(X))\n","\n","axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters, cmap=color_map_2, s=60)\n","title = f\"Random ARI: {adjusted_rand_score(y, random_clusters):.2f}\" + '\\n' +\\\n","    f\"Random silhouette: {silhouette_score(X_scaled, random_clusters):.2f}\"\n","axes[0].set_title(title)\n","\n","# plot clurstering algorithms\n","algorithms = [KMeans(n_clusters=2), AgglomerativeClustering(n_clusters=2),\n","              DBSCAN()]\n","for ax, algorithm in zip(axes[1:], algorithms):\n","    clusters = algorithm.fit_predict(X_scaled)\n","    # plot the cluster assignments and cluster centers\n","    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=color_map_2, s=60)\n","    title = f\"{algorithm.__class__.__name__} ARI: {adjusted_rand_score(y, clusters):.2f}\" + '\\n' + \\\n","    f\"{algorithm.__class__.__name__} silhouette: {silhouette_score(X_scaled, clusters):.2f}\"\n","    ax.set_title(title)"],"execution_count":0,"outputs":[]}]}