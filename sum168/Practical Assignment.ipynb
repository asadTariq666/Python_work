{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names: ['Mustafa Al-Tamimi', 'How Jong Lai'] \n",
    "## Studentnumbers: ['12717916', '12426083']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NuJ0879WJF0E",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Names: ['Mustafa Al-Tamimi', 'How Jong Lai'] \n",
    "Studentnumbers: ['12717916', '12426083']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PHjzAhvgBlo7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "# Dataset with 10K instances\n",
    "! gdown \"https://drive.google.com/uc?id=1cj-CzkY6QZUe42ky64GI5CSSg7-K40N5\"\n",
    "# Dataset with 100k instances\n",
    "! gdown \"https://drive.google.com/uc?id=1MbWGXLawE3VTxP1XgNpj8uEo1VHPq12B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SlHJBPXQJF0K",
    "nbgrader": {
     "checksum": "86f687db575cf409d54ac5e91e6dd861",
     "grade": false,
     "grade_id": "cell-1979a89473cf7ece",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 1: Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "id": "wKpbQMIQJF0K",
    "nbgrader": {
     "checksum": "89914f38bf3510543caaef66d0f14169",
     "grade": false,
     "grade_id": "cell-700f4a41782fa412",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Applied Machine learning\n",
    "## Practical Assignment 2\n",
    "\n",
    "### Important Notes:\n",
    "1. Submit through **Canvas** before 11:59pm on Tuesday, May 17, 2022\n",
    "2. No late homework will be accepted\n",
    "3. This is a group-of-two assignment\n",
    "4. The submitted file should be in ipynb format\n",
    "5. The assignment is worth it 10 points\n",
    "6. For questions, please use the discussion part of Canvas (English only!)\n",
    "7. The indication **optional** means that the question is optional; you won't lose any points if you do not do that part of the assignment, nor will you gain if you do it.\n",
    "\n",
    "### Software:\n",
    "We will be using Python programming language throughout this course. Further we will be using:\n",
    "+ IPython Notebooks (as an environment)\n",
    "+ Numpy\n",
    "+ Pandas\n",
    "+ Scikit-learn\n",
    "\n",
    "### Background:\n",
    "\n",
    "This practical assignment will be covering logistic regression, neural networks, support vector machines and evaluation of classifiers. \n",
    "\n",
    "For the assignment, please download a dataset on Load Defaults. You are provided with two datasets:\n",
    "1. [Dataset](https://drive.google.com/open?id=1cj-CzkY6QZUe42ky64GI5CSSg7-K40N5) with 10,000 instances \n",
    "2. [Dataset](https://drive.google.com/open?id=1MbWGXLawE3VTxP1XgNpj8uEo1VHPq12B) with 100,000 instances\n",
    "\n",
    "In principle you should work on the second, larger dataset, but if you face scaling computational issues then better work with the first, smaller dataset.\n",
    "\n",
    "This data corresponds to a set of financial transactions associated with individuals. The data has been standardized, de-trended, and anonymized. You are provided with thousands of observations and nearly 800 features. Each observation (instance) is independent from the previous. \n",
    "\n",
    "For each observation, it was recorded whether a default was triggered (i.e. whether an individual could not pay back the loan). In case of a default, the loss for the bank was measured. This quantity lies between 0 and 100. If the loan did not default, the loss for the bank was 0. You are asked to predict whether a loan will default or not for each individual in the test set.\n",
    "\n",
    "Missing feature values have been kept as is, so that the competing teams can really use the maximum data available, implementing a strategy to fill the gaps if desired. Consider all variables continuous, even though some variables may be categorical (e.g. f776 and f777).\n",
    "\n",
    "The goal of the machine learning algorithm will be to predict whether a loan will default, given a set of features. For privacy reasons the feature names are not provided.\n",
    "\n",
    "**Important Note**: This second assignment is not as instructive as the first assignment. The first assignment guided you step-by-step through all the preprocessing, training-validation-testing setup, etc. This assignment does not do so, but it leaves it up to you to decide how to use the data and design your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "k63PQb_KJF0L",
    "nbgrader": {
     "checksum": "cdc9100b2eb32f795318f88531439408",
     "grade": false,
     "grade_id": "cell-3a36fe2e430fa9ab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howjo\\AppData\\Local\\Temp/ipykernel_57256/164970065.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only\n",
      "  dfn = df.dropna(0, how='any')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('loan_default_10K.csv', sep=\",\", header=0, dtype=np.float64)\n",
    "\n",
    "# Drop the observations that contain missing values\n",
    "dfn = df.dropna(0, how='any')\n",
    "\n",
    "# Consider only a handful of features to start with; you can extend to the full set later on.\n",
    "X = dfn.loc[:,'f400':'f500'].values\n",
    "\n",
    "# Generate the labels; if 'loss' is zero the this indicates the negative class, class 0, i.e. no default;\n",
    "# if 'loss' is possitive this indicates the positive class, class 1, i.e. there is a loan default;\n",
    "y = [ bool(y) for y in dfn.loc[:,'loss'].values ]\n",
    "\n",
    "# Split the data into train, validation, and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83607.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>127.76</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79124.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>122.72</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-0.5399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.985674</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13026.0</td>\n",
       "      <td>4565.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>126.36</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.06</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>-0.6732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.385778</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79244.0</td>\n",
       "      <td>6597.0</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>127.19</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>-0.7220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.745471</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>78920.0</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>123.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2601</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>9994.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.158750</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>81149.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>2616.0</td>\n",
       "      <td>129.27</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>-22.69</td>\n",
       "      <td>17.55</td>\n",
       "      <td>0.2338</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>9995.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.110664</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>3358.0</td>\n",
       "      <td>127.21</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.42</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>8.71</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>-0.3310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.049355</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>81629.0</td>\n",
       "      <td>6142.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>123.49</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>-3.32</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.811840</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14629.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>124.39</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>-9.10</td>\n",
       "      <td>7.17</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.147179</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7399.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>7437.0</td>\n",
       "      <td>132.69</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.68</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4367 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     f1    f2        f3      f4    f5       f6      f7      f8  \\\n",
       "2        3.0  126.0  10.0  0.500080  1100.0   3.0  83607.0  1800.0  1527.0   \n",
       "4        5.0  109.0   9.0  0.502749  2900.0   4.0  79124.0    89.0   491.0   \n",
       "6        7.0  121.0   9.0  0.985674  2900.0   4.0  13026.0  4565.0   263.0   \n",
       "7        8.0  128.0   9.0  0.385778  2900.0   4.0  79244.0  6597.0  3592.0   \n",
       "8        9.0  126.0   9.0  0.745471  2900.0   4.0  78920.0  3058.0   112.0   \n",
       "...      ...    ...   ...       ...     ...   ...      ...     ...     ...   \n",
       "9993  9994.0  131.0   8.0  0.158750  1700.0  10.0  81149.0   328.0  2616.0   \n",
       "9994  9995.0  131.0   8.0  0.110664  1700.0  10.0    387.0   348.0  3358.0   \n",
       "9996  9997.0  120.0   8.0  0.049355  1700.0  10.0  81629.0  6142.0  3359.0   \n",
       "9997  9998.0  122.0   8.0  0.811840  1700.0  10.0  14629.0  1274.0  1044.0   \n",
       "9998  9999.0  134.0   8.0  0.147179  1700.0  10.0   7399.0  3526.0  7437.0   \n",
       "\n",
       "          f9  ...  f770   f771   f772   f773    f774    f775  f776  f777  \\\n",
       "2     127.76  ...  13.0   2.89  -1.73   1.04  0.2521  0.7258   1.0   0.0   \n",
       "4     122.72  ...  26.0   6.11  -3.82   2.51  0.2282 -0.5399   0.0   0.0   \n",
       "6     126.36  ...  23.0   7.06  -4.99   3.77  0.2458 -0.6732   0.0   0.0   \n",
       "7     127.19  ...  17.0   4.45  -3.26   2.56  0.2947 -0.7220   0.0   0.0   \n",
       "8     123.89  ...   7.0   2.02  -1.35   0.95  0.2601  0.7132   0.0   0.0   \n",
       "...      ...  ...   ...    ...    ...    ...     ...     ...   ...   ...   \n",
       "9993  129.27  ...  74.0  30.47 -22.69  17.55  0.2338  0.7184   0.0   0.0   \n",
       "9994  127.21  ...  50.0  15.42 -11.25   8.71  0.2840 -0.3310   0.0   0.0   \n",
       "9996  123.49  ...  12.0   4.55  -3.32   2.46  0.2615  0.8489   0.0   0.0   \n",
       "9997  124.39  ...  30.0  12.00  -9.10   7.17  0.2605  0.6744   0.0   0.0   \n",
       "9998  132.69  ...  20.0   7.68  -5.57   4.20  0.2407  0.7930   0.0   0.0   \n",
       "\n",
       "      f778  loss  \n",
       "2      5.0   0.0  \n",
       "4      5.0   0.0  \n",
       "6      5.0   0.0  \n",
       "7      5.0   1.0  \n",
       "8      5.0   0.0  \n",
       "...    ...   ...  \n",
       "9993   8.0   0.0  \n",
       "9994   8.0   0.0  \n",
       "9996   8.0   8.0  \n",
       "9997   8.0   0.0  \n",
       "9998   8.0   0.0  \n",
       "\n",
       "[4367 rows x 771 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0LKlXxS3JF0L",
    "nbgrader": {
     "checksum": "ff730342a91fefa515c3117b502aa292",
     "grade": false,
     "grade_id": "cell-735be096b0f642ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 2: Evaluation measures (2pts)\n",
    "In what follows you should implement a number of evaluation measures. You need to implement these from scratch, meaning that it is not allowed to call any scikit-learn function, or any other API function that implements the method for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4yvWH4cgJF0L",
    "nbgrader": {
     "checksum": "cdadfd696f9d159f0242cad28b7f41ef",
     "grade": false,
     "grade_id": "cell-a127e8413f617d64",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that produces the contigency matrix, i.e. True Positives, False Positives, True Negatives, False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "id": "294-dY4BJF0M",
    "nbgrader": {
     "checksum": "bd892db60c7761bace1ca06b9361a045",
     "grade": false,
     "grade_id": "cell-aab0f82d6a21bea5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def contigency_matrix(true_y, predicted_y):\n",
    "    # YOUR CODE HERE, Create TP, FP, TN, FN\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(predicted_y)): \n",
    "        if true_y[i]==predicted_y[i]==1:\n",
    "            TP += 1\n",
    "        if predicted_y[i]==1 and true_y[i]!=predicted_y[i]:\n",
    "            FP += 1\n",
    "        if true_y[i]==predicted_y[i]==0:\n",
    "            TN += 1\n",
    "        if predicted_y[i]==0 and true_y[i]!=predicted_y[i]:\n",
    "            FN += 1\n",
    "\n",
    "    #return(TP, FP, TN, FN)\n",
    "    \n",
    "    # Make sure your output fits the following format:\n",
    "    matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,  78],\n",
       "       [697,  91]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contigency_matrix(y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cV3BfX8jJF0M",
    "nbgrader": {
     "checksum": "b2f901219adca9d441082d3fcf702e6b",
     "grade": false,
     "grade_id": "cell-b3c52de1970e361e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes accuracy (without using any built-in accuracy function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "DK2lCwiNJF0M",
    "nbgrader": {
     "checksum": "f6705877fef7cd74d89832d32a8536a0",
     "grade": false,
     "grade_id": "cell-2e0cc734628dd4c2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(true_y, predicted_y):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(predicted_y)): \n",
    "        if true_y[i]==predicted_y[i]==1:\n",
    "            TP += 1\n",
    "        if predicted_y[i]==1 and true_y[i]!=predicted_y[i]:\n",
    "            FP += 1\n",
    "        if true_y[i]==predicted_y[i]==0:\n",
    "            TN += 1\n",
    "        if predicted_y[i]==0 and true_y[i]!=predicted_y[i]:\n",
    "            FN += 1\n",
    "    \n",
    "    matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    \n",
    "    upper = TP + TN\n",
    "    lower = TP + TN + FN + FP\n",
    "    accuracy = upper/lower\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066361556064073"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4LznpIdTJF0M",
    "nbgrader": {
     "checksum": "4b3798ba720235065011afa2736346a7",
     "grade": false,
     "grade_id": "cell-d045e95a552112ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes precision for one class (without using any built-in precision function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "id": "QC8SeWOIJF0M",
    "nbgrader": {
     "checksum": "40f4c7470d6073739cff4934761469c8",
     "grade": false,
     "grade_id": "cell-a403be8ac0ee7af0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def precision(true_y, predicted_y):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(predicted_y)): \n",
    "        if true_y[i]==predicted_y[i]==1:\n",
    "            TP += 1\n",
    "        if predicted_y[i]==1 and true_y[i]!=predicted_y[i]:\n",
    "            FP += 1\n",
    "        if true_y[i]==predicted_y[i]==0:\n",
    "            TN += 1\n",
    "        if predicted_y[i]==0 and true_y[i]!=predicted_y[i]:\n",
    "            FN += 1\n",
    "    \n",
    "    matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    \n",
    "    upper = TP\n",
    "    lower = TP + FP\n",
    "    precision = upper/lower\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09302325581395349"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_D7OYnK4JF0N",
    "nbgrader": {
     "checksum": "6dbe4298af11247615077250b24d3f59",
     "grade": false,
     "grade_id": "cell-4822b32d0cedb0e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes recall for one class (without using any built-in recall function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "id": "X08ucQRFJF0N",
    "nbgrader": {
     "checksum": "cf41435f0b5003e31ae61340d3188bde",
     "grade": false,
     "grade_id": "cell-075963e37ff41c66",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def recall(true_y, predicted_y):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(predicted_y)): \n",
    "        if true_y[i]==predicted_y[i]==1:\n",
    "            TP += 1\n",
    "        if predicted_y[i]==1 and true_y[i]!=predicted_y[i]:\n",
    "            FP += 1\n",
    "        if true_y[i]==predicted_y[i]==0:\n",
    "            TN += 1\n",
    "        if predicted_y[i]==0 and true_y[i]!=predicted_y[i]:\n",
    "            FN += 1\n",
    "    \n",
    "    matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    \n",
    "    upper = TP\n",
    "    lower = TP + FN\n",
    "    recall = upper/lower\n",
    "    return recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08080808080808081"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yE78OP9tJF0N",
    "nbgrader": {
     "checksum": "c0fa7903c66407fa515b5c4c5e12b266",
     "grade": false,
     "grade_id": "cell-f0c5ff30db6fc1b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes f1 for one class(without using any built-in f1 function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "id": "FB-f5OO1JF0N",
    "nbgrader": {
     "checksum": "0b8095ecb0d05692b4a57cc17eff026d",
     "grade": false,
     "grade_id": "cell-bcc41b9d876ee5d4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def f1(true_y, predicted_y):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(predicted_y)): \n",
    "        if true_y[i]==predicted_y[i]==1:\n",
    "            TP += 1\n",
    "        if predicted_y[i]==1 and true_y[i]!=predicted_y[i]:\n",
    "            FP += 1\n",
    "        if true_y[i]==predicted_y[i]==0:\n",
    "            TN += 1\n",
    "        if predicted_y[i]==0 and true_y[i]!=predicted_y[i]:\n",
    "            FN += 1\n",
    "    \n",
    "    matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    \n",
    "    upper = TP\n",
    "    lower = (TP + 0.5*(FP+FN))\n",
    "    f1 = upper/lower\n",
    "    return f1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08648648648648649"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jO5VhQLWJF0N",
    "nbgrader": {
     "checksum": "e0d9785e1e45e2179c318aec035059ad",
     "grade": false,
     "grade_id": "cell-c21fd73cbce64a50",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 3: Algorithms\n",
    "Compare the performance of Logistic Regression, SVMs and Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UWXjVAenJF0N",
    "nbgrader": {
     "checksum": "af0943a520201c48990805ce5cb2cb7c",
     "grade": false,
     "grade_id": "cell-7ea6f44ccf633c76",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### Logistic Regression (Lecture 3) (2pts)\n",
    "\n",
    "+ Train and test a logistic regression model\n",
    "    + Construct a table with each row being a different value of the regularization parameter and each column the aforementioned measures\n",
    "    + Explain your findings and select the optimal model\n",
    "    + Report the performance of the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "vnnZ6T1MJF0O",
    "nbgrader": {
     "checksum": "bb4b24cb9b3769517aafa02dce6321d4",
     "grade": true,
     "grade_id": "cell-eea85664ef370cd5",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Train and test logistic regression model\n",
    "\n",
    "# Construct table\n",
    "\n",
    "# Select optimal model\n",
    "\n",
    "# Report performance of optimal model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KNigDLF2JF0O",
    "nbgrader": {
     "checksum": "0d74b83486a9bcdcbdf539376bd56e52",
     "grade": false,
     "grade_id": "cell-f57d340c8ac3f3b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Explain what you observe regarding the positive class; i.e. the performance of the algorithm in predicting defaults. Explain why is this happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "NjRu6n9kJF0O",
    "nbgrader": {
     "checksum": "106a108640959c5f8b9523216dfc1ca2",
     "grade": true,
     "grade_id": "cell-75527f6a11293f5c",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">**Replace the text in this cell with your explanation**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MZUnFZUxJF0O",
    "nbgrader": {
     "checksum": "847a1e00ad9d4316b9512efe1a66df26",
     "grade": false,
     "grade_id": "cell-f1d84ada7bb6859e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "There are a number of ways to fix the problem you have observed above. Here we will consider two of them: downsampling and upsampling. In an ideal situation you will like your dataset to be balanced, i.e. to have the same number of instances for the positive and the negative class.\n",
    "\n",
    "**Downsampling**: Let's assume that the positive class has *n1* instances, while the negative class *n2* instances, where *n2* is much bigger than *n1*. One solution is to create a new training set for which from the *n2* instances of the negative class you sample *n1* of them only to include in your training set; hence now you have *n1* + *n1* training instances.\n",
    "\n",
    "**Upsampling**: Let's assume that the positive class has *n1* instances, while the negative class *n2* instances, where *n2* is much bigger than *n1*. Another solution is to create a new training set for which you create  *n2* instances of the positive class. To do so you sample *n2* instances from the *n1* instance, with replacement. With replacement means that you allow the same instance to be sampled multiple times; hence now you have *n2* + *n2* training instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "otj4Qm3MJF0O"
   },
   "source": [
    "#### Downsampling (OPTIONAL – If you wish to skip downsampling continue to Neural Networks further below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_sDkkIcUJF0O",
    "nbgrader": {
     "checksum": "ea6ec4f362d483b9439040f12d09b46a",
     "grade": false,
     "grade_id": "cell-59aa6ae849b90374",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function for downsampling (**optional**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "7L6yUCajJF0P",
    "nbgrader": {
     "checksum": "005c2fee650b5518f0d377e26d46615d",
     "grade": true,
     "grade_id": "cell-f111bc027ec54669",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def downsample(y_train):\n",
    "    # y_train is the 1d matrix of the labels in your training data, e.g.\n",
    "    #       0     1     2     3     4   5     6     7     8   ... \n",
    "    # y = [True False False False True True False False False ... False]\n",
    "    #\n",
    "    # the function returns the position of the training data to be considered for the final training set.\n",
    "    # e.g. if you decide from the True instances to select 0, 4 and 5, while from the False instances 1, 3, and 8\n",
    "    # the outcome of the function will be [0, 1, 3, 4, 5, 8] (= sampled_indexes)\n",
    "    \n",
    "    # your code goes here\n",
    "    \n",
    "    return sampled_indexes\n",
    "    \n",
    "def new_training_set(X_train, y_train, sampled_indexes):\n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "akjEu_5-JF0P",
    "nbgrader": {
     "checksum": "7acfd4fa50b0ce7567f3622b8df52dc9",
     "grade": false,
     "grade_id": "cell-0489481a9fc804d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Test the performance of logistic regression using the new training set, and report your conclusions (**optional**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "gYWgW2LOJF0P",
    "nbgrader": {
     "checksum": "8ef852228cb6d7212a28012d7e335ad1",
     "grade": true,
     "grade_id": "cell-cd7143b6e088d522",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT1gcqt_JF0P"
   },
   "source": [
    "# The last few questions below are not optional!\n",
    "If you did not finish the optional downsampling, just go through with the data created before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5DL60WojJF0Q",
    "nbgrader": {
     "checksum": "88788580e9ea0cc74560a55c6231466b",
     "grade": false,
     "grade_id": "cell-d7e21719abffa28b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### SVMs (Lecture 4) (2pts)\n",
    "\n",
    "+ Train and test a Support Vector Machine model\n",
    "    + Construct a table with each row being a different configuration of the SVM algorithm (play with the regularization parameter, and the kernel function – use linear, poly, and rbf) and each column the evaluation measures\n",
    "    + Explain your findings and select the optimal model\n",
    "    + Report the performance of the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Ac5mNYD3JF0P",
    "nbgrader": {
     "checksum": "167eed2eaafde3d4951aef9059e06a58",
     "grade": true,
     "grade_id": "cell-c6f93c6c6f633c47",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "hte-UpsCJF0Q",
    "nbgrader": {
     "checksum": "2412fc015a280623635f3bf03e3fde9e",
     "grade": true,
     "grade_id": "cell-b4ae750d1154f837",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">**Replace the text in this cell with your report**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YI7doqzLJF0P",
    "nbgrader": {
     "checksum": "fdac93da6191896d74c7346d2e875a84",
     "grade": false,
     "grade_id": "cell-4dc578274728380b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### Neural Network (Lecture 5) (2pts)\n",
    "\n",
    "+ Train and test a Neural Network model\n",
    "    + Construct a table with each row being a different configuration of the network (play with the number of hidden layers, the number of neurons in each layer, and the activation function) and each column the evaluation measures\n",
    "    + Report the performance of at least three different configurations\n",
    "    + Explain your findings and select the optimal model\n",
    "    + Justify your choice of different paramteres and architectures\n",
    "    + Report the performance of the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "YWgD6iFmJF0Q",
    "nbgrader": {
     "checksum": "e4d7a215763017f7111a6162d214ed5e",
     "grade": true,
     "grade_id": "cell-7009d775455986ad",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "Pw5mJ1z1JF0Q",
    "nbgrader": {
     "checksum": "36cda951bae6da0700d3f6202d0f1a89",
     "grade": true,
     "grade_id": "cell-42c8bf3a6a671fef",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">**Replace the text in this cell with your report**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OIgJSXMTJF0Q",
    "nbgrader": {
     "checksum": "baabfebe46559e2d055cef7ceae38b0e",
     "grade": false,
     "grade_id": "cell-23280b034d299667",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Compare Algorithms (2pts)\n",
    "* Plot the Precision-Recall curves for the best model for each one of the above algorithms, Logistic Regression, Neural Nets, and SVM.\n",
    "    * Use the precision_recall_curve from scikit-learn\n",
    "* Explain your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "8kRDcyLuJF0Q",
    "nbgrader": {
     "checksum": "b17597ab95452fa3d4259cb4d2bee6c2",
     "grade": true,
     "grade_id": "cell-d6967e3b3e3dbe7a",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "_vShAj6OJF0Q",
    "nbgrader": {
     "checksum": "58ca34644cf139f5987905e2058ea0b3",
     "grade": true,
     "grade_id": "cell-b91319845bc74219",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">**Replace the text in this cell with your report**</span>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "Practical Assignment 2 - Student.ipynb ",
   "provenance": [
    {
     "file_id": "17ja4GM2Ci0MjQjO3RjTNBS0wcnLBpBIr",
     "timestamp": 1618862623296
    },
    {
     "file_id": "1tO5F-kPHZPpMGLNuPjfNqd3rXU1Lkmn1",
     "timestamp": 1618842712618
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
